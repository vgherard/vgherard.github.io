---
title: "Bootstrap"
author:
  - name: Valerio Gherardi
    url: https://vgherard.github.io
date: 2024-02-07
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 3
bibliography: biblio.bib
draft: true
---

## Introduction

The Bootstrap [@EfronBootstrap79] is a set of computational techniques for statistical inference that generally operate by approximating the true, unknown distribution of a population of interest with the empirical distribution observed in a finite sample. 

## Theoretical Motivation

The main theoretical ideas behind the bootstrap can be sketched with a non-parametric example. Consider a functional $t=t(P)$ of a probability measure $P$ which admits a first order expansion :

$$
t(Q) \approx t(P) + L(P; Q - P),(\#eq:FunctionalApprox)
$$
where $L(P;\nu)$ is assumed to be a *linear* functional of $\nu$. If $Q$ has finite support, linearity implies that:

$$
L(P,Q-P) = \intop \psi _P\,\text dQ(\#eq:GateauxIntegralRep),
$$
and we shall further assume that such a representation is valid for any $Q$^[The integral representation \@ref(eq:GateauxIntegralRep) with bounded $\psi _P$ automatically follows if $L$ is (weak-star) continuous and Frech√©t differentiable [@huber2004robust]. In the most general case, the sense in which Eq. \@ref(eq:FunctionalApprox) is assumed to hold is that of a directional (Gateaux) derivative, and we assume Eq. \@ref(eq:GateauxIntegralRep) to hold for some measurable (not necessarily bounded) function $\psi _P$, which is usually easy to verify in concrete cases.]. Notice in particular, that from this definition we have: 

$$
\mathbb E(\psi _P) = L(P,P-P) = 0(\#eq:PsiZeroExp)
$$

Suppose now that we have a sample of $N$ i.i.d. observations $\{X_1,\,X_2,\,\dots,\,X_N\}$ coming from  $P$, and let $Q=\hat P _N$ in the previous expression, where $\hat P _N = \frac{1}{N}\sum _{i=1}^N\delta _{X_i}$ stands for the empirical distribution. Then:

$$
t(\hat P _N) \approx t(P) + L(P; \hat P _N - P) = t(P) + \frac{1}{N}\sum _{i = 1} ^N \psi(X_i).(\#eq:FunctionalApproxEmpDist)
$$
It follows that $t(\hat P _N)$, *i.e.* the so-called "plugin" estimate, is a consistent estimate of $t(P)$, with:

$$
\mathbb E(t(\hat P _N)) \approx t(P),\quad \mathbb V(t(\hat P_N)) \approx \frac{1}{N}\mathbb V(\psi(X)),(\#eq:PluginPrinciple)
$$
where the first equation follows from \@ref(eq:PsiZeroExp), while the second one follows from the i.i.d. nature of the sample.

The general idea behind the bootstrap is to estimate $t(P)$ with $t(\hat P _N)$. Equation \@ref(eq:PluginPrinciple) shows that this is justified whenever the $\mathcal O (N^{-1})$ variance can be considered negligible, as is often the case in concrete bootstrap applications^[To be precise, in many practical applications, the functional of interest $t(P)$ would itself depend on $N$, so that we should actually write $t_N(P)$. A relevant example would be the variance of a plugin estimate $v_N(P)\equiv\mathbb V (t(\hat P _N))$. In this and similar cases, in which $v_N=\mathcal O (N^{-\alpha})$ the argument can be repeated *mutatis mutandis* for the functional $V_N = N^\alpha \cdot v_N$, which has a finite limit $V_N \to V$, assumed to be different from zero. Specifically, if we let $V_N = V+\Delta$ we have:
$$
V_N(\hat P_N) -V_N(P) = V(\hat P_N)-V(P)+\Delta _N (\hat P_N)-\Delta_N(P).
$$
Since both terms in the right hand side have vanishing (to first order) expectation and $\mathcal O (N^{-1})$ variance, this shows that we can use $V_N(\hat P _N)$ to approximate the target quantity $V_N(P)$, or equivalently $v_N(\hat P _N)$ to approximate $v_N(P)$, since $\frac{\mathbb E(v_N(\hat P_N))}{v_N(P)}\approx 1$ and $\frac{\mathbb V(v_N(\hat P_N))}{v_N(P)}=\mathcal O (N^{-1})$.]. 

## The role of simulation

The second, more case specific, ingredient of a practical bootstrap estimate would be an *approximation scheme* (often a Monte-Carlo one) for effectively computing $t(\hat P _N)$, which, apart from trivial examples, is by itself impossible to compute exactly - either analytically or numerically. This is best clarified in the example above 



[
  {
    "path": "posts/2022-10-18-posi/",
    "title": "How to get away with selection. Part I: Introduction",
    "description": "Introducing the problem of Selective Inference, illustrated through a simple simulation in R.",
    "author": [
      {
        "name": "vgherard",
        "url": "https://vgherard.github.io"
      }
    ],
    "date": "2022-11-14",
    "categories": [
      "R",
      "Statistics"
    ],
    "contents": "\nPrologue\nA few months back, for undocumented circumstances, my browser‚Äôs search\nhistory was full of terms like ‚Äúparameter estimation with variable selection‚Äù,\nor ‚Äúconfidence intervals after cross-validation‚Äù, or again\n‚Äúlinear model uncertainties after staring into the abyss‚Äù, ‚Ä¶\nSparing you my rock bottom, I eventually stumbled upon the right keywords, and\nstarted digging into the mathematical aspects of Selective Inference, or\nPost-Model Selection Inference. Now, while my hands\nare still full of dirt, I‚Äôve decided it‚Äôs the right moment to write some\nnotes about what I‚Äôve learned - whose main recipient is the future me,\nwhich will otherwise inevitably forget what the present me thinks he\nknows. If you‚Äôre not the future me:\nWelcome üëã\nIf you have detected some imprecision, or have suggestions for this or the\nnext posts, you are more than welcome to create an issue on the source\nrepository of this blog.\nIntroduction\nBroadly speaking, the problem of Selective Inference is that of\nperforming valid statistical inferences when the actual questions of the data analysis are not fixed in advance, but rather selected through data examination. In model-based inference, this lack of\npre-determination usually stems from the (often unavoidable) practice of\nusing the same data to choose an adequate model for the data generating\nprocess and to perform inference. The intrinsic\nrandomness of the selection process has important consequences on the\nprobability of making different guesses about the selected questions,\nwhich, if not properly taken into account, can completely invalidate the\nanalysis results.\nIf this sounds unfamiliar, think about machine-learning: when training a\npredictive model on a given dataset, you would usually consider the\nerror on the same dataset as a poor (optimistic) estimate of the true\nmodel‚Äôs error rate, because the model was tuned to perform well on that\ndata in the first place. There we go, Selective Inference! A selection\nfrom an extended family of models1 is performed through data examination,\nand this event introduces a bias in the error estimate of the final\nmodel from training data.\nThe example from machine-learning also suggests a very simple-minded and\nrelatively a-theoretical approach to Selective Inference: data-splitting2. According to this method, we would use only part of the available data to select the questions to be answered by the analysis, while the remaining part would\nbe reserved to perform the actual inference. For this program to\nsucceed, there are however two important requirements: first, we must have\nenough data to ensure decent statistics for both the selection and inference\ntasks; and second, we must be able to split data in two independent\n(or close to independent) sets. This can suppose problems with, e.g.,\ntime-series data. If, on the other hand, these requirements cannot be met, we\nhave to resort to more sophisticated methods.\nAt this point, I would like to stress that the conceptual problems\nI‚Äôve just pointed out will probably look obvious to any reader with a\ndecent intuition for probability3. What is less obvious, but in fact\na fairly active research field in statistics,\nis how to perform valid selective inferences when the ‚Äúeasy‚Äù solution of\ndata-splitting I mentioned above is not available. This is where theory\nre-enters the game, and what I‚Äôm going to ramble about in this and the next\nposts.\nIllustrations of Selective Inference\nEnough for the speech, let us see how selection can affect (and invalidate)\nclassical inference with a simple-minded simulation.\nSetting\nTo illustrate why naive classical inference can fail in the presence of\nselection, we consider a very simple regression\nproblem involving a single regressor \\(X\\) and a response \\(Y\\), where all the assumptions of the classical linear model hold. In fact, we will assume the true data generating process to be:\n\\[\nY = mX + \\varepsilon, \\qquad \\varepsilon \\sim \\mathcal N (0, \\sigma),\n\\tag{1}\n\\]\nwhere \\(\\varepsilon \\sim \\mathcal N (0, \\sigma)\\) means ‚Äú\\(\\varepsilon\\) follows a gaussian distribution with mean \\(0\\) and standard deviation \\(\\sigma\\)‚Äù.\nA selective modeling procedure\nNow, suppose we are given a dataset of \\(N\\) independent observations\n\\((y_i, x_i)_{i = 1, \\,2,\\, \\dots,\\,N}\\), and we would like to study the\ndependence of \\(Y\\) from \\(X\\). Of course we don‚Äôt know the true law, Eq.\n(1), but by a stroke of luck (or by a Taylor expansion\nargument) we make the correct initial guess that such dependence is\nlinear in \\(X\\). We are, however, unsure whether it would be appropriate\nto also include an intercept term in the fit. We thus establish the\nfollowing selective modeling procedure:\nFit a linear model with intercept term,\n\\(Y = mX + q + \\varepsilon\\).\nStop if the intercept estimate is significantly different from zero (say, at the level of 1-\\(\\sigma\\), \\(p\\text{-value}<32\\%\\)). Otherwise:\nFit a model with no intercept, \\(Y = mX + \\varepsilon\\).\nFinally, we use the last fitted model to construct a ‚Äúnaive 95%‚Äù\nconfidence interval \\((\\hat m_-, \\hat m_+)\\) for the slope \\(m\\).\nThis is defined by:\n\\[\n\\hat m_\\pm = \\hat m\\pm t_{0.975, \\,N-d} \\cdot \\hat \\sigma _\\hat m\\qquad (95\\%\\,\\text {C.L.}).\n\\tag{2}\n\\]\nHere \\(t_{0.975,\\, N-d}\\) is the 97.5%-quantile of the \\(t\\)-student\ndistribution with \\(N-d\\) degrees of freedom, and \\(d\\) is the number of\nestimated parameters, (\\(2\\) or \\(1\\), according to where we stopped in the\nmodeling procedure). \\(\\hat m\\) and \\(\\hat \\sigma _{\\hat m}\\) are the\nOrdinary Least Squares (OLS) estimates of the slope and its standard\ndeviation, respectively. These are the classical confidence intervals\nreported by the lm() function in R.\nAt a first glance, this procedure might look reasonable. After all, both\nintervals we may end up constructing do have a genuine 95% coverage probability,\nwhen constructed unconditionally‚Ä¶ and by selecting the ‚Äúbest‚Äù model we‚Äôre\nsupposedly choosing the ‚Äúbest‚Äù confidence interval. In spite of this qualitative\nargument, we inquire:\n‚Ä¶ does it work?\nNow, the question is: how often do the naive CIs (2)\ncover the true parameter \\(m\\) of Eq. (1)? The answer\nbetter be ‚Äúat least 95% of the times‚Äù for our confidence claim in Eq.\n(2) to be valid!\nWe can check the actual coverage of (2) through a simulation.\nHere I‚Äôll assume \\(m = \\sigma = 1\\), and that the\ndataset consists of \\(N=10\\) independent observations of \\(Y\\) at fixed points\n\\(X = (1, \\,2, \\,\\dots ,\\, 10)\\).\n\n\nm <- sigma <- 1  # True parameters\nx <- 1:10  # x covariate, assumed fixed\n\n\nThe following function generates observations of \\(Y\\) according to the distribution (1):\n\n\ngenerate_y <- function(x, m, sigma) {\n  eps <- rnorm(length(x), mean = 0, sd = sigma)\n  return(m * x + eps)\n  }\n\n\nFor example:\n\n\nset.seed(840)\nplot(x, generate_y(x, m, sigma), xlab = \"X\", ylab = \"Y\")\n\n\n\nBelow we generate \\(B=10^4\\) such \\((X,Y)\\) datasets, for each of which we fit a linear model according to the procedure specified above, and check how many\ntimes the true slope \\(m = 1\\) falls in the confidence interval defined by Eq. (2).\n\n\n# Simulation parameters\nB <- 1e4  # Number of replications\n\n# Preallocate logical vectors to be assigned for each replica - for efficiency. \nq_dropped <- logical(B)  # Was the intercept term 'q' dropped? \nm_covered <- logical(B)  # Was the true parameter 'm' covered?\n\n# Set seed for reproducibility\nset.seed(841)\n\n# Logging\ntime_start <- Sys.time()  \n\n# Start the simulation\nfor (b in 1:B) {\n  y <- generate_y(x, m, sigma)\n  \n  # Fit full model (including intercept 'q')\n  fit <- lm(y ~ x + 1)  \n  q_pval <- summary(fit)$coefficients[1, 4]\n  \n  # Is 'q' term \"significant\"? If not, drop 'q' and fit a simpler model\n  if (q_pval > 0.32)  { \n    q_dropped[[b]] <- TRUE\n    fit <- lm(y ~ x - 1) \n  } else {\n    q_dropped[[b]] <- FALSE\n  }\n  \n  # Construct CI for 'm',  using the selected model's fit\n  m_ci <- confint(fit, 'x', level = 0.95)\n  m_covered[[b]] <- m_ci[[1]] < m && m < m_ci[[2]]\n}\n\ntime_end <- Sys.time()\ncat(\"Done :) Took \", as.numeric(time_end - time_start), \" seconds.\")\n\nDone :) Took  12.12071  seconds.\n\nThe variable m_covered[[b]] is TRUE if the slope \\(m\\) fell in the\nnaive CI \\((m_-, m_+)\\) defined by Eq. (2) in the\nb-th replica of the simulation. Hence, the actual coverage fraction of\nthe CI is given by:\n\n\nmean(m_covered)  # Actual coverage of naive \"95%\" CIs.\n\n[1] 0.9172\n\n92%! If this difference from the nominal 95% coverage guarantee does not\nstrike you as enormous, think about it in these terms: the naive CIs\n(2) fail to cover the true parameter about 8% of the\ntimes; This is a relative +60% of failures with respect to an honest 95%\nCI.\nWhat‚Äôs going on\nWe can understand a bit better what‚Äôs happening here by decomposing the\ncoverage probability as follows:\n\\[\n\\text {Pr}(m \\in \\text{CI})  = \\text {Pr}(m \\in \\text{CI}_{q \\text{ dropped}}\\,\\vert\\,q \\text{ dropped})\\cdot \\text {Pr}(q \\text{ dropped}) +\\\\ +\\text {Pr}(m \\in \\text{CI}_{q  \\text{ kept}}\\,\\vert\\,q \\text{ kept})\\cdot \\text {Pr}(q \\text{ kept})\n\\tag{3}\n\\]\nThe right hand side of this equation shows how our selective modeling\nprocedure alters the probability \\(\\text{Pr}(m\\in \\text{CI})\\). There are\ntwo contributing factors here: the probability of dropping the intercept\nterm, and the covering probabilities of the CIs constructed in the two\ncases (\\(\\text{CI}_{q \\text{ dropped}}\\) and\n\\(\\text{CI}_{q \\text{ kept}}\\)). We can estimate all these\nprobabilities as:\n\n\nmean(q_dropped)  # Pr(q dropped)\n\n[1] 0.6782\n\nmean(m_covered[q_dropped])  # Pr(m covered | q dropped)\n\n[1] 0.9510469\n\nmean(m_covered[!q_dropped])  # Pr(m covered | q kept)\n\n[1] 0.845867\n\nThe first result directly follows from our procedure, which uses a\nhypothesis test with significance \\(\\alpha = 32\\%\\) to test the (true)\nnull hypothesis \\(q = 0\\). It is a bit harder but in fact possible to\nprove that4\n\\(\\text {Pr}(m \\in \\text{CI}_{q \\text{ dropped}}\\,\\vert\\,q \\text{ dropped}) = 95\\%\\),\nas the second estimate would seem to suggest. The third result is\nfinally what invalidates the naive coverage guarantee in Eq.\n(2).\nConcluding Remarks\nTo summarize:\nWe started with two linear models for \\(Y\\) vs.¬†\\(X\\), which were in fact both well-specified (that is, correct).\nWe stipulated to choose one of the two models by testing the null hypothesis \\(q = 0\\).\nAfter selection, we constructed \\(95\\%\\) confidence intervals for the slope\n\\(\\hat m\\) using the selected model, as if this had been fixed in advance.\nA simulation shows that such intervals have a true coverage probability of\n\\(\\approx 92\\%\\).\nThe mathematical explanation of the last result is provided by Eq. (3), while the (hopefully) plain English one in the introductory part of this post. I will conclude with a few parenthetical remarks.\nFirst, the selective procedure proposed here would likely hardly be applied in practice in such a simple situation5. However, one could easily think of a more complex scenario with multiple covariates, where eliminating redundant ones could turn out to be beneficial for interpretation (if not compulsory, if the number of covariates exceeds the sample size).\nSecond, in order to avoid cluttering the discussion with too much\ntechnicalities, I have deliberately chosen a quite special point in true-model space (\\(q = 0\\)). This implies that both fits with and without intercept estimate the same slope \\(m\\); this is a peculiar property of \\(q = 0\\), which would not be true in the general case \\(q \\in \\mathbb R\\). In general, we would have to carefully define the inferential targets for the \\(q=0\\) and \\(q \\in \\mathbb R\\) cases, in a differential manner.\nConclusion\nThat was all for today. In the next post, I will discuss some mathematical details\nregarding the formulation of the Selective Inference problem in model-building.\nFor those surviving down to the bottom of the funnel, my future plan is to\nreview some (valid) selective inference methods I found interesting, including:\nBenjamini-Yekutieli control of False Coverage Rate (Benjamini and Yekutieli 2005),\nPOSI bounds for marginal coverage (Berk et al. 2013),\nData Fission, an elegant generalization of good old data splitting (Leiner et al. 2021).\n‚Ä¶whatever cool stuff I may discover in the meantime.\nCiao!\n\n\n\nBenjamini, Yoav, and Daniel Yekutieli. 2005. ‚ÄúFalse Discovery Rate‚ÄìAdjusted Multiple Confidence Intervals for Selected Parameters.‚Äù Journal of the American Statistical Association 100 (469): 71‚Äì81.\n\n\nBerk, Richard, Lawrence Brown, Andreas Buja, Kai Zhang, and Linda Zhao. 2013. ‚ÄúValid Post-Selection Inference.‚Äù The Annals of Statistics, 802‚Äì37.\n\n\nIsidori, Gino, Davide Lancierini, Patrick Owen, and Nicola Serra. 2021. ‚ÄúOn the Significance of New Physics in b‚Üí S‚Ñì+ ‚Ñì- Decays.‚Äù Physics Letters B 822: 136644.\n\n\nLeiner, James, Boyan Duan, Larry Wasserman, and Aaditya Ramdas. 2021. ‚ÄúData Fission: Splitting a Single Data Point.‚Äù arXiv. https://doi.org/10.48550/ARXIV.2112.11079.\n\n\nShalizi, C. R. 2020. ‚ÄúPost-Model-Selection Inference.‚Äù 2020. http://bactra.org/notebooks/post-model-selection-inference.html.\n\n\nVrbik, Jan. 2020. ‚ÄúRegression Analysis (Lecture Notes).‚Äù 2020. http://spartan.ac.brocku.ca/~jvrbik/MATH3P82/notes.pdf.\n\n\nHere, in the ‚Äúextended family of models‚Äù, I‚Äôm also implicitly\naccounting for the multiplicity introduced by continuous model\nparameters and training parameters (also known as hyper-parameters).‚Ü©Ô∏é\nThe preferential method according to (Shalizi 2020), from which\nI borrowed the ‚Äúa-theoretical‚Äù description, and which I recommend as a starting point for literature review.‚Ü©Ô∏é\nThis is not to say that correctly accounting for Selective Inference is\nthe default in scientific practice. A relevant example from the field I come\nfrom (Particle Physics), is documented in this stimulating reference:\n(Isidori et al. 2021).‚Ü©Ô∏é\nI‚Äôm always amazed by the great deal of theory one can learn by\nrunning a dumb simulation, and trying to explain a posteriori what\nseems to be a too perfect result. Technically, this follows from the fact that the slope estimate\n\\(\\hat m\\) and residual sum of squares \\(\\text{RSS}\\) of the reduced\nmodel, and the \\(F\\)-statistic used to test \\(q = 0\\), are all\nindependent random variables under the same null hypothesis, here\ntrue by construction. All these facts are in turn consequences of\ngeneral theorems from linear model theory, see for example\n(Vrbik 2020, chap. 4)‚Ä¶ and, to be sure, it took me more than a single\nnight without sleep to figure all this out.‚Ü©Ô∏é\nAnd I‚Äôm actually not sure that, after properly taking into account Selective Inference, it would lead to a substantial gain in estimation accuracy, compared to simply fitting the possibly redundant model with intercept.‚Ü©Ô∏é\n",
    "preview": "posts/2022-10-18-posi/posi_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-11-14T19:30:52+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-11-13-kgrams-v012-released/",
    "title": "kgrams v0.1.2 on CRAN",
    "description": "kgrams: Classical k-gram Language Models in R.",
    "author": [
      {
        "name": "vgherard",
        "url": "https://vgherard.github.io"
      }
    ],
    "date": "2021-11-13",
    "categories": [
      "R"
    ],
    "contents": "\nSummary\nVersion v0.1.2 of my R package kgrams was just accepted by CRAN. This package provides tools for training and evaluating k-gram language models in R, supporting several probability smoothing techniques, perplexity computations, random text generation and more.\nShort demo\n\n\nlibrary(kgrams)\n# Get k-gram frequency counts from Shakespeare's \"Much Ado About Nothing\"\nfreqs <- kgram_freqs(kgrams::much_ado, N = 4)\n\n# Build modified Kneser-Ney 4-gram model, with discount parameters D1, D2, D3.\nmkn <- language_model(freqs, smoother = \"mkn\", D1 = 0.25, D2 = 0.5, D3 = 0.75)\n\n# Sample sentences from the language model at different temperatures\nset.seed(840)\nsample_sentences(model = mkn, n = 3, max_length = 10, t = 1)\n\n\n[1] \"i have studied eight or nine truly by your office [...] (truncated output)\"\n[2] \"ere you go : <EOS>\"                                                        \n[3] \"don pedro welcome signior : <EOS>\"                                         \n\nsample_sentences(model = mkn, n = 3, max_length = 10, t = 0.1)\n\n\n[1] \"i will not be sworn but love may transform me [...] (truncated output)\" \n[2] \"i will not fail . <EOS>\"                                                \n[3] \"i will go to benedick and counsel him to fight [...] (truncated output)\"\n\nsample_sentences(model = mkn, n = 3, max_length = 10, t = 10)\n\n\n[1] \"july cham's incite start ancientry effect torture tore pains endings [...] (truncated output)\"   \n[2] \"lastly gallants happiness publish margaret what by spots commodity wake [...] (truncated output)\"\n[3] \"born all's 'fool' nest praise hurt messina build afar dancing [...] (truncated output)\"          \n\nNEWS\nOverall Software Improvements\nThe package‚Äôs test suite has been greatly extended.\nImproved error/warning conditions for wrong arguments.\nRe-enabled compiler diagnostics as per CRAN policy (#19)\nAPI Changes\nverbose arguments now default to FALSE.\nprobability(), perplexity() and sample_sentences() are restricted to accept only language_model class objects as their model argument.\nNew features\nas_dictionary(NULL) now returns an empty dictionary.\nBug Fixes\nFixed bug causing .preprocess and .tknz_sent arguments to be ignored in process_sentences().\nFixed previously wrong defaults for max_lines and batch_size arguments in kgram_freqs.connection().\nAdded print method for class dictionary.\nFixed bug causing invalid results in dictionary() with batch processing and non-trivial size constraints on vocabulary size.\nOther\nMaintainer‚Äôs email updated\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-17T08:21:30+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-25-r-client-for-r-universe-apis/",
    "title": "R Client for R-universe APIs",
    "description": "Introducing W.I.P. {runiv}, an R package to interact with R-universe \nrepository APIs",
    "author": [
      {
        "name": "vgherard",
        "url": "https://vgherard.github.io"
      }
    ],
    "date": "2021-07-25",
    "categories": [
      "R"
    ],
    "contents": "\nIntroduction\nFollowing my previous post on how to use your R-universe API to automatically generate a list of the packages on your R-universe, I started working on a simple R client to interact with such APIs.\nFor those who missed it, R-universe is a new project from rOpenSci that allows you to mantain a personal CRAN-like repository, which automatically syncs with the GitHub repositories hosting your projects.\nAmong other features, each repository has associated a RESTful API with which users can interact for managing and retrieving informations about packages in the repo. Quoting R-universe:\n\nThe package server provides REST APIs for managing package submissions and querying information about individual packages as well as on the repository level. These data can be accessed programmatically or displayed in a front-end dashboard.\n\n{runiv}\nSince this has already proved to be useful to me (and could hopefully be so also to others), I started playing around to implement an R client for R-universe APIs. The package is called runiv and the code is here. Up to now, only a small subset of the full API features are available. You can peek at the development version from GitHub, using:\nremotes::install_github(\"vgherard/runiv\")\nFor instance, the procedure for obtaining your packages DESCRIPTION outlined in my previous post is performed by:\n\n\ndf <- runiv::runiv_descriptions(\"vgherard\") # 'vgherard' is my R-universe name.\n\n\n\ndf is a dataframe containing all the entries of the DESCRIPTION files of my packages:\n\n\ndf[, c(\"Package\", \"Title\")]\n\n\n   Package                                             Title\n1      r2r                    R-Object to R-Object Hash Maps\n2   kgrams                  Classical k-gram Language Models\n3 scribblr                          A Notepad Inside RStudio\n4  gsample   Efficient Weighted Sampling Without Replacement\n5      sbo Text Prediction via Stupid Back-Off N-Gram Models\n6     fcci              Feldman-Cousins Confidence Intervals\n\ndf[1, \"Description\"] |> strtrim(60) |> paste(\"[...]\")\n\n\n[1] \"Implementation of hash tables (hash sets and hash maps) in R [...]\"\n\nConclusion\nI hope you find this useful. I have very little experience with web API R packages (this was another personal reason to tackle this), so that if you have any suggestion, or maybe want to collaborate on runiv, you are welcome to reach out to me through GitHub.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-13T16:53:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api/",
    "title": "Automatic resumes of your R-developer portfolio from your R-Universe",
    "description": "Create automatic resumes of your R packages using the R-Universe API.",
    "author": [
      {
        "name": "vgherard",
        "url": "https://vgherard.github.io"
      }
    ],
    "date": "2021-07-21",
    "categories": [
      "R"
    ],
    "contents": "\nHi R-bloggers üëã\nStarting from today, all posts from this blog in the R category will also appear on R-bloggers. I would like to thank Tal for aggregating my blog, and say ‚Äúhi!‚Äù to all R-bloggers readers. I‚Äôm a particle physicist with a passion for R, Statistics and Machine Learning. If you want to find out something more about me, you can take a look at my website, and links therein.\nIntroduction\nR-universe is a cool initiative from rOpenSci, which allows you to create your own CRAN-like repository. The latter is synced with the GitHub repositories (main or specific branches, or releases) associated to your R packages, so that using an R-universe is a very effortless way to organize and share your personal package ecosystem.\nIf you want to setup your own R-universe, follow the instructions in this blog post. In this post, I assume that you have created your own R-universe, and show you how to retrieve metadata on your packages using the R-universe API.\nRetrieving packages descriptions from your R-universe API\nOnce you will have it set up, your R-universe will be available at the URL your-user-name.r-universe.dev. For instance, mine is vgherard.r-universe.dev. From your R-universe home page, you can access the documentation of the API. We will use the command:\nGET /stats/descriptions\n    NDJSON stream with data from package DESCRIPTION files.\nThe JSON stream can be read with jsonlite, as follows:\n\n\ncon <- url(\"https://vgherard.r-universe.dev/stats/descriptions\")\npkgs <- jsonlite::stream_in(con)\n\n\n\n Found 6 records...\n Imported 6 records. Simplifying...\n\nThe result is a dataframe with alll the entries of your packages‚Äô DESCRIPTION file, e.g.:\n\n\npkgs[, c(\"Package\", \"Title\", \"Version\")]\n\n\n   Package                                             Title\n1      r2r                    R-Object to R-Object Hash Maps\n2   kgrams                  Classical k-gram Language Models\n3 scribblr                          A Notepad Inside RStudio\n4  gsample   Efficient Weighted Sampling Without Replacement\n5      sbo Text Prediction via Stupid Back-Off N-Gram Models\n6     fcci              Feldman-Cousins Confidence Intervals\n     Version\n1 0.1.1.9000\n2      0.1.0\n3 0.2.0.9000\n4      0.1.0\n5      0.5.0\n6      1.0.0\n\nI use this query on my personal website to automatically generate a resume of the packages available on my R-universe (this is combined with a GitHub Action scheduled workflow which periodically updates the Code section of my website). More precisely, I define an R string txt containing the Markdown code for my resume, and I inline it in R Markdown using the synthax `r `. This is the code I use on my website:\n\n\ntxt <- \"\"\nfor (i in seq_len(nrow(pkgs))) {\n  txt <- paste0(\n    txt, \n    \"### [`\", pkgs[i, \"Package\"], \"`](\", pkgs[i, \"RemoteUrl\"], \")\", \"\\n\",\n    \"[![CRAN status](https://www.r-pkg.org/badges/version/\", pkgs[i,\"Package\"],\n    \")](https://CRAN.R-project.org/package=\",pkgs[i, \"Package\"], \")\",\n    \"\\n\\n\",\n    \"*\", pkgs[i, \"Title\"], \".* \", pkgs[i, \"Description\"],\n    \"\\n\\n\"\n    )\n}\n\n\n\nand this is the output:\nr2r\n\nR-Object to R-Object Hash Maps. Implementation of hash tables (hash sets and hash maps) in R, featuring arbitrary R objects as keys, arbitrary hash and key-comparison functions, and customizable behaviour upon queries of missing keys.\nkgrams\n\nClassical k-gram Language Models. Tools for training and evaluating k-gram language models in R, supporting several probability smoothing techniques, perplexity computations, random text generation and more.\nscribblr\n\nA Notepad Inside RStudio. A project aware notepad inside RStudio, for taking quick project-related notes without distractions. RStudio addin.\ngsample\n\nEfficient Weighted Sampling Without Replacement. Sample without replacement using the Gumbel-Max trick (c.f. ).\nsbo\n\nText Prediction via Stupid Back-Off N-Gram Models. Utilities for training and evaluating text predictors based on Stupid Back-Off N-gram models (Brants et al., 2007, https://www.aclweb.org/anthology/D07-1090/).\nfcci\n\nFeldman-Cousins Confidence Intervals. Provides support for building Feldman-Cousins confidence intervals [G. J. Feldman and R. D. Cousins (1998) doi:10.1103/PhysRevD.57.3873].\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-13T16:53:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-06-r2r/",
    "title": "{r2r} now on CRAN",
    "description": "Introducing {r2r}, an R implementation of hash tables.",
    "author": [
      {
        "name": "vgherard",
        "url": {}
      }
    ],
    "date": "2021-07-06",
    "categories": [
      "R"
    ],
    "contents": "\nIntroduction\nMy package {r2r} (v0.1.1) has been accepted by CRAN, and is now available for download from the public repository.\nr2r\n\n   \nr2r provides a flexible implementation of hash tables in R, allowing for:\narbitrary R objects as keys and values,\narbitrary key comparison and hash functions,\ncustomizable behaviour (throw or return a default value) on missing key exceptions.\nInstallation\nYou can install the released version of r2r from CRAN with:\ninstall.packages(\"r2r\")\nand the development version from my R-universe repository, with:\ninstall.packages(\"r2r\", repos = \"https://vgherard.r-universe.dev\")\nUsage\n\n\nlibrary(r2r)\nm <- hashmap()\n\n# Insert and query a single key-value pair\nm[[ \"user\" ]] <- \"vgherard\"\nm[[ \"user\" ]]\n\n\n[1] \"vgherard\"\n\n# Insert and query multiple key-value pairs\nm[ c(1, 2, 3) ] <- c(\"one\", \"two\", \"three\")\nm[ c(1, 3) ]\n\n\n[[1]]\n[1] \"one\"\n\n[[2]]\n[1] \"three\"\n\n# Keys and values can be arbitrary R objects\nm[[ lm(mpg ~ wt, mtcars) ]] <- c(TRUE, FALSE, TRUE)\nm[[ lm(mpg ~ wt, mtcars) ]]\n\n\n[1]  TRUE FALSE  TRUE\n\nGetting help\nFor further details, including an introductory vignette illustrating the features of r2r hash maps, you can consult the r2r website. If you encounter a bug, want to suggest a feature or need further help, you can open a GitHub issue.\nComparison with hash\nCRAN package {hash} also offers an implementation of hash tables based on R environments. The two tables below offer a comparison between {r2r} and {hash} (for more details, see the benchmarks Vignette)\n\nTable 1: Features supported by {r2r} and {hash}.\nFeature\nr2r\nhash\nBasic data structure\nR environment\nR environment\nArbitrary type keys\nX\n\nArbitrary type values\nX\nX\nArbitrary hash function\nX\n\nArbitrary key comparison function\nX\n\nThrow or return default on missing keys\nX\n\nHash table inversion\n\nX\n\n\nTable 2: Performances of {r2r} and {hash} for basic hash table operations.\nTask\nComparison\nKey insertion\n{r2r} ~ {hash}\nKey query\n{r2r} < {hash}\nKey deletion\n{r2r} << {hash}\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-13T16:53:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-06-test-post/",
    "title": "Test post",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "vgherard",
        "url": {}
      }
    ],
    "date": "2021-07-06",
    "categories": [
      "Other"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-13T16:53:50+01:00",
    "input_file": {}
  }
]

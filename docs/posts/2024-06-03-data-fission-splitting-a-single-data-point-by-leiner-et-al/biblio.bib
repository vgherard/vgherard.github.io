@article{datafission,
	author = {James Leiner, Boyan Duan, Larry Wasserman and Aaditya Ramdas},
	title = {Data Fission: Splitting a Single Data Point},
	journal = {Journal of the American Statistical Association},
	volume = {0},
	number = {0},
	pages = {1--12},
	year = {2023},
	publisher = {Taylor \& Francis},
	doi = {10.1080/01621459.2023.2270748},
	URL = {https://doi.org/10.1080/01621459.2023.2270748},
	eprint = {https://doi.org/10.1080/01621459.2023.2270748},
}

@article{splittingstrategies,
    author = {Rasines, D Garc√≠a and Young, G A},
    title = "{Splitting strategies for post-selection inference}",
    journal = {Biometrika},
    volume = {110},
    number = {3},
    pages = {597-614},
    year = {2022},
    month = {12},
    abstract = "{We consider the problem of providing valid inference for a selected parameter in a sparse regression setting. It is well known that classical regression tools can be unreliable in this context because of the bias generated in the selection step. Many approaches have been proposed in recent years to ensure inferential validity. In this article we consider a simple alternative to data splitting based on randomizing the response vector, which allows for higher selection and inferential power than the former, and is applicable with an arbitrary selection rule. We perform a theoretical and empirical comparison of the two methods and derive a central limit theorem for the randomization approach. Our investigations show that the gain in power can be substantial.}",
    issn = {1464-3510},
    doi = {10.1093/biomet/asac070},
    url = {https://doi.org/10.1093/biomet/asac070},
    eprint = {https://academic.oup.com/biomet/article-pdf/110/3/597/51111504/asac070\_supplementary\_data.pdf},
}




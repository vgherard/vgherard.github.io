<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>Valerio Gherardi</title>
    <link>https://vgherard.github.io/</link>
    <atom:link href="https://vgherard.github.io/index.xml" rel="self" type="application/rss+xml"/>
    <description>Valerio Gherardi
</description>
    <generator>Distill</generator>
    <lastBuildDate>2023-07-10</lastBuildDate>
    <item>
      <title>Testing functional specification in linear regression</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression</link>
      <description>


&lt;p&gt;Another one from the series on “misspecified regression models”
(started with &lt;a
href="https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches/"&gt;Model
Misspecification and Linear Sandwiches&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;Lately I’ve been messing around with the &lt;a
href="https://cran.r-project.org/web/packages/lmtest/index.html"&gt;&lt;code&gt;{lmtest}&lt;/code&gt;&lt;/a&gt;
R package, a nice collection of hypothesis tests for classical linear
model assumptions: &lt;em&gt;linearity&lt;/em&gt; (of course) and
&lt;em&gt;heteroskedasticity&lt;/em&gt; (&lt;span
class="math inline"&gt;\(X\)&lt;/span&gt;-independence of the conditional
variance).&lt;/p&gt;
&lt;p&gt;Just to clarify, here the relevant “linearity” assumption is that the
conditional mean &lt;span class="math inline"&gt;\(\mathbb E (Y\vert
X)\)&lt;/span&gt; is given by a linear combination of &lt;em&gt;known functions&lt;/em&gt;
&lt;span class="math inline"&gt;\(f_i\)&lt;/span&gt; of &lt;span
class="math inline"&gt;\(X\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E (Y\vert X) = \sum _{i = 1}^p \alpha_if_i(X),
\]&lt;/span&gt; Testing “linearity” (or, as the title goes, “functional
specification”) refers to testing that the chosen set of functions &lt;span
class="math inline"&gt;\(\{f_{i}\}_{i=1,\dots,p}\)&lt;/span&gt; provide a valid
description of the data generating process.&lt;/p&gt;
&lt;h2 id="first-attempt-residual-autocorrelation"&gt;First attempt: residual
autocorrelation&lt;/h2&gt;
&lt;p&gt;My initial intuition was that it should be possible to test
functional specification through the following procedure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Perform linear regression with the specified functional form.&lt;/li&gt;
&lt;li&gt;Order the residuals according to the corresponding values of &lt;span
class="math inline"&gt;\(X\)&lt;/span&gt;&lt;a href="#fn1" class="footnote-ref"
id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Test for serial correlation (e.g. performing a Durbin-Watson test,
&lt;code&gt;lmtest::dwtest&lt;/code&gt;) on the series of ordered residuals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The idea is quite simple: if residuals exhibit some systematic
pattern when plotted against &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;,
then for close values of &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;,
residuals should also tend to be close, leading to a positive
correlation. For example:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;set.seed(840)
x &amp;lt;- rnorm(1e2)
y &amp;lt;- x^3 + rnorm(length(x))
plot(x, y)
abline(lm(y ~ x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1b362dd97bfe_files/figure-html/unnamed-chunk-1-1.png" width="672" /&gt;
This, I suspect, is the reason why functions such as
&lt;code&gt;lmtest::dwtest()&lt;/code&gt; have an &lt;code&gt;order.by&lt;/code&gt; argument
which precisely allows to sort residuals before performing the test.&lt;/p&gt;
&lt;p&gt;Unfortunately, it turns out that such a method is not only sensitive
to functional misspecification, but also to heteroskedasticity - as one
can quickly verify by running a simulation using
&lt;code&gt;lmtest::dwtest()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The overall idea is interesting, and works for homoskedastic noise,
but the limitation to constant variance may be a bit too stringent. For
this reason I turned to a second method, which also allows to take into
account the possibility of heteroskedastic noise.&lt;/p&gt;
&lt;h2
id="second-attempt-reset-heteroskedastic-consistent-variance-estimates"&gt;Second
attempt: RESET + Heteroskedastic Consistent variance estimates&lt;/h2&gt;
&lt;p&gt;The idea of RESET tests (see &lt;code&gt;?lmtest::resettest()&lt;/code&gt;) is
also quite simple: if the linear model is correct, there should be
relatively little gain in adding additional non-linear functions of the
original covariates to the fit’s formula.&lt;/p&gt;
&lt;p&gt;The statistical significance of these model adjustments can be tested
through a standard &lt;span class="math inline"&gt;\(Z\)&lt;/span&gt;-test (or &lt;span
class="math inline"&gt;\(F\)&lt;/span&gt;-test, for multiple adjustments at
once), with an important catch: the covariance matrix of regression
coefficients used in these tests can be chosen to be robust to
heteroskedasticity (see &lt;a
href="https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches/"&gt;Model
Misspecification and Linear Sandwiches&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The code that follows illustrates this procedure with an example
dataset. The following section contains a more in-depth simulation study
of the property of the RESET test.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fit_cars &amp;lt;- lm(dist ~ speed, data = cars)
with(data = cars, plot(speed, dist))
abline(fit_cars)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1b362dd97bfe_files/figure-html/fit_cars-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;lmtest::resettest(fit_cars, 
                                    type = &amp;quot;regressor&amp;quot;, 
                                    power = 2,
                                    vcov = sandwich::vcovHC
                                    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    RESET test

data:  fit_cars
RESET = 2.32, df1 = 1, df2 = 48, p-value = 0.1344&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, the output of &lt;code&gt;lmtest::resettest&lt;/code&gt; does not
include the results of the extended fit, which can be useful to
understand the &lt;em&gt;impact&lt;/em&gt; of the omitted covariates on the overall
model picture (independently of the RESET &lt;span
class="math inline"&gt;\(p\)&lt;/span&gt;-value under the null hypothesis). &lt;a
href="#fn2" class="footnote-ref" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In order to get some insight on the effect of misspecification, we
need to manually perform the RESET fit and make the relevant
comparisons:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fit_cars_sq &amp;lt;- lm(dist ~ speed + I(speed*speed), data = cars)
with(data = cars, plot(speed, dist))
abline(fit_cars)
lines(x = cars$speed, y = fitted(fit_cars_sq), col = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1b362dd97bfe_files/figure-html/fit_cars_sq-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="reset-hc-vcov-a-simulation-study"&gt;RESET + HC vcov: a simulation
study&lt;/h2&gt;
&lt;p&gt;We consider a univariate regression problem, with a regressor &lt;span
class="math inline"&gt;\(X \sim \mathcal N (0,1)\)&lt;/span&gt;, a and a response
&lt;span class="math inline"&gt;\(Y\)&lt;/span&gt;. We will consider three ground
truth distributions for &lt;span class="math inline"&gt;\(Y\)&lt;/span&gt; given
&lt;span class="math inline"&gt;\(X\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\begin{split}
\text{T1}:&amp;amp; \qquad Y=\frac{1}{5}X+Z\\
\text{T2}:&amp;amp; \qquad Y=\frac{1}{5}X + \vert X \vert Z\\
\text{T3}:&amp;amp; \qquad Y=\frac{1}{5}X^3 + Z
\end{split}
\]&lt;/span&gt; where &lt;span class="math inline"&gt;\(Z\sim \mathcal N
(0,1)\)&lt;/span&gt; is independent from &lt;span
class="math inline"&gt;\(X\)&lt;/span&gt;. We will study, through simulation, the
&lt;span class="math inline"&gt;\(p\)&lt;/span&gt;-value distribution of the RESET
test for linear regression based on the model &lt;span
class="math inline"&gt;\(Y = q+m X + \varepsilon\)&lt;/span&gt;, where &lt;span
class="math inline"&gt;\(q\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(m\)&lt;/span&gt; are unknown coefficients, and &lt;span
class="math inline"&gt;\(\epsilon\)&lt;/span&gt; is a noise term with unknown
variance. It follows that the model is correctly specified with respect
to &lt;span class="math inline"&gt;\(\text{T1}\)&lt;/span&gt;, has functional
misspecification with respect to &lt;span
class="math inline"&gt;\(\text{T3}\)&lt;/span&gt;, and potentially noise
misspecification&lt;a href="#fn3" class="footnote-ref"
id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; with respect to &lt;span
class="math inline"&gt;\(\text{T2}\)&lt;/span&gt;, if we model variance as being
independent of &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Data will consist of independent samples &lt;span
class="math inline"&gt;\((X_i, Y_i)\)&lt;/span&gt; from the joint distribution of
&lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(Y\)&lt;/span&gt;. To facilitate simulation, we define
some helpers in the code chunk below.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;#&amp;#39; Helper to generate data with prescribed: 
#&amp;#39; * Regressor distribution: `x`
#&amp;#39; * Response conditional mean: `f`
#&amp;#39; * Response conditional noise: `eps` 
dgp_fun &amp;lt;- function(x, f, eps) {
    function(n) {
        .x &amp;lt;- x(n)
        data.frame(x = .x, y = f(.x) + eps(.x))
    }
}

#&amp;#39; Helper to simulate results of linear regression, with prescribed:
#&amp;#39; * Data generating process: `dgp`
#&amp;#39; * Sample size of simulated datasets: `n`
#&amp;#39; * Summary function (e.g. p-value of RESET test): `summarize_fun`
lm_simulate &amp;lt;- function(dgp, n, summarize_fun, nsim, simplify) {
    replicate(nsim, {
        data &amp;lt;- dgp(n)
        fit &amp;lt;- lm(y ~ x, data)
        summarize_fun(fit)
    }, simplify = simplify)
} 

#&amp;#39; Helper to perform RESET test on a `lm` fit object, and plot the p-value
#&amp;#39; distribution. The estimator for regression coefficients variance-covariance
#&amp;#39; matrix can be set through the `vcov` argument.
reset_pvalue &amp;lt;- function(
        dgp, n,  # Data generating process params
        power = 2:3, type = &amp;quot;regressor&amp;quot;, vcov = sandwich::vcovHC,  # RESET params
        nsim = 1e3  # Simulation params
        ) 
{
    summarize_fun &amp;lt;- function(fit)
        lmtest::resettest(fit, power = power, type = type, vcov = vcov)$p.value
    
    p &amp;lt;- lm_simulate(
        dgp = dgp, 
        n = n, 
        summarize_fun = summarize_fun, 
        nsim = nsim,
        simplify = TRUE
        )
    
    return(data.frame(
        p = p,
        dgp = deparse(substitute(dgp)),
        n = n,
        vcov = deparse(substitute(vcov)),
        nsim = nsim
    ))
    
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Furthermore, we will use:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(dplyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for plotting.&lt;/p&gt;
&lt;h3 id="data-generating-processes"&gt;Data generating processes&lt;/h3&gt;
&lt;p&gt;The data generating processes can be defined as follows:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;dgp_t1 &amp;lt;- dgp_fun(
    x = rnorm,
    f = \(x) 0.2 * x,
    eps = \(x) rnorm(length(x))
)

dgp_t2 &amp;lt;- dgp_fun(
    x = rnorm,
    f = \(x) 0.2 * x,
    eps = \(x) abs(x) * rnorm(length(x))
)

dgp_t3 &amp;lt;- dgp_fun(
    x = rnorm,
    f = \(x) 0.2 * x^3,
    eps = \(x) rnorm(length(x))
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Data generated according to these three distributions looks as
follows:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;bind_rows(
    tibble(dgp_t1(100), dgp = &amp;quot;dgp_t1&amp;quot;),
    tibble(dgp_t2(100), dgp = &amp;quot;dgp_t2&amp;quot;),
    tibble(dgp_t3(100), dgp = &amp;quot;dgp_t3&amp;quot;),
    ) |&amp;gt;
    ggplot(aes(x = x, y = y)) +
        geom_point() +
        geom_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x, se = F) +
        facet_grid(~ dgp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1b362dd97bfe_files/figure-html/unnamed-chunk-2-1.png" width="672" /&gt;
### RESET &lt;span class="math inline"&gt;\(p\)&lt;/span&gt;-value distributions&lt;/p&gt;
&lt;p&gt;The RESET &lt;span class="math inline"&gt;\(p\)&lt;/span&gt;-value cumulative
distributions for the three ground truths &lt;span
class="math inline"&gt;\(\text{T1}\)&lt;/span&gt;, &lt;span
class="math inline"&gt;\(\text{T2}\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\text{T3}\)&lt;/span&gt; are shown below &lt;a href="#fn4"
class="footnote-ref" id="fnref4"&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. The &lt;span
class="math inline"&gt;\(y\)&lt;/span&gt; coordinates of these plots can be
interpreted as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;For the ground truths &lt;span
class="math inline"&gt;\(\text{T1}\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\text{T2}\)&lt;/span&gt;, &lt;span
class="math inline"&gt;\(y\)&lt;/span&gt; represents the false positive rate (or
Type I Error Rate) in rejecting the null hypothesis “no functional
misspecification” at a given size of the test &lt;span
class="math inline"&gt;\(x\)&lt;/span&gt;. For a valid &lt;span
class="math inline"&gt;\(p\)&lt;/span&gt;-value, these curves should lie on or
below the straight line &lt;span class="math inline"&gt;\(y =
x\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For the ground truth &lt;span
class="math inline"&gt;\(\text{T3}\)&lt;/span&gt;, &lt;span
class="math inline"&gt;\(y\)&lt;/span&gt; represents the Power (or one minus the
Type II Error Rate) in detecting functional misspecification at a given
size &lt;span class="math inline"&gt;\(x\)&lt;/span&gt;. High values correspond to
high sensitivity.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;sim_data &amp;lt;- dplyr::bind_rows(
    reset_pvalue(dgp = dgp_t1, n = 10, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t1, n = 100, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t1, n = 1000, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t1, n = 10000, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t1, n = 10, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t1, n = 100, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t1, n = 1000, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t1, n = 10000, vcov = stats::vcov),
    
    reset_pvalue(dgp = dgp_t2, n = 10, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t2, n = 100, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t2, n = 1000, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t2, n = 10000, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t2, n = 10, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t2, n = 100, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t2, n = 1000, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t2, n = 10000, vcov = stats::vcov),
    
    reset_pvalue(dgp = dgp_t3, n = 10, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t3, n = 100, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t3, n = 1000, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t3, n = 10000, vcov = sandwich::vcovHC),
    reset_pvalue(dgp = dgp_t3, n = 10, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t3, n = 100, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t3, n = 1000, vcov = stats::vcov),
    reset_pvalue(dgp = dgp_t3, n = 10000, vcov = stats::vcov)
)

sim_data |&amp;gt;
    mutate(n_label = paste(&amp;quot;n&amp;quot;, n, sep = &amp;quot; = &amp;quot;)) |&amp;gt;
    ggplot(aes(p, color = vcov)) + 
        stat_ecdf() +
        scale_color_discrete(&amp;quot;vcov&amp;quot;) + 
        scale_x_continuous(&amp;quot;p-value&amp;quot;, labels = scales::percent) + 
        scale_y_continuous(&amp;quot;Empirical CDF&amp;quot;, labels = scales::percent) +
        geom_abline(slope = 1, intercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
        facet_grid(n_label ~ dgp, ) +
        ggtitle(
            &amp;quot;p-value distribution of RESET test&amp;quot;,
            paste(&amp;quot;nsim&amp;quot;, max(sim_data$nsim), sep = &amp;quot; = &amp;quot;)
            )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1b362dd97bfe_files/figure-html/unnamed-chunk-3-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;The plots illustrate qualitatively the behavior of the RESET test
with and without the &lt;code&gt;vcov&lt;/code&gt; correction for noise
heteroskedasticity. Various remarks:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;The test with the standard &lt;code&gt;stats::vcov&lt;/code&gt; estimator is
sensitive not only to pure functional misspecification (&lt;span
class="math inline"&gt;\(\text{T3}\)&lt;/span&gt;), but also to pure
heteroskedastic noise (&lt;span
class="math inline"&gt;\(\text{T2}\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;sandwich::vcovHC&lt;/code&gt; estimator leads to an
asymptotically correct Type I Error Rate in the &lt;span
class="math inline"&gt;\(\text{T2}\)&lt;/span&gt; case, but to a somewhat lower
sensitivity (with respect to &lt;code&gt;stats::vcov&lt;/code&gt;) in the &lt;span
class="math inline"&gt;\(\text{T3}\)&lt;/span&gt; case.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We need to keep in mind that &lt;code&gt;sandwich::vcovHC&lt;/code&gt; only
provides &lt;em&gt;asymptotically&lt;/em&gt; correct variance-covariance estimates.
Thus, for small &lt;span class="math inline"&gt;\(n\)&lt;/span&gt;, the &lt;span
class="math inline"&gt;\(p\)&lt;/span&gt;-value distribution of the RESET test
using the &lt;code&gt;sandwich::vcovHC&lt;/code&gt; can also be distorted (even in
the perfectly specified case &lt;span
class="math inline"&gt;\(\text{T1}\)&lt;/span&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="conclusions"&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;This post explained how to perform model validation checks that are
sensitive to functional misspecification, but relatively robust to
heteroskedasticity.&lt;/p&gt;
&lt;p&gt;The general idea is to extend the original model, allowing for more
general functional forms in the conditional mean of the response, and
test whether such extension significantly improves the fit. The catch is
that, when performing the latter test, we need to somehow keep into
account the possibility of heteroskedastic noise.&lt;/p&gt;
&lt;p&gt;This idea is readily implemented with RESET tests for linear models:
one can simply use a variance-covariance estimator for regression
coefficients that is robust to heteroskedasticity. In R, this can be
achieved with a single line of code, using
&lt;code&gt;lmtest::resettest(vcov = sandwich::vcovHC)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;With some effort, one may be able to generalize such a procedure to
any parametric model fitted by Maximum Likelihood Estimation, since a
sandwich estimator is available also in this more general case (see
&lt;em&gt;e.g.&lt;/em&gt; the presentation of sandwich estimators in this &lt;a
href="https://www.tandfonline.com/doi/abs/10.1198/000313006X152207"&gt;paper
by D.A. Freedman&lt;/a&gt;).&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div class="footnotes footnotes-end-of-document"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;Here I’m implicitly assuming that we have a single &lt;span
class="math inline"&gt;\(X\)&lt;/span&gt;, but a similar logic should also apply
to multivariate regression.&lt;a href="#fnref1"
class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;With enough data, the RESET test would likely test
positive for a variety of misspecifications, but that doesn’t mean that
such misspecification are necessarily relevant from a modeling
perspective. Here, for instance, a large coefficient for &lt;span
class="math inline"&gt;\(\text{(speed)}^2\)&lt;/span&gt; with a &lt;span
class="math inline"&gt;\(Z\)&lt;/span&gt;-score of two &lt;span
class="math inline"&gt;\(\sigma\)&lt;/span&gt;s could be more worrying than a
minuscule coefficient with a &lt;span
class="math inline"&gt;\(Z\)&lt;/span&gt;-score of five &lt;span
class="math inline"&gt;\(\sigma\)&lt;/span&gt;s.&lt;a href="#fnref2"
class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;Sometimes also referred to as “second order
misspecification”.&lt;a href="#fnref3" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn4"&gt;&lt;p&gt;The code is a bit unelegant 😬 but it works.&lt;a
href="#fnref4" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5 xmlns:distill="https://distill.pub/journal/">ec69dd9e2d1bad604fb3d8d7b407895e</distill:md5>
      <category>Statistics</category>
      <category>Model Misspecification</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression</guid>
      <pubDate>2023-07-10</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression_files/figure-html5/unnamed-chunk-1-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Linear regression with autocorrelated noise</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise</link>
      <description>Effects of noise autocorrelation on linear regression. Explicit formulae and a simple simulation.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Time Series</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise</guid>
      <pubDate>2023-05-25</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise_files/figure-html5/unnamed-chunk-2-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Model Misspecification and Linear Sandwiches</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches</link>
      <description>Being wrong in the right way. With R excerpts.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches</guid>
      <pubDate>2023-05-14</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches_files/figure-html5/unnamed-chunk-7-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>How to get away with selection. Part I: Introduction</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2022-10-18-posi</link>
      <description>Introducing the problem of Selective Inference, illustrated through a simple simulation in R.</description>
      <category>Statistics</category>
      <category>Selective Inference</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2022-10-18-posi</guid>
      <pubDate>2022-11-14</pubDate>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://vgherard.github.io/posts/2022-10-18-posi/posi_files/figure-html5/unnamed-chunk-3-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>kgrams v0.1.2 on CRAN</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2021-11-13-kgrams-v012-released</link>
      <description>kgrams: Classical k-gram Language Models in R.</description>
      <category>Natural Language Processing</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-11-13-kgrams-v012-released</guid>
      <pubDate>2021-11-13</pubDate>
    </item>
    <item>
      <title>R Client for R-universe APIs</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-25-r-client-for-r-universe-apis</link>
      <description>Introducing W.I.P. {runiv}, an R package to interact with R-universe 
repository APIs</description>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-25-r-client-for-r-universe-apis</guid>
      <pubDate>2021-07-25</pubDate>
    </item>
    <item>
      <title>Automatic resumes of your R-developer portfolio from your R-Universe</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api</link>
      <description>Create automatic resumes of your R packages using the R-Universe API.</description>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api</guid>
      <pubDate>2021-07-21</pubDate>
    </item>
    <item>
      <title>{r2r} now on CRAN</title>
      <dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vgherard</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-06-r2r</link>
      <description>Introducing {r2r}, an R implementation of hash tables.</description>
      <category>Data Structures</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-06-r2r</guid>
      <pubDate>2021-07-06</pubDate>
    </item>
  </channel>
</rss>

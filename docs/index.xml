<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>vgherard</title>
    <link>https://vgherard.github.io/</link>
    <atom:link href="https://vgherard.github.io/index.xml" rel="self" type="application/rss+xml"/>
    <description>Valerio Gherardi's Personal Website
</description>
    <generator>Distill</generator>
    <lastBuildDate>Thu, 16 May 2024 00:00:00 +0000</lastBuildDate>
    <item>
      <title>AIC in the well-specified linear model: theory and simulation</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation</link>
      <description>


&lt;h2 id="theory"&gt;Theory&lt;/h2&gt;
&lt;h3 id="aic"&gt;AIC&lt;/h3&gt;
&lt;p&gt;Consider the AIC for the usual linear model &lt;span
class="math inline"&gt;\(Y = X\beta + \varepsilon\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{AIC} = \frac{1}{2}\ln(2\pi e\hat \sigma^2)+\frac{p+1}{N}
(\#eq:AIC)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class="math inline"&gt;\(p\)&lt;/span&gt; is the dimension of the
covariate vector &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\hat \sigma ^2\)&lt;/span&gt; is the ML estimate of the
&lt;span class="math inline"&gt;\(Y\vert X\)&lt;/span&gt; conditional variance. The
expectation of @ref(eq:AIC) under model assumptions can be found by
using the fact that, for a &lt;span class="math inline"&gt;\(\chi^2\)&lt;/span&gt;
random variable with &lt;span class="math inline"&gt;\(\nu\)&lt;/span&gt; degrees of
freedom&lt;a href="#fn1" class="footnote-ref"
id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E(\ln\chi ^2 )=\ln2+ \psi(\frac{\nu}{2})(\#eq:ElogX2)
\]&lt;/span&gt; where: &lt;span class="math display"&gt;\[
\psi(x)\equiv\frac{\text d}{\text d x}\ln \Gamma(x) \approx \ln
x-\frac{1}{2x}(\#eq:PsiFun)
\]&lt;/span&gt; and the second equality results from the Stirling
approximation &lt;span class="math inline"&gt;\(\Gamma(x) =
\sqrt{2\pi}x^{x-\frac{1}{2}}e^{-x}\)&lt;/span&gt;. We obtain:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E(\text{AIC}) = \frac{\ln \left[2\pi e\mathbb V(Y\vert X)\right]
}{2}+\frac{1}{2}\ln\left(\frac{N-p}{2}\right)-\frac{1}{2}\frac{1}{N-p}+\frac{p+1}{N},(\#eq:EAIC)
\]&lt;/span&gt; where, according to standard assumptions, &lt;span
class="math inline"&gt;\(\mathbb V(Y \vert X)\)&lt;/span&gt; is assumed to be
constant in &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now consider two such models, with different covariate vectors &lt;span
class="math inline"&gt;\(X_1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(X_2\)&lt;/span&gt;, of dimension &lt;span
class="math inline"&gt;\(p_1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(p_2\)&lt;/span&gt; respectively, both assumed to be well
specified. Denote, as before:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{AIC}_i =\frac{1}{2}\ln(2\pi e\hat \sigma^2_i)+\frac{p_i+1}{N}
(\#eq:AICi)
\]&lt;/span&gt; for &lt;span class="math inline"&gt;\(i = 1,\,2\)&lt;/span&gt;. Equation
@ref(eq:EAIC) gives the unconditional expectation of &lt;span
class="math inline"&gt;\(\text{AIC}\)&lt;/span&gt; for both models&lt;a href="#fn2"
class="footnote-ref" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, so that:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E(\text{AIC}_1 - \text{AIC}_2) =
\frac{1}{2}\ln\left(\frac{\mathbb V(Y\vert X_1)}{\mathbb V(Y\vert
X_2)}\right)+\frac{p_1-p_2}{2N}+\mathcal O(N^{-2})(\#eq:DeltaEAIC).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Assuming, without loss of generality, that &lt;span
class="math inline"&gt;\(p_1 \leq p_2\)&lt;/span&gt;, we have:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E(\text{AIC}_1 - \text{AIC}_2) &amp;lt; 0 \iff N &amp;lt;
\frac{p_2-p_1}{\ln\left(\frac{\mathbb V(Y\vert X_1)}{\mathbb V(Y\vert
X_2)}\right)}.(\#eq:AICCondition)
\]&lt;/span&gt; To gain some intuition, suppose that the set of variables
contained in &lt;span class="math inline"&gt;\(X_1\)&lt;/span&gt; is a subset of
those contained in &lt;span class="math inline"&gt;\(X_2\)&lt;/span&gt;, so that the
two corresponding models are nested. Eq. @ref(eq:AICCondition) tells us
that, for &lt;span class="math inline"&gt;\(N\)&lt;/span&gt; below a certain
threshold, AIC will prefer the more “parsimonious” model involving &lt;span
class="math inline"&gt;\(X_1\)&lt;/span&gt; only. In particular, if &lt;span
class="math inline"&gt;\(\mathbb V(Y\vert X_1)\approx \mathbb V(Y\vert
X_2)\)&lt;/span&gt;, we can make a first-order approximation in the RHS of Eq.
@ref(eq:AICCondition), that yields:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
N \lesssim \frac{\mathbb V(Y\vert X_2)}{\mathbb V(Y\vert X_1)-\mathbb
V(Y\vert X_2)}(p_2-p_1).(\#eq:AICConditionApprox)
\]&lt;/span&gt;&lt;/p&gt;
&lt;h3 id="cross-entropy"&gt;Cross-entropy&lt;/h3&gt;
&lt;p&gt;In parallel to AIC, we can consider the exact “information criterion”
provided by the model in-sample cross-entropy under the true data
generating process. For a single linear model, the in-sample
cross-entropy is:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{CE}_{\text {in}} = \frac{1}{2}\ln(2\pi e \hat \sigma ^2)
+\frac{1}{2}\frac{\sigma ^2-\hat \sigma
^2+\frac{1}{N}(\beta-\hat{\beta})^{T}\mathbf{X}^{T}\mathbf{X}(\beta-\hat{\beta})}{\hat
\sigma ^2}.(\#eq:InSampleCrossEntropy)
\]&lt;/span&gt; (“in-sample” refers to the fact that we fix, &lt;em&gt;i.e.&lt;/em&gt;
condition, on the covariate vector of the training sample, &lt;span
class="math inline"&gt;\(\mathbf X\)&lt;/span&gt;.) The &lt;span
class="math inline"&gt;\(\mathbf X\)&lt;/span&gt; conditional expectation of
&lt;span class="math inline"&gt;\(\text{CE}_{\text {in}}\)&lt;/span&gt;, again under
model assumptions, can be computed by noticing two facts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The numerator and denominator are conditionally independent &lt;span
class="math inline"&gt;\(\chi^2\)&lt;/span&gt; variables with &lt;span
class="math inline"&gt;\(p\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(N-p\)&lt;/span&gt; degrees of freedom respectively. This
can be seen by rewriting these as &lt;span
class="math inline"&gt;\(\boldsymbol \epsilon ^T \mathbf H \boldsymbol
\epsilon\)&lt;/span&gt;, and &lt;span class="math inline"&gt;\(\boldsymbol \epsilon
^T (1-\mathbf H) \boldsymbol \epsilon\)&lt;/span&gt;, respectively, where
&lt;span class="math inline"&gt;\(\mathbf H = \mathbf X (\mathbf X ^T \mathbf
X)^{-1} \mathbf X ^T\)&lt;/span&gt; as usual.&lt;/li&gt;
&lt;li&gt;For a &lt;span class="math inline"&gt;\(\chi ^2\)&lt;/span&gt; random variable
with &lt;span class="math inline"&gt;\(\nu\)&lt;/span&gt; degrees of freedom we have
&lt;span class="math inline"&gt;\(\mathbb E(\frac{1}{\chi ^2})=\frac{1}{\nu -
2}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using these results, we can show that:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E(\text{CE}_{\text {in}}\vert \mathbf X)=\mathbb
E(\text{AIC}\vert \mathbf X)+\mathcal O(N^{-2})(\#eq:AICvsCE)
\]&lt;/span&gt; (an equation which is true by design of AIC).&lt;/p&gt;
&lt;p&gt;Before rushing to the (wrong) conclusion that &lt;span
class="math inline"&gt;\(\text{AIC}_1 - \text{AIC}_2\)&lt;/span&gt; will
correspondingly estimate a difference of expected cross-entropies, let
us notice that the relevant in-sample cross-entropy to be considered for
model evaluation is Eq. @ref(eq:InSampleCrossEntropy) with &lt;span
class="math inline"&gt;\(\mathbf X\)&lt;/span&gt; &lt;em&gt;corresponding to the full
covariate vector&lt;/em&gt;: this is the target we should try to estimate (at
least to the extent that our goal is predicting &lt;span
class="math inline"&gt;\(Y\)&lt;/span&gt; given &lt;span
class="math inline"&gt;\(X\)&lt;/span&gt;). For this reason, strictly speaking,
Eq. @ref(eq:AICvsCE) is exact only if our model is well specified as a
model of &lt;span class="math inline"&gt;\(Y \vert X\)&lt;/span&gt;. Otherwise, in
order to estimate consistently &lt;span class="math inline"&gt;\(\mathbb
E(\text{CE}_{\text {in}}\vert \mathbf X)\)&lt;/span&gt;, we should use
Takeuchi’s Information Criterion (TIC) rather than AIC.&lt;/p&gt;
&lt;p&gt;A bit more pragmatically, in the real world we could assume the
remainder of @ref(eq:AICvsCE) to be &lt;span class="math inline"&gt;\(\mathcal
O (N^{-1})\)&lt;/span&gt; (rather than &lt;span class="math inline"&gt;\(\mathcal O
(N^{-2})\)&lt;/span&gt;), but generally small with respect the leading order
AIC correction (&lt;span class="math inline"&gt;\(\frac{p+1}{N}\)&lt;/span&gt;).
This will be the case if the models being compared are approximately
well specified.&lt;/p&gt;
&lt;h2 id="simulation"&gt;Simulation&lt;/h2&gt;
&lt;h3 id="setup"&gt;Setup&lt;/h3&gt;
&lt;p&gt;We take the data generating process to be:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
Y = m X + q + \varepsilon, (\#eq:DGPSim)
\]&lt;/span&gt; with:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
X \sim \mathcal N (0,\,1),\quad \varepsilon \sim \mathcal N(0,\,1),\quad
\varepsilon \perp X. (\#eq:DGPSim2)
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;m &amp;lt;- 0.1
q &amp;lt;- 0

rxy &amp;lt;- function(n) {
    tibble(
        x = rnorm(n, sd = 1),
        y = m * x + q + rnorm(n, sd = 1)
        )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We compare the model with &lt;em&gt;vs.&lt;/em&gt; without slope term (&lt;span
class="math inline"&gt;\(m = 0\)&lt;/span&gt; &lt;em&gt;vs.&lt;/em&gt; &lt;span
class="math inline"&gt;\(m \neq 0\)&lt;/span&gt;), which we will denote by
suffixes &lt;span class="math inline"&gt;\(1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(1\oplus X\)&lt;/span&gt;, respectively. The functions
below compute AIC and in-sample cross-entropy from the corresponding
&lt;code&gt;lm&lt;/code&gt; objects. We also define a “Naive Information Criterion”
&lt;span class="math inline"&gt;\(\text{NIC} \equiv \log(\hat
\sigma)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;nic &amp;lt;- function(fit) {
    p &amp;lt;- length(coef(fit))
    n &amp;lt;- nobs(fit)
    sigma_hat &amp;lt;- sigma(fit) * sqrt((n - p) / n)
    
    log(sigma_hat)
}

aic &amp;lt;- function(fit) {
    p &amp;lt;- length(coef(fit))
    n &amp;lt;- nobs(fit)
    sigma_hat &amp;lt;- sigma(fit) * sqrt((n - p) / n)
    
    log(sigma_hat) + (p + 1) / n + 0.5 *(1 + log(2*pi))
}

ce &amp;lt;- function(fit, data) {
    p &amp;lt;- length(coef(fit))
    n &amp;lt;- nobs(fit)
    sigma_hat &amp;lt;- sigma(fit) * sqrt((n - p) / n)
    y_hat &amp;lt;- fitted(fit)
    mu &amp;lt;- data$x * m + q
    
    res &amp;lt;- 0
    res &amp;lt;- res + 0.5 / (sigma_hat^2)
    res &amp;lt;- res + log(sigma_hat)
    res &amp;lt;- res + mean(0.5 * (y_hat - mu)^2 / (sigma_hat^2))
    res &amp;lt;- res + 0.5 * log(2 * pi)

    return(res)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From our results above, we expect:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E(\text{AIC}_{1\oplus X}-\text{AIC}_{1} )&amp;lt;0 \iff N \geq
\frac{1}{\ln(1+m^2)}\left(1+\mathcal O(m^2 )\right)(\#eq:DeltaEAICSim)
\]&lt;/span&gt; The expected in-sample cross-entropies cannot be computed
explicitly, but for relatively small &lt;span
class="math inline"&gt;\(m^2\)&lt;/span&gt; we expect (&lt;em&gt;cf.&lt;/em&gt; Eq.
@ref(eq:AICvsCE)):&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathbb E((\text{CE}_{\text {in}})_i)=\mathbb E(\text{AIC}_i)+\mathcal
O(N^{-2},\,m^2N^{-1}),(\#eq:AICvsCESim)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I will use tidyverse for plotting results.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(dplyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to make results reproducible let’s:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;set.seed(840)&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="results"&gt;Results&lt;/h3&gt;
&lt;p&gt;We simulate fitting models &lt;span class="math inline"&gt;\(1\)&lt;/span&gt; and
&lt;span class="math inline"&gt;\(1\oplus X\)&lt;/span&gt; at different sample sizes
from the data generating process described above.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fits &amp;lt;- tidyr::expand_grid(
        n = 10 ^ seq(from = 1, to = 3, by = 0.5), b = 1:1e3
        ) |&amp;gt;
    mutate(data = lapply(n, rxy)) |&amp;gt;
    group_by(n, b, data) |&amp;gt;
    tidyr::expand(model = c(y ~ 1, y ~ x)) |&amp;gt;
    ungroup() |&amp;gt;
    mutate(
        fit = lapply(row_number(), \(i) lm(model[[i]], data = data[[i]])),
        ce = sapply(row_number(), \(i) ce(fit[[i]], data[[i]])),
        aic = sapply(fit, aic),
        nic = sapply(fit, nic),
        model = format(model)
        ) |&amp;gt;
    select(-c(fit, data))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plots below show the dependence from sample size of &lt;span
class="math inline"&gt;\(\mathbb E(\Delta\text{AIC})\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\mathbb E(\Delta\text{CE}_\text{in})\)&lt;/span&gt;, as
well as AIC selection frequencies. Notice that for &lt;span
class="math inline"&gt;\(N = \frac{1}{m^2}\)&lt;/span&gt;, even though &lt;span
class="math inline"&gt;\(\mathbb E(\Delta\text{AIC}) = 0\)&lt;/span&gt;, the
selection frequency of the “complex” model &lt;span
class="math inline"&gt;\(1\oplus X\)&lt;/span&gt; is still below &lt;span
class="math inline"&gt;\(\text{50 %}\)&lt;/span&gt;. This is because the
distribution of &lt;span class="math inline"&gt;\(\Delta\text{AIC}\)&lt;/span&gt; is
asymmetric, as seen in the second plot, and &lt;span
class="math inline"&gt;\(\mathbb E(\Delta\text{AIC}) &amp;lt; \text
{median}(\Delta\text{AIC})\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fits |&amp;gt;
    mutate(
        is_baseline = model == &amp;quot;y ~ 1&amp;quot;,
        delta_ce = ce - ce[is_baseline], 
        delta_aic = aic - aic[is_baseline],
        delta_nic = nic - nic[is_baseline],
        .by = c(n, b),
        ) |&amp;gt;
    filter(!is_baseline) |&amp;gt;
    summarise(
        `E( ΔCE )` = mean(delta_ce), 
        `E( ΔAIC )` = mean(delta_aic),
        `E( ΔNIC )` = mean(delta_nic),
        .by = n
        ) |&amp;gt;
    tidyr::pivot_longer(
        -n, names_to = &amp;quot;metric&amp;quot;, values_to = &amp;quot;value&amp;quot;
    ) |&amp;gt;
    ggplot(aes(x = n, y = value, color = metric)) +
        geom_point() +
        geom_line() +
        geom_hline(yintercept = 0, linetype = &amp;quot;dashed&amp;quot;) +
        geom_vline(aes(xintercept = 1 / m^2), linetype = &amp;quot;dotted&amp;quot;) +
        scale_x_log10(&amp;quot;Sample Size&amp;quot;) +
        coord_cartesian(ylim = c(-0.025, 0.025)) + ylab(expression(IC)) +
        theme(legend.position = &amp;quot;bottom&amp;quot;, legend.title = element_blank()) +
        ggtitle(&amp;quot;AIC vs. in-sample cross-entropy&amp;quot;, &amp;quot;Expected values&amp;quot;) +
        NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file3efc21335166_files/figure-html/aic_exp-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fits |&amp;gt;
    filter(aic == min(aic), .by = c(n, b)) |&amp;gt;
    summarise(count = n(), .by = c(n, model)) |&amp;gt;
    ggplot(aes(fill = model, x = n, y = count)) + 
        geom_col() + 
        scale_x_log10(&amp;quot;Sample Size&amp;quot;) +
        ylab(&amp;quot;Count&amp;quot;) +
        theme(legend.position = &amp;quot;bottom&amp;quot;) +
        ggtitle(&amp;quot;AIC model selection frequencies&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file3efc21335166_files/figure-html/aic_freq-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fits |&amp;gt;
    filter(n %in% c(10, 100, 1000)) |&amp;gt;
    mutate(delta_aic = aic - aic[model == &amp;quot;y ~ 1&amp;quot;], .by = c(n, b)) |&amp;gt;
    filter(model != &amp;quot;y ~ 1&amp;quot;) |&amp;gt;
    mutate(expec = -0.5 * log(1 + m^2) + 0.5 / n) |&amp;gt;
    ggplot(aes(x = delta_aic, color = as.factor(n))) +
        geom_density() +
        coord_cartesian(xlim = c(-0.1, NA)) +
        labs(x = &amp;quot;ΔAIC&amp;quot;, y = &amp;quot;Density&amp;quot;, color = &amp;quot;Sample Size&amp;quot;) +
        ggtitle(&amp;quot;ΔAIC probability density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file3efc21335166_files/figure-html/aic_density-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, here is something I have no idea where it comes from. The
plot below shows the scatterplot of in-sample cross-entropy differences
&lt;em&gt;vs.&lt;/em&gt; the AIC differences. It is well known that AIC only
estimates the expectation of these differences, averaged over potential
training samples. One may ask whether AIC has anything to say about the
actual cross-entropy difference for the estimated models, conditional on
the realized training sample.&lt;/p&gt;
&lt;p&gt;Assuming I have made no errors here, the tilted-U shape of this
scatterplot is a clear negative answer. What’s especially interesting is
that, apparently, these differences have a negative correlation. I fail
to see where do the negative correlation and the U-shape come from.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;fits |&amp;gt; 
    filter(n == 100) |&amp;gt;
    mutate(
        is_baseline = model == &amp;quot;y ~ 1&amp;quot;,
        delta_ce = ce - ce[is_baseline], 
        delta_aic = aic - aic[is_baseline],
        .by = c(n, b),
        ) |&amp;gt;
    filter(!is_baseline) |&amp;gt;
    ggplot(aes(x = delta_aic, y = delta_ce)) +
        geom_point(size = 1, alpha = 0.2) +
        lims(x = c(-0.02, 0.01), y = c(-0.01, 0.03)) +
        labs(x = &amp;quot;ΔAIC&amp;quot;, y = &amp;quot;ΔCE&amp;quot;) +
        ggtitle(&amp;quot;AIC vs. in-sample cross-entropy&amp;quot;, &amp;quot;Point values for N = 100&amp;quot;) +
        NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file3efc21335166_files/figure-html/aic_vs_ce_2-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div class="footnotes footnotes-end-of-document"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt; See &lt;em&gt;e.g.&lt;/em&gt; &lt;a
href="https://arxiv.org/pdf/1503.06266"&gt;1503.06266&lt;/a&gt;&lt;a href="#fnref1"
class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;The same equation actually gives the expectation of
&lt;span class="math inline"&gt;\(\text{AIC}\)&lt;/span&gt; conditional to the
in-sample covariate vector &lt;span class="math inline"&gt;\(\mathbb
X\)&lt;/span&gt;. Since this conditioning differs for the two different models
involving &lt;span class="math inline"&gt;\(X_1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(X_2\)&lt;/span&gt;, in our comparison of expected values
we must interpret this as unconditional expectations, in general.&lt;a
href="#fnref2" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>54f1d77816eacb308a2b3468c68c9d88</distill:md5>
      <category>Model Selection</category>
      <category>Linear Models</category>
      <category>Regression</category>
      <category>Statistics</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation</guid>
      <pubDate>Thu, 16 May 2024 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation_files/figure-html5/aic_exp-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>"Annual adult survival rates for four sympatric breeding swallow species" by Imlay et al.</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-25-annual-adult-survival-rates-for-four-sympatric-breeding-swallow-species</link>
      <description>An obscure mark-recapture data analysis.</description>
      <category>Comment on...</category>
      <category>Population Dynamics</category>
      <category>Biology</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-04-25-annual-adult-survival-rates-for-four-sympatric-breeding-swallow-species</guid>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Grammar as a biometric for Authorship Verification</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification</link>
      <description>Notes on preprint 2403.08462 by A. Nini, O. Halvani, L. Graner, S. Ishihara 
and myself.</description>
      <category>Authorship Verification</category>
      <category>Natural Language Processing</category>
      <category>Forensic Science</category>
      <category>Machine Learning</category>
      <category>Statistics</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification</guid>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>"Induction and Deduction in Bayesian Data Analysis" by A. Gelman</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman</link>
      <description>On the importance of model checks in Bayesian data analysis.</description>
      <category>Comment on...</category>
      <category>Bayesian Methods</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman</guid>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>"The Abuse of Power" by J. M. Hoenig and D. M. Heisey</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey</link>
      <description>Why observed power calculations are useless (plus a few other points I don't buy).</description>
      <category>Comment on...</category>
      <category>Hypothesis Testing</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey</guid>
      <pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>AIC for the linear model: known vs. unknown variance</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance</link>
      <description>Does knowledge of noise variance have any effect on model selection for the mean?</description>
      <category>Model Selection</category>
      <category>Linear Models</category>
      <category>Regression</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance</guid>
      <pubDate>Wed, 13 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>"A Closer Look at the Deviance" by T. Hastie</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie</link>
      <description>A nice review of properties of Deviance for one parameter exponential 
families.</description>
      <category>Comment on...</category>
      <category>Maximum Likelihood Estimation</category>
      <category>Linear Models</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie</guid>
      <pubDate>Thu, 07 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>No binomial overdispersion from variations at the individual level</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level</link>
      <description>Some notes on the causes of overdispersion in count data.</description>
      <category>Population Dynamics</category>
      <category>Biology</category>
      <category>Ecology</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level</guid>
      <pubDate>Wed, 06 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>On the first and second laws of thermodynamics for open systems</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems</link>
      <description>Matter transfer in open systems changes the relationship between heat and entropy, and work and volume.</description>
      <category>Open Systems</category>
      <category>Thermodynamics</category>
      <category>Physics</category>
      <guid>https://vgherard.github.io/posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems</guid>
      <pubDate>Mon, 04 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Gravity waves in an ideal fluid</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-02-22-gravity-waves-in-an-ideal-fluid</link>
      <description>Compares the "parcel" method with standard linearization of fluid dynamics equations.</description>
      <category>Atmospheric Physics</category>
      <category>Fluid Dynamics</category>
      <category>Waves</category>
      <category>Physics</category>
      <guid>https://vgherard.github.io/posts/2024-02-22-gravity-waves-in-an-ideal-fluid</guid>
      <pubDate>Thu, 22 Feb 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Binary digits of uniform random variables</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-01-29-binary-digits-of-uniform-random-variables</link>
      <description>... are independent fair coin tosses.</description>
      <category>Probability Theory</category>
      <guid>https://vgherard.github.io/posts/2024-01-29-binary-digits-of-uniform-random-variables</guid>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Interpreting the Likelihood Ratio cost</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-11-15-interpreting-the-likelihood-ratio-cost</link>
      <description>Analysis of infinite sample properties and comparison with cross-entropy loss.</description>
      <category>Forensic Science</category>
      <category>Bayesian Methods</category>
      <category>Information Theory</category>
      <category>Probability Theory</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-11-15-interpreting-the-likelihood-ratio-cost</guid>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost_files/figure-html5/unnamed-chunk-3-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Conditional Probability</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-11-03-conditional-probability</link>
      <description>Notes on the formal definition of conditional probability.</description>
      <category>Probability Theory</category>
      <category>Measure Theory</category>
      <guid>https://vgherard.github.io/posts/2023-11-03-conditional-probability</guid>
      <pubDate>Fri, 03 Nov 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Prefix-free codes</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-10-31-prefix-free-codes</link>
      <description>Generalities about prefix-free (a.k.a. instantaneous) codes</description>
      <category>Information Theory</category>
      <category>Entropy</category>
      <category>Probability Theory</category>
      <guid>https://vgherard.github.io/posts/2023-10-31-prefix-free-codes</guid>
      <pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>AB tests and repeated checks</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-07-24-ab-tests-and-repeated-checks</link>
      <description>False Positive Rates under repeated checks - a simulation study using R.</description>
      <category>AB testing</category>
      <category>Sequential Hypothesis Testing</category>
      <category>Frequentist Methods</category>
      <category>Statistics</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-07-24-ab-tests-and-repeated-checks</guid>
      <pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks_files/figure-html5/unnamed-chunk-7-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Testing functional specification in linear regression</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression</link>
      <description>Some options in R, using the `{lmtest}` package.</description>
      <category>Statistics</category>
      <category>Model Misspecification</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression</guid>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression_files/figure-html5/unnamed-chunk-1-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Sum and ratio of independent random variables</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-06-14-sum-and-ratio-of-independent-random-variables</link>
      <description>Sufficient conditions for independence of sum and ratio.</description>
      <category>Mathematics</category>
      <category>Probability Theory</category>
      <guid>https://vgherard.github.io/posts/2023-06-14-sum-and-ratio-of-independent-random-variables</guid>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Fisher's Randomization Test</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-06-07-fishers-randomization-test</link>
      <description>Notes and proofs of basic theorems</description>
      <category>Statistics</category>
      <category>Frequentist Methods</category>
      <category>Causal Inference</category>
      <guid>https://vgherard.github.io/posts/2023-06-07-fishers-randomization-test</guid>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>p-values and measure theory</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-06-07-p-values-and-measure-theory</link>
      <description>Self-reassurance that p-value properties don't depend on regularity 
assumptions on the test statistic.</description>
      <category>Probability Theory</category>
      <category>Measure Theory</category>
      <category>Frequentist Methods</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2023-06-07-p-values-and-measure-theory</guid>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Linear regression with autocorrelated noise</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise</link>
      <description>Effects of noise autocorrelation on linear regression. Explicit formulae and a simple simulation.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Time Series</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise</guid>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise_files/figure-html5/unnamed-chunk-2-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Model Misspecification and Linear Sandwiches</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches</link>
      <description>Being wrong in the right way. With R excerpts.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches</guid>
      <pubDate>Sun, 14 May 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches_files/figure-html5/unnamed-chunk-7-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Consistency and bias of OLS estimators</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-12-consistency-and-bias-of-ols-estimators</link>
      <description>OLS estimators are consistent but generally biased - here's an example.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <guid>https://vgherard.github.io/posts/2023-05-12-consistency-and-bias-of-ols-estimators</guid>
      <pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Bayes, Neyman and the Magic Piggy Bank</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-01-magic-piggy-bank</link>
      <description>Compares frequentist properties of credible intervals and confidence 
intervals in a gambling game involving a magic piggy bank.</description>
      <category>Statistics</category>
      <category>Confidence Intervals</category>
      <category>Frequentist Methods</category>
      <category>Bayesian Methods</category>
      <guid>https://vgherard.github.io/posts/2023-05-01-magic-piggy-bank</guid>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Correlation Without Causation</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-03-10-correlation-without-causation</link>
      <description>*Cum hoc ergo propter hoc*</description>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2023-03-10-correlation-without-causation</guid>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to get away with selection. Part II: Mathematical Framework</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2022-11-07-posi-2</link>
      <description>Mathematicals details on Selective Inference, model misspecification and coverage guarantees.</description>
      <category>Statistics</category>
      <category>Selective Inference</category>
      <category>Model Misspecification</category>
      <guid>https://vgherard.github.io/posts/2022-11-07-posi-2</guid>
      <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to get away with selection. Part I: Introduction</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2022-10-18-posi</link>
      <description>Introducing the problem of Selective Inference, illustrated through a simple simulation in R.</description>
      <category>Statistics</category>
      <category>Selective Inference</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2022-10-18-posi</guid>
      <pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2022-10-18-posi/posi_files/figure-html5/unnamed-chunk-3-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>kgrams v0.1.2 on CRAN</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-11-13-kgrams-v012-released</link>
      <description>kgrams: Classical k-gram Language Models in R.</description>
      <category>Natural Language Processing</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-11-13-kgrams-v012-released</guid>
      <pubDate>Sat, 13 Nov 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>R Client for R-universe APIs</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-25-r-client-for-r-universe-apis</link>
      <description>{runi}, an R package to interact with R-universe repository APIs</description>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-25-r-client-for-r-universe-apis</guid>
      <pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Automatic resumes of your R-developer portfolio from your R-Universe</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api</link>
      <description>Create automatic resumes of your R packages using the R-Universe API.</description>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api</guid>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>{r2r} now on CRAN</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-06-r2r</link>
      <description>Introducing {r2r}, an R implementation of hash tables.</description>
      <category>Data Structures</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-06-r2r</guid>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Test post</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-06-test-post</link>
      <description>A short description of the post.</description>
      <category>Other</category>
      <guid>https://vgherard.github.io/posts/2021-07-06-test-post</guid>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>

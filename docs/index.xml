<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>vgherard</title>
    <link>https://vgherard.github.io/</link>
    <atom:link href="https://vgherard.github.io/index.xml" rel="self" type="application/rss+xml"/>
    <description>Valerio Gherardi's Personal Website
</description>
    <generator>Distill</generator>
    <lastBuildDate>Fri, 31 May 2024 00:00:00 +0000</lastBuildDate>
    <item>
      <title>Statements of the Second Law of Thermodynamics</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-06-01-statements-of-the-second-law-of-thermodynamics</link>
      <description>


&lt;p&gt;The Second Law of Thermodynamics is commonly stated in the forms of
Kelvin’s and Clausius’ postulates. These can be enunciated in the
following way &lt;span class="citation"&gt;(Dittman and Zemansky 2021)&lt;/span&gt;
&lt;a href="#fn1" class="footnote-ref" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Kelvin’s Postulate.&lt;/strong&gt; It is impossible to construct an
engine that, operating in a cycle, will produce no effect other than the
extraction of heat from a reservoir and the performance of an equivalent
amount of work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Clausius’ Postulate.&lt;/strong&gt; It is impossible to construct a
refrigerator that, operating in a cycle, will produce no effect other
than the transfer of heat from a lower-temperature reservoir to a higher
temperature reservoir.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Either formulation is equivalent to the other and leads to the
fundamental &lt;em&gt;Clausius’ theorem&lt;/em&gt;. This asserts the existence of a
universal state function &lt;span class="math inline"&gt;\(T\)&lt;/span&gt;, the
&lt;em&gt;absolute temperature&lt;/em&gt;, defined for any thermodynamic system,
that satisfies the &lt;em&gt;Clausius inequality&lt;/em&gt;. Concretely, if a system
undergoes a cyclic process, during which it absorbs quantities &lt;span
class="math inline"&gt;\(\Delta Q _i\)&lt;/span&gt; of energy in the form of heat
from reservoirs at absolute temperatures &lt;span
class="math inline"&gt;\(T_i\)&lt;/span&gt;, the inequality:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\sum _i\frac{\Delta Q_i}{T_i} \leq 0 (\#eq:ClausiusTheorem)
\]&lt;/span&gt; always holds.&lt;/p&gt;
&lt;p&gt;The derivation of Eq. @ref(eq:ClausiusTheorem) from Kelvin’s and
Clausius’ postulates, a clever argument that employs ideal Carnot
engines, is standard textbook material; see for example &lt;span
class="citation"&gt;(Fermi 1956)&lt;/span&gt;. On the other hand, I’ve never seen
the converse being stressed, that is, that Clausius theorem allows one
to recover versions of Kelvin’s and Clausius’ postulates. Here are two
(fairly obvious) arguments in this direction.&lt;/p&gt;
&lt;p&gt;Consider a cyclic process of a thermodynamic system during which a
quantity &lt;span class="math inline"&gt;\(\Delta Q\)&lt;/span&gt; of heat is
absorbed from a reservoir at constant temperature &lt;span
class="math inline"&gt;\(T_0\)&lt;/span&gt;. Equation @ref(eq:ClausiusTheorem)
applied to this special process implies:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\Delta Q\leq 0.(\#eq:KelvinProof1)
\]&lt;/span&gt; The fact that &lt;span class="math inline"&gt;\(\Delta Q\leq
0\)&lt;/span&gt; means that the heat reservoir can only absorb energy during a
cycle, which must be supplied by performing a positive work on the
system. This is the content of Kelvin’s postulate.&lt;/p&gt;
&lt;p&gt;Similarly, if the system performs a cycle exchanging amounts of heat
&lt;span class="math inline"&gt;\(\Delta Q_1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\Delta Q_2\)&lt;/span&gt; with two heat sources at
temperatures &lt;span class="math inline"&gt;\(T_1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(T_2\)&lt;/span&gt; respectively,
@ref(eq:ClausiusTheorem) implies:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\frac{\Delta Q_1}{T_1}+\frac{\Delta Q_2}{T_2}\leq 0(\#eq:ClausiusProof1)
\]&lt;/span&gt; But &lt;span class="math inline"&gt;\(\Delta Q_1 + \Delta Q_2 =
\Delta Q =-\Delta W\)&lt;/span&gt;, the external work performed on the system
during a cycle. Hence:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
(\frac{1}{T_1}-\frac{1}{T_2})\Delta Q_1\leq \frac{\Delta
W}{T_2}.(\#eq:ClausiusProof2)
\]&lt;/span&gt; Therefore, &lt;span class="math inline"&gt;\(\Delta Q_1 \geq
0\)&lt;/span&gt; with &lt;span class="math inline"&gt;\(T_1 &amp;lt; T_2\)&lt;/span&gt;
requires &lt;span class="math inline"&gt;\(\Delta W \geq 0\)&lt;/span&gt;. In other
words, in order to perform a cycle in which a positive amount of heat is
transferred from a low-temperature reservoir to a high-temperature one,
we must necessarily perform some positive work&lt;a href="#fn2"
class="footnote-ref" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. This is the content
of Clausius’ postulate.&lt;/p&gt;
&lt;p&gt;A subtle point that may require some elucidation is that, in the
usual logical exposition of Thermodynamics, the temperature to which
Kelvin’s and Clausius’ postulates make reference is the
&lt;em&gt;empirical&lt;/em&gt; temperature, call it &lt;span
class="math inline"&gt;\(\theta\)&lt;/span&gt;. This is the “quantity measured by
a thermometer” &lt;span class="citation"&gt;(Fermi 1956)&lt;/span&gt;, and is
logically distinct from the absolute temperature &lt;span
class="math inline"&gt;\(T\)&lt;/span&gt;, whose existence is a consequence of
the second law. What we actually proved here are versions of Kelvin’s
and Clausius’ postulates &lt;em&gt;formulated in terms of the absolute
temperature&lt;/em&gt;, &lt;span class="math inline"&gt;\(T\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now, if we take Kelvin’s or Clausius’ postulate (formulated in terms
of &lt;span class="math inline"&gt;\(\theta\)&lt;/span&gt;) as our logical starting
point, we can actually prove that &lt;span class="math inline"&gt;\(T\)&lt;/span&gt;
is an increasing function of &lt;span
class="math inline"&gt;\(\theta\)&lt;/span&gt;, in which case there is no point
in specifying which temperature the postulates refer to. However, if our
starting point is&lt;br /&gt;
Clausius’ Theorem, there is no &lt;em&gt;a priori&lt;/em&gt; logical reason for a
relation between &lt;span class="math inline"&gt;\(T\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\theta\)&lt;/span&gt;, which should be considered as an
additional assumption.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Even though this goes a bit beyond the original scope of the post,
I’d like to show here how @ref(eq:ClausiusTheorem) leads the existence
of another state function, the &lt;em&gt;entropy&lt;/em&gt; &lt;span
class="math inline"&gt;\(S\)&lt;/span&gt;, which satisfies a generalized version
of @ref(eq:ClausiusTheorem), namely:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\sum _i\frac{\Delta Q_i}{T_i} \leq \Delta S(\#eq:ClausiusTheoremEntropy)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where quantities have the same meaning as in Eq.
@ref(eq:ClausiusTheorem), but the process is not necessarily cyclic. One
can additionally show that the differential of &lt;span
class="math inline"&gt;\(S\)&lt;/span&gt; is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text dS = \frac{\delta Q _R}{T}(\#eq:EntropyDifferential),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class="math inline"&gt;\(\delta Q_R = \text d U + \delta
W_R\)&lt;/span&gt; is the differential heat absorbed by the system in a
reversible process, and &lt;span class="math inline"&gt;\(T\)&lt;/span&gt; is the
system’s temperature.&lt;/p&gt;
&lt;p&gt;We start by observing that, for a reversible process, equality must
hold in Eq. @ref(eq:ClausiusTheorem). This is so because, for a
reversible cycle, the inverse cycle, in which the system absorbs amounts
&lt;span class="math inline"&gt;\(-\Delta Q_i\)&lt;/span&gt; of heat at temperatures
&lt;span class="math inline"&gt;\(T_i\)&lt;/span&gt;, must also be possible.
Altogether, the Clausius inequalities for the direct and inverse cycles
thus imply:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\sum _i\frac{\Delta Q_i}{T_i} = 0\quad \text{(reversible
process)}(\#eq:ClausiusTheoremRev).
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Imagining an ideal cyclic process, in which the system exchanges
infinitesimal amounts of heat &lt;span class="math inline"&gt;\(\delta
Q(T&amp;#39;)\)&lt;/span&gt; with a continuous distribution of sources at
temperatures &lt;span class="math inline"&gt;\(T&amp;#39;\)&lt;/span&gt;, we should
replace the sum in Eq. @ref(eq:ClausiusTheoremRev) with an integral:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\intop \frac{\delta Q(T&amp;#39;)}{T&amp;#39;} = 0 \quad\text{(reversible
process)}(\#eq:ClausiusTheoremRevInt)
\]&lt;/span&gt; We now fix a reference state &lt;span
class="math inline"&gt;\(\sigma _0\)&lt;/span&gt; of our system, and define for
any other state &lt;span class="math inline"&gt;\(\sigma\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
S(\sigma;\sigma _0) = \intop _{\sigma_0}^\sigma \frac{\delta
Q(T&amp;#39;)}{T&amp;#39;}(\#eq:EntropyDef)
\]&lt;/span&gt; where the integral is taken along &lt;em&gt;any&lt;/em&gt; reversible path
that connects &lt;span class="math inline"&gt;\(\sigma _0\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\sigma\)&lt;/span&gt;, and &lt;span
class="math inline"&gt;\(\delta Q(T&amp;#39;)\)&lt;/span&gt; is the amount of heat
exchanged at temperature &lt;span class="math inline"&gt;\(T&amp;#39;\)&lt;/span&gt;
along this representative process. The fact that the integral in
@ref(eq:EntropyDef) depends only upon the final states &lt;span
class="math inline"&gt;\(\sigma _0\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(\sigma\)&lt;/span&gt; is guaranteed by
@ref(eq:ClausiusTheoremRevInt).&lt;/p&gt;
&lt;p&gt;By construction, we see that Eq. @ref(eq:EntropyDifferential) must
hold with &lt;span class="math inline"&gt;\(T\)&lt;/span&gt; being the temperature
of a source that, if placed in thermal contact with the system, can
produce a reversible exchange of heat. It remains to be shown that this
temperature is nothing but the temperature of the system itself.
Consider a reversible process in which two systems at temperatures &lt;span
class="math inline"&gt;\(T_1\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(T_2\)&lt;/span&gt; exchange an (infinitesimal) amount of
heat. From what we have just said:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text d S_1 = \frac{\delta Q_1}{T_2},\quad \text d S_2 = \frac{\delta Q
_2}{T_1},(\#eq:EntropyDifferentialsSwitched)
\]&lt;/span&gt; where &lt;span class="math inline"&gt;\(\delta Q_i\)&lt;/span&gt; is the
heat absorbed by system &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;, and
&lt;span class="math inline"&gt;\(\text d S_i\)&lt;/span&gt; is its corresponding
entropy change. However, since the composite system is thermally
insulated, we must have &lt;span class="math inline"&gt;\(\delta Q_1 + \delta
Q_2=0\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\text d S_1 + \text d S_2
= 0\)&lt;/span&gt;&lt;a href="#fn3" class="footnote-ref"
id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. Eq. @ref(eq:EntropyDifferentialsSwitched)
then implies that, if the process is reversible, we must necessarily
have &lt;span class="math inline"&gt;\(T_1 = T_2\)&lt;/span&gt;. This completes the
proof of @ref(eq:EntropyDifferential).&lt;/p&gt;
&lt;div id="refs" class="references csl-bib-body hanging-indent"&gt;
&lt;div id="ref-dittman2021heat" class="csl-entry"&gt;
Dittman, Richard H, and Mark W Zemansky. 2021. &lt;span&gt;“Heat and
Thermodynamics SEVENTH EDITION.”&lt;/span&gt;
&lt;/div&gt;
&lt;div id="ref-fermi1956thermodynamics" class="csl-entry"&gt;
Fermi, E. 1956. &lt;em&gt;Thermodynamics&lt;/em&gt;. Dover Books in Physics and
Mathematical Physics. Dover Publications. &lt;a
href="https://books.google.es/books?id=VEZ1ljsT3IwC"&gt;https://books.google.es/books?id=VEZ1ljsT3IwC&lt;/a&gt;.
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="footnotes footnotes-end-of-document"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;We may compare these with the corresponding formulations
given in Enrico Fermi’s famous book &lt;span class="citation"&gt;(Fermi
1956)&lt;/span&gt;. For instance, Kelvin’s postulate reads: &lt;em&gt;“A
transformation whose only final result is to transform into work heat
extracted from a source which is at the same temperature throughout is
impossible.”&lt;/em&gt;. Even though I’m a big fan of Fermi’s book, I find the
more modern formulations given in &lt;span class="citation"&gt;(Dittman and
Zemansky 2021)&lt;/span&gt; clearer.&lt;a href="#fnref1"
class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;In fact, Eq. @ref(eq:ClausiusProof2) tells us a bit more
than Clausius postulate, since it gives the maximum theoretical
efficiency of a refrigerator operating between temperatures &lt;span
class="math inline"&gt;\(T_1 &amp;lt; T_2\)&lt;/span&gt;: &lt;span
class="math display"&gt;\[
\frac{\Delta Q_1}{\Delta W} \leq \frac{T_1}{T_2-T_1}
\]&lt;/span&gt;&lt;a href="#fnref2" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;The additivity of entropy is a consequence of the
additivity of heat, which in turn would require a dedicate discussion.
Such a requirement boils down to the additivity of external work, which
holds generally if the interaction energies of the systems being
composed are negligible. This is always assumed (more or less
explicitly) whenever discussing the interaction of a system with a heat
reservoir.&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;a href="#fnref3" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>3b38a91cced01b553fec61b3485cfe2f</distill:md5>
      <category>Thermodynamics</category>
      <category>Physics</category>
      <guid>https://vgherard.github.io/posts/2024-06-01-statements-of-the-second-law-of-thermodynamics</guid>
      <pubDate>Fri, 31 May 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Authorship Attribution in Lennon-McCartney Songs</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-05-23-authorship-attribution-in-lennon-mccartney-songs</link>
      <description>


&lt;p&gt;&lt;span class="citation"&gt;(Glickman, Brown, and Song 2019)&lt;/span&gt;. An
enjoyable read. The authors present a statistical analysis of the
Beatles’ repertoire from the point of view of authorship (Lennon
&lt;em&gt;vs.&lt;/em&gt; McCartney), a &lt;a
href="https://vgherard.github.io/posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/"&gt;topic
with which I’ve been lately involved&lt;/a&gt;. As a side-note, this also made
me discover the &lt;a href="https://hdsr.mitpress.mit.edu/"&gt;Harvard Data
Science Review&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;From the paper’s abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The songwriting duo of John Lennon and Paul McCartney, the two
founding members of the Beatles, composed some of the most popular and
memorable songs of the last century. Despite having authored songs under
the joint credit agreement of Lennon-McCartney, it is well-documented
that most of their songs or portions of songs were primarily written by
exactly one of the two. Furthermore, the authorship of some
Lennon-McCartney songs is in dispute, with the recollections of
authorship based on previous interviews with Lennon and McCartney in
conflict. For Lennon-McCartney songs of known and unknown authorship
written and recorded over the period 1962-66, we extracted musical
features from each song or song portion. These features consist of the
occurrence of melodic notes, chords, melodic note pairs, chord change
pairs, and four-note melody contours. We developed a prediction model
based on variable screening followed by logistic regression with elastic
net regularization. Out-of-sample classification accuracy for songs with
known authorship was 76%, with a c-statistic from an ROC analysis of
83.7%. We applied our model to the prediction of songs and song portions
with unknown or disputed authorship.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The modeling approach looks to me very sound and appropriate to the
small sample size available (&lt;span class="math inline"&gt;\(N =
70\)&lt;/span&gt;, the statistical unit corresponding to a song of known
authorship). Effective model selection and testing is achieved through
three nested layers of cross-validation (😱): one for elastic net
hyperparameter tuning, one for feature screening, and finally one for
estimating the prediction error.&lt;/p&gt;
&lt;p&gt;The discussion of feature importance is insightful, in that it
identifies concrete aspects of McCartney’s compositions that make them
distinguishable from Lennon’s ones. This type of interpretability is a
big plus for authorship analysis. The general qualitative conclusion,
that McCartney’s music tended to exhibit more complex and unusual
patterns kinda resonates with my perception of Beatles’ songs.&lt;/p&gt;
&lt;p&gt;Armed with the trained logistic regression model, together with a
valid accuracy estimate (76%), the authors set out to apply their model
to authorship prediction for controversial cases within the Beatles’
corpus (outside of the training sample). I don’t fully understand the
authors approach in this part of the paper, and some points appear to be
questionable, for the reasons I explain below.&lt;/p&gt;
&lt;p&gt;One of the advantages of fitting a full probability model, such as
logistic regression, rather than a conceptually simpler pure
classification model (like a tree, for example), is that the output of
the former is not a mere class (McCartney or Lennon), but rather a
&lt;em&gt;probability&lt;/em&gt; of belonging to that class. This allows one to make
much more informative statements in the analysis of new cases, since the
strength of evidence provided by the data towards the predicted class
can be quantified on a case by case basis. All of this is true, of
course, &lt;em&gt;provided that the fitted model gives a decent approximation
to the true data generating process&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;With similar considerations in mind, I suppose, the authors produce
probability estimates for each of the disputed cases considered, in the
form of a point estimate and a confidence interval to represent
uncertainty. I think there is room for improvement here, in two
aspects.&lt;/p&gt;
&lt;p&gt;My first objection is what I already pointed out above: nothing in
the modeling process explained in the paper suggests that the final
model provides a good approximation to the true class probability
conditional on features. The model has, with reasonable confidence, a
predictive performance close to the best achievable within the
possibilities considered - quantified by 76% accuracy and 84% AUC - but
this says nothing about its correct specification as a probability
model. Without a careful specification study, it is impossible to
conclude anything on the nature of the true estimation targets of the
fitted “probabilities”: they may perfectly have nothing to do with the
actual &lt;span class="math inline"&gt;\(\text{Pr}(\text{author}\,\vert\,
\text{song features})\)&lt;/span&gt; the authors are after. There is still
value, I believe, in reporting fitted probabilities as qualitative
measures of evidence, but these should not be conflated with the true
(unknown) class probabilities… at least without some serious attempt to
detect differences between the two.&lt;/p&gt;
&lt;p&gt;My second point is a technical one and concerns how they construct
confidence intervals for fitted probabilities. The construction
resembles that of bootstrap percentile confidence intervals but, rather
than the usual bootstrap synthetic datasets, the delete-one datasets
used in leave-one-out cross-validation are used to obtain replicas of
the fitted probabilities. This is nothing but Jackknife resampling in
disguise, and it is well known that the resampling standard deviation of
such Jackknife replicae is roughly &lt;span class="math inline"&gt;\(N
^{-1/2}\)&lt;/span&gt; times the true standard deviation, see &lt;em&gt;e.g.&lt;/em&gt;
&lt;span class="citation"&gt;(Tibshirani and Efron 1993)&lt;/span&gt;. Therefore, I
have strong reasons to believe that the reported intervals strongly
underestimate the uncertainty associated with these probability
estimates.&lt;/p&gt;
&lt;p&gt;All in all, the attempt to go beyond reporting simple classes -
backed up by an overall 76% accuracy estimate - is well-motivated in
principle, but the final outcome is not very dependable.&lt;/p&gt;
&lt;p&gt;As usual, I’m more eloquent when criticizing than when praising, but
let me end on a very positive note. The authors do a &lt;em&gt;great&lt;/em&gt;
favor to the reader, by including a discussion of the informal steps
performed prior and in parallel to the formal analysis presented in the
paper. This kind of transparency - which is also present in the rest of
the discussion - is, I believe, not so common as it should, and is what
makes it eventually possible to think critically about someone else’s
work.&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id="refs" class="references csl-bib-body hanging-indent"&gt;
&lt;div id="ref-Glickman2019Data" class="csl-entry"&gt;
Glickman, Mark, Jason Brown, and Ryan Song. 2019.
&lt;span&gt;“(&lt;span&gt;A&lt;/span&gt;) &lt;span&gt;Data&lt;/span&gt; in the &lt;span&gt;Life&lt;/span&gt;:
Authorship &lt;span&gt;Attribution&lt;/span&gt; in
&lt;span&gt;Lennon&lt;/span&gt;-&lt;span&gt;McCartney&lt;/span&gt; &lt;span&gt;Songs&lt;/span&gt;.”&lt;/span&gt;
&lt;em&gt;Harvard Data Science Review&lt;/em&gt; 1 (1).
&lt;/div&gt;
&lt;div id="ref-tibshirani1993introduction" class="csl-entry"&gt;
Tibshirani, Robert J, and Bradley Efron. 1993. &lt;span&gt;“An Introduction to
the Bootstrap.”&lt;/span&gt; &lt;em&gt;Monographs on Statistics and Applied
Probability&lt;/em&gt; 57 (1): 1–436.
&lt;/div&gt;
&lt;/div&gt;</description>
      <distill:md5>7b1b8fa9a1ecfd0183e658839ab311f3</distill:md5>
      <category>Comment on...</category>
      <category>Authorship Verification</category>
      <category>Natural Language Processing</category>
      <category>Machine Learning</category>
      <category>Music</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-05-23-authorship-attribution-in-lennon-mccartney-songs</guid>
      <pubDate>Thu, 23 May 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Frequentist bounds for Bayesian sequential hypothesis testing</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-05-22-frequentist-bounds-for-bayesian-sequential-hypothesis-testing</link>
      <description>


&lt;p&gt;I just came across &lt;span class="citation"&gt;(Kerridge 1963)&lt;/span&gt;, an
old result which falls under the umbrella of “frequentist properties of
Bayesian inference”. Specifically, the theorem proved in this reference
applies to sequential testing, a context in which the mechanics of
Bayesian inference, with its typical sequential updates, may be regarded
as natural.&lt;/p&gt;
&lt;p&gt;Suppose we wish to compare two hypotheses &lt;span
class="math inline"&gt;\(H_0\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(H_1\)&lt;/span&gt;, where &lt;span
class="math inline"&gt;\(H_0\)&lt;/span&gt; is simple&lt;a href="#fn1"
class="footnote-ref" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. We start collecting
data until our sample meets some specific requirement, according to some
given &lt;em&gt;stopping rule&lt;/em&gt; &lt;span class="math inline"&gt;\(S\)&lt;/span&gt;. If
this ever occurs, we compute the &lt;em&gt;Bayes factor&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
B = \frac{\text{Pr}(\text {data} \vert H_0)}{\text{Pr}(\text {data}
\vert H_1)}.(\#eq:BayesRatio)
\]&lt;/span&gt; and reject &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt; if &lt;span
class="math inline"&gt;\(B \leq b\)&lt;/span&gt;, for some &lt;span
class="math inline"&gt;\(b &amp;gt; 0\)&lt;/span&gt;. The theorem is that if &lt;span
class="math inline"&gt;\(H_0\)&lt;/span&gt; is the true data generating process,
the above procedure has a false rejection rate lower than &lt;span
class="math inline"&gt;\(b\)&lt;/span&gt;, &lt;em&gt;independently of the stopping rule
employed to end sampling&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Notice that the rejection event is composed by two parts:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Sampling has stopped at some point during data taking.&lt;/li&gt;
&lt;li&gt;When sampling stopped, &lt;span class="math inline"&gt;\(B \leq b\)&lt;/span&gt;
held.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also note that the stopping rule needs not be deterministic,
although this appears to be implicitly assumed in the original
reference. In general, the data collected up to a certain point will
only determine the &lt;em&gt;probability&lt;/em&gt; that sampling stops at that time
(and, to reinforce the previous point, the sum of these probabilities
will not, in general, add up to &lt;span
class="math inline"&gt;\(1\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;In order to prove this theorem, let us set up some notation. Let
&lt;span class="math inline"&gt;\((X_n)_{n\in \mathbb N}\)&lt;/span&gt; be some
stochastic process representing “data”, where each &lt;span
class="math inline"&gt;\(X_n \in \mathcal X\)&lt;/span&gt; is a data point. We
denote by &lt;span class="math inline"&gt;\(P^{(0)}\)&lt;/span&gt; the probability
distribution of &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; under &lt;span
class="math inline"&gt;\(H_0\)&lt;/span&gt;, which is completely defined since
&lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt; is simple. We further denote by
&lt;span class="math inline"&gt;\(P_n ^{(0)}\)&lt;/span&gt; the corresponding
probability measure on &lt;span class="math inline"&gt;\(\mathcal X
^n\)&lt;/span&gt; for the set of the first &lt;span
class="math inline"&gt;\(n\)&lt;/span&gt; observations &lt;span
class="math inline"&gt;\(X_1,\,X_2,\,\dots, \,X_n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We first consider the case in which &lt;span
class="math inline"&gt;\(H_1\)&lt;/span&gt; is also simple, and denote by &lt;span
class="math inline"&gt;\(P^{(1)}\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(P^{(1)}_n\)&lt;/span&gt; the corresponding measures. The
Bayes factor is defined as the Radon-Nikodym derivative:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
B_n \equiv \frac{\text d P^{(0)}_n}{\text d
P_n^{(1)}}(\#eq:BayesRatioRadonNikodym)
\]&lt;/span&gt; (we assume regularity conditions so that such a derivative
exists).&lt;/p&gt;
&lt;p&gt;Also, we assume for the moment that the stopping rule is
deterministic, embodied by binary functions &lt;span
class="math inline"&gt;\(S_n=S(X_1,\,X_2,\,\dots,X_n)\)&lt;/span&gt; of the first
&lt;span class="math inline"&gt;\(n\)&lt;/span&gt; observations, with &lt;span
class="math inline"&gt;\(S_n = 1\)&lt;/span&gt; if sampling can stop at step
&lt;span class="math inline"&gt;\(n\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now fix &lt;span class="math inline"&gt;\(b&amp;gt;0\)&lt;/span&gt;. A rejection of
&lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt; at sampling step &lt;span
class="math inline"&gt;\(n\)&lt;/span&gt; is represented by the event:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathcal R _{n}(b)\equiv \{B_n\leq b,\,S_n=1,\,S_i=0\,\text{ for
}i&amp;lt;n\},(\#eq:RejectionEvents)
\]&lt;/span&gt; which, with abuse of notation, we may identify with a subset
of &lt;span class="math inline"&gt;\(\mathcal X ^n\)&lt;/span&gt;. The overall
rejection event (at any sampling step) is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathcal R (b)\equiv \bigcup _{n=1} ^\infty \mathcal
R_n(b),(\#eq:BigRejectionEvent)
\]&lt;/span&gt; so that our theorem amounts to the bound:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{Pr}_{H_0}(\mathcal R(b))\leq b. (\#eq:TheoremStatement)
\]&lt;/span&gt; In order to prove this, we first note that:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{Pr}_{H_0}(\mathcal R _n(b))=
        \intop _{\mathcal R _n(b)} \text d P_n=
        \intop _{\mathcal R _n(b)}B_n \text d Q_n \leq
        b\intop _{\mathcal R _n(b)} \text d
Q_n=b\cdot\text{Pr}_{H_1}(\mathcal R _n(b)).(\#eq:TheoremStep1)
\]&lt;/span&gt; Hence, since the events &lt;span class="math inline"&gt;\(\mathcal R
_n(b)\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\mathcal R _m(b)\)&lt;/span&gt;
are clearly disjoint for &lt;span class="math inline"&gt;\(n\neq m\)&lt;/span&gt;,
we have:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{Pr}_{H_0}(\mathcal R(b))\leq b\cdot\text{Pr}_{H_1}(\mathcal R
(b))(\#eq:TheoremStep2),
\]&lt;/span&gt; which, since &lt;span
class="math inline"&gt;\(\text{Pr}_Q(\cdot)\leq1\)&lt;/span&gt;, implies
@ref(eq:TheoremStatement).&lt;/p&gt;
&lt;p&gt;We may relax the assumption that the alternative hypothesis is
simple, by considering a parametric family of measures &lt;span
class="math inline"&gt;\((P^{(1)}_\theta)_{\theta \in \Theta}\)&lt;/span&gt;,
where the parameter &lt;span class="math inline"&gt;\(\theta\)&lt;/span&gt; has some
prior probability &lt;span class="math inline"&gt;\(\text
d\Phi(\theta)\)&lt;/span&gt;. The argument given above still applies to this
case, if &lt;span class="math inline"&gt;\(P^{(1)}\)&lt;/span&gt; is replaced by the
mixture &lt;span class="math inline"&gt;\(P^{(1)} = \intop \text d
\Phi(\theta) P^{(1)}_\theta\)&lt;/span&gt; (under appropriate regularity
assumptions). In the notation of Eq. @ref(eq:BayesRatio), the
denominator &lt;span class="math inline"&gt;\(\text {Pr}(\text {data} \vert
H_1)\equiv \intop \text d \Phi(\theta)\,\text{Pr}(\text{data} \vert
H_{1,\theta})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, in order to lift the assumption that our stopping rule is
deterministic, let us first consider the following special
(deterministic) stopping rule:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
S^*_n =1\iff B_n \leq b.(\#eq:DataDredging)
\]&lt;/span&gt; In other words, we stop sampling whenever the sample would
reject &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt; according to &lt;span
class="math inline"&gt;\(B_n \leq b\)&lt;/span&gt;. The rejection event &lt;span
class="math inline"&gt;\(\mathcal R(b)\)&lt;/span&gt; for this special stopping
rule is simply:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathcal R^*(b) \equiv \{B_n \leq b\text{ for some }n\in \mathbb
N\}.(\#eq:RejectionDataDredging)
\]&lt;/span&gt; Since we already proved the theorem for any deterministic
stopping rule, Eq. @ref(eq:TheoremStatement) implies:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text {Pr}_{H_0}(\mathcal R^*(b)) \leq b.(\#eq:BoundDataDredging)
\]&lt;/span&gt; But Eq. @ref(eq:BoundDataDredging) clearly implies the theorem
for any stopping rule, deterministic or not, since in general:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\mathcal R(b) \subseteq \mathcal R^*(b)(\#eq:ProperSubsetDataDredging)
\]&lt;/span&gt; (we need &lt;span class="math inline"&gt;\(B_n\leq b\)&lt;/span&gt; to
hold for some &lt;span class="math inline"&gt;\(n\in \mathbb N\)&lt;/span&gt; in
order to reject &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Interestingly, the argument just given leads to a more accurate
statement of our main result @ref(eq:TheoremStatement):&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{Pr}_{H_0}(\mathcal R(b))\leq \text {Pr}_{H_0}(B_n \leq b\text{ for
some }n\in \mathbb N) \leq b,(\#eq:TheoremStatement2)
\]&lt;/span&gt; where the leftmost quantity is the false rejection rate of a
selective testing procedure, such as the one we have been considering so
far, wheareas the central quantity is the false rejection rate of a
&lt;em&gt;simultaneous&lt;/em&gt; testing procedure (that checks whether &lt;span
class="math inline"&gt;\(B_n \leq b\)&lt;/span&gt; at each step of sampling).
What’s happening here is analogous to a phenomenon observed in the
context of parameter estimation following model selection &lt;span
class="citation"&gt;(Berk et al. 2013)&lt;/span&gt;, where one can show that, in
order to guarantee marginal coverage for the selected parameters, if the
selection rule is allowed to be completely arbitrary one must actually
require &lt;em&gt;simultaneous&lt;/em&gt; coverage for all possible parameters.&lt;/p&gt;
&lt;p&gt;To conclude the post, let us remark that theorem
@ref(eq:TheoremStatement) was originally formulated in terms of the
posterior probability &lt;span class="math inline"&gt;\(Q_n(\pi)\)&lt;/span&gt; of
&lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
Q_n(\pi) = \frac{\pi }{\pi +(1-\pi)B^{-1}_n},(\#eq:PosteriorProb)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class="math inline"&gt;\(\pi\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(1-\pi\)&lt;/span&gt; are the prior probabilities of the
two competing models &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt; and &lt;span
class="math inline"&gt;\(H_1\)&lt;/span&gt;, respectively. We may use &lt;span
class="math inline"&gt;\(Q_n(\pi) \leq q\)&lt;/span&gt;, rather than &lt;span
class="math inline"&gt;\(B_n \leq b\)&lt;/span&gt;, as the relevant criterion for
rejecting &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;. From the pure
frequentist point of view, this doesn’t add anything to our formulation
in terms of the Bayes ratio, as &lt;span class="math inline"&gt;\(Q_n(\pi)\leq
q\)&lt;/span&gt; is equivalent to &lt;span class="math inline"&gt;\(B_n \leq
b\)&lt;/span&gt; as long as &lt;span class="math inline"&gt;\(b =
\frac{q}{1-q}\frac{1-\pi}{\pi}\)&lt;/span&gt;. In particular, the bound
analogous to @ref(eq:TheoremStatement) reads:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\text{Pr}_{H_0}(\mathcal R(q))\leq \text {Pr}_{H_0}(Q_n(\pi) \leq
q\text{ for some }n\in \mathbb N) \leq
\frac{q}{1-q}\frac{1-\pi}{\pi}.(\#eq:TheoremStatement3)
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div id="refs" class="references csl-bib-body hanging-indent"&gt;
&lt;div id="ref-berk2013valid" class="csl-entry"&gt;
Berk, Richard, Lawrence Brown, Andreas Buja, Kai Zhang, and Linda Zhao.
2013. &lt;span&gt;“Valid Post-Selection Inference.”&lt;/span&gt; &lt;em&gt;The Annals of
Statistics&lt;/em&gt;, 802–37.
&lt;/div&gt;
&lt;div id="ref-kerridge1963bounds" class="csl-entry"&gt;
Kerridge, D. 1963. &lt;span&gt;“Bounds for the Frequency of Misleading Bayes
Inferences.”&lt;/span&gt; &lt;em&gt;The Annals of Mathematical Statistics&lt;/em&gt; 34
(3): 1109–10.
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="footnotes footnotes-end-of-document"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;This is a technical term, meaning that &lt;span
class="math inline"&gt;\(H_0\)&lt;/span&gt; completely characterizes the
probability distribution of data. An example of a non-simple hypothesis
would be a parametric model depending on some unknown parameter &lt;span
class="math inline"&gt;\(\theta\)&lt;/span&gt;.&lt;a href="#fnref1"
class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>2cd0556ecb9f91f44d1332f72e39cba8</distill:md5>
      <category>Sequential Hypothesis Testing</category>
      <category>Bayesian Methods</category>
      <category>Frequentist Methods</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-05-22-frequentist-bounds-for-bayesian-sequential-hypothesis-testing</guid>
      <pubDate>Wed, 22 May 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>AIC in the well-specified linear model: theory and simulation</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation</link>
      <description>Some illustrations of the Akaike Information Criterion (AIC) at work in a toy 
example.</description>
      <category>Model Selection</category>
      <category>Linear Models</category>
      <category>Regression</category>
      <category>Statistics</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation</guid>
      <pubDate>Fri, 17 May 2024 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation_files/figure-html5/aic_exp-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Grammar as a biometric for Authorship Verification</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification</link>
      <description>Notes on preprint 2403.08462 by A. Nini, O. Halvani, L. Graner, S. Ishihara 
and myself.</description>
      <category>Authorship Verification</category>
      <category>Natural Language Processing</category>
      <category>Forensic Science</category>
      <category>Machine Learning</category>
      <category>Statistics</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification</guid>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>"Induction and Deduction in Bayesian Data Analysis" by A. Gelman</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman</link>
      <description>On the importance of model checks in Bayesian data analysis.</description>
      <category>Comment on...</category>
      <category>Bayesian Methods</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman</guid>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>"The Abuse of Power" by J. M. Hoenig and D. M. Heisey</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey</link>
      <description>Why observed power calculations are useless (plus a few other points I don't buy).</description>
      <category>Comment on...</category>
      <category>Hypothesis Testing</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey</guid>
      <pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>AIC for the linear model: known vs. unknown variance</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance</link>
      <description>Does knowledge of noise variance have any effect on model selection for the mean?</description>
      <category>Model Selection</category>
      <category>Linear Models</category>
      <category>Regression</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance</guid>
      <pubDate>Wed, 13 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>"A Closer Look at the Deviance" by T. Hastie</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie</link>
      <description>A nice review of properties of Deviance for one parameter exponential 
families.</description>
      <category>Comment on...</category>
      <category>Maximum Likelihood Estimation</category>
      <category>Linear Models</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie</guid>
      <pubDate>Thu, 07 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>No binomial overdispersion from variations at the individual level</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level</link>
      <description>Some notes on the causes of overdispersion in count data.</description>
      <category>Population Dynamics</category>
      <category>Biology</category>
      <category>Ecology</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level</guid>
      <pubDate>Wed, 06 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>On the first and second laws of thermodynamics for open systems</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems</link>
      <description>Matter transfer in open systems changes the relationship between heat and entropy, and work and volume.</description>
      <category>Open Systems</category>
      <category>Thermodynamics</category>
      <category>Physics</category>
      <guid>https://vgherard.github.io/posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems</guid>
      <pubDate>Mon, 04 Mar 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Gravity waves in an ideal fluid</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-02-22-gravity-waves-in-an-ideal-fluid</link>
      <description>Compares the "parcel" method with standard linearization of fluid dynamics equations.</description>
      <category>Atmospheric Physics</category>
      <category>Fluid Dynamics</category>
      <category>Waves</category>
      <category>Physics</category>
      <guid>https://vgherard.github.io/posts/2024-02-22-gravity-waves-in-an-ideal-fluid</guid>
      <pubDate>Thu, 22 Feb 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Binary digits of uniform random variables</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2024-01-29-binary-digits-of-uniform-random-variables</link>
      <description>... are independent fair coin tosses.</description>
      <category>Probability Theory</category>
      <guid>https://vgherard.github.io/posts/2024-01-29-binary-digits-of-uniform-random-variables</guid>
      <pubDate>Mon, 29 Jan 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Interpreting the Likelihood Ratio cost</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-11-15-interpreting-the-likelihood-ratio-cost</link>
      <description>Analysis of infinite sample properties and comparison with cross-entropy loss.</description>
      <category>Forensic Science</category>
      <category>Bayesian Methods</category>
      <category>Information Theory</category>
      <category>Probability Theory</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-11-15-interpreting-the-likelihood-ratio-cost</guid>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost_files/figure-html5/unnamed-chunk-3-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Conditional Probability</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-11-03-conditional-probability</link>
      <description>Notes on the formal definition of conditional probability.</description>
      <category>Probability Theory</category>
      <category>Measure Theory</category>
      <guid>https://vgherard.github.io/posts/2023-11-03-conditional-probability</guid>
      <pubDate>Fri, 03 Nov 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Prefix-free codes</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-10-31-prefix-free-codes</link>
      <description>Generalities about prefix-free (a.k.a. instantaneous) codes</description>
      <category>Information Theory</category>
      <category>Entropy</category>
      <category>Probability Theory</category>
      <guid>https://vgherard.github.io/posts/2023-10-31-prefix-free-codes</guid>
      <pubDate>Tue, 31 Oct 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>AB tests and repeated checks</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-07-24-ab-tests-and-repeated-checks</link>
      <description>False Positive Rates under repeated checks - a simulation study using R.</description>
      <category>AB testing</category>
      <category>Sequential Hypothesis Testing</category>
      <category>Frequentist Methods</category>
      <category>Statistics</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-07-24-ab-tests-and-repeated-checks</guid>
      <pubDate>Thu, 27 Jul 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks_files/figure-html5/unnamed-chunk-7-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Testing functional specification in linear regression</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression</link>
      <description>Some options in R, using the `{lmtest}` package.</description>
      <category>Statistics</category>
      <category>Model Misspecification</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression</guid>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression_files/figure-html5/unnamed-chunk-1-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Sum and ratio of independent random variables</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-06-14-sum-and-ratio-of-independent-random-variables</link>
      <description>Sufficient conditions for independence of sum and ratio.</description>
      <category>Mathematics</category>
      <category>Probability Theory</category>
      <guid>https://vgherard.github.io/posts/2023-06-14-sum-and-ratio-of-independent-random-variables</guid>
      <pubDate>Wed, 14 Jun 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Fisher's Randomization Test</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-06-07-fishers-randomization-test</link>
      <description>Notes and proofs of basic theorems</description>
      <category>Statistics</category>
      <category>Frequentist Methods</category>
      <category>Causal Inference</category>
      <guid>https://vgherard.github.io/posts/2023-06-07-fishers-randomization-test</guid>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>p-values and measure theory</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-06-07-p-values-and-measure-theory</link>
      <description>Self-reassurance that p-value properties don't depend on regularity 
assumptions on the test statistic.</description>
      <category>Probability Theory</category>
      <category>Measure Theory</category>
      <category>Frequentist Methods</category>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2023-06-07-p-values-and-measure-theory</guid>
      <pubDate>Wed, 07 Jun 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Linear regression with autocorrelated noise</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise</link>
      <description>Effects of noise autocorrelation on linear regression. Explicit formulae and a simple simulation.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Time Series</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise</guid>
      <pubDate>Thu, 25 May 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise_files/figure-html5/unnamed-chunk-2-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Model Misspecification and Linear Sandwiches</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches</link>
      <description>Being wrong in the right way. With R excerpts.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches</guid>
      <pubDate>Sun, 14 May 2023 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches_files/figure-html5/unnamed-chunk-7-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Consistency and bias of OLS estimators</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-12-consistency-and-bias-of-ols-estimators</link>
      <description>OLS estimators are consistent but generally biased - here's an example.</description>
      <category>Statistics</category>
      <category>Regression</category>
      <category>Linear Models</category>
      <category>Model Misspecification</category>
      <guid>https://vgherard.github.io/posts/2023-05-12-consistency-and-bias-of-ols-estimators</guid>
      <pubDate>Fri, 12 May 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Bayes, Neyman and the Magic Piggy Bank</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-05-01-magic-piggy-bank</link>
      <description>Compares frequentist properties of credible intervals and confidence 
intervals in a gambling game involving a magic piggy bank.</description>
      <category>Statistics</category>
      <category>Confidence Intervals</category>
      <category>Frequentist Methods</category>
      <category>Bayesian Methods</category>
      <guid>https://vgherard.github.io/posts/2023-05-01-magic-piggy-bank</guid>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Correlation Without Causation</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2023-03-10-correlation-without-causation</link>
      <description>*Cum hoc ergo propter hoc*</description>
      <category>Statistics</category>
      <guid>https://vgherard.github.io/posts/2023-03-10-correlation-without-causation</guid>
      <pubDate>Thu, 30 Mar 2023 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to get away with selection. Part II: Mathematical Framework</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2022-11-07-posi-2</link>
      <description>Mathematicals details on Selective Inference, model misspecification and coverage guarantees.</description>
      <category>Statistics</category>
      <category>Selective Inference</category>
      <category>Model Misspecification</category>
      <guid>https://vgherard.github.io/posts/2022-11-07-posi-2</guid>
      <pubDate>Fri, 25 Nov 2022 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to get away with selection. Part I: Introduction</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2022-10-18-posi</link>
      <description>Introducing the problem of Selective Inference, illustrated through a simple simulation in R.</description>
      <category>Statistics</category>
      <category>Selective Inference</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2022-10-18-posi</guid>
      <pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate>
      <media:content url="https://vgherard.github.io/posts/2022-10-18-posi/posi_files/figure-html5/unnamed-chunk-3-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>kgrams v0.1.2 on CRAN</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-11-13-kgrams-v012-released</link>
      <description>kgrams: Classical k-gram Language Models in R.</description>
      <category>Natural Language Processing</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-11-13-kgrams-v012-released</guid>
      <pubDate>Sat, 13 Nov 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>R Client for R-universe APIs</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-25-r-client-for-r-universe-apis</link>
      <description>{runi}, an R package to interact with R-universe repository APIs</description>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-25-r-client-for-r-universe-apis</guid>
      <pubDate>Sun, 25 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Automatic resumes of your R-developer portfolio from your R-Universe</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api</link>
      <description>Create automatic resumes of your R packages using the R-Universe API.</description>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-21-automatically-resume-your-r-package-portfolio-using-the-r-universe-api</guid>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>{r2r} now on CRAN</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-06-r2r</link>
      <description>Introducing {r2r}, an R implementation of hash tables.</description>
      <category>Data Structures</category>
      <category>R</category>
      <guid>https://vgherard.github.io/posts/2021-07-06-r2r</guid>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Test post</title>
      <dc:creator>Valerio Gherardi</dc:creator>
      <link>https://vgherard.github.io/posts/2021-07-06-test-post</link>
      <description>A short description of the post.</description>
      <category>Other</category>
      <guid>https://vgherard.github.io/posts/2021-07-06-test-post</guid>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>

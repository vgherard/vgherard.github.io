[
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software",
    "section": "",
    "text": "This page contains some selected software projects - mainly R libraries - I am currently or have been working on. See also my GitHub profile and my R-universe website."
  },
  {
    "objectID": "software.html#kgrams",
    "href": "software.html#kgrams",
    "title": "Software",
    "section": "kgrams",
    "text": "kgrams\n  \nkgrams provides tools for training and evaluating \\(k\\)-gram language models, including several probability smoothing methods, perplexity computations, random text generation and more. It is based on an C++ back-end which makes kgrams fast, coupled with an accessible R API which aims at streamlining the process of model building, and can be suitable for small- and medium-sized NLP experiments, baseline model building, and for pedagogical purposes."
  },
  {
    "objectID": "software.html#fcci",
    "href": "software.html#fcci",
    "title": "Software",
    "section": "fcci",
    "text": "fcci\n  \nfcci is an R package providing support for building Feldman-Cousins confidence intervals."
  },
  {
    "objectID": "software.html#r2r",
    "href": "software.html#r2r",
    "title": "Software",
    "section": "r2r",
    "text": "r2r\n  \nr2r provides a flexible implementation of hash tables in R, allowing for:\n\narbitrary R objects as keys and values,\narbitrary key comparison and hash functions,\ncustomizable behaviour (throw or return a default value) on missing key exceptions."
  },
  {
    "objectID": "posts/2024-11-04-exponential-of-a-2x2-matrix/exponential-of-a-2x2-real-matrix.html",
    "href": "posts/2024-11-04-exponential-of-a-2x2-matrix/exponential-of-a-2x2-real-matrix.html",
    "title": "Exponential of a 2x2 real matrix",
    "section": "",
    "text": "Let \\(A\\) be a 2x2 real matrix, with eigenvalues:\n\\[\n\\lambda _{\\pm} = \\frac{\\text {Tr}A}{2}\\pm \\sqrt{\\Delta}, \\qquad \\Delta \\equiv \\left( \\frac{\\text {Tr}A}{2} \\right )^2-\\det A\n\\tag{1}\\]\nIf \\(\\Delta \\neq 0\\), \\(A\\) has two distinct eigenvalues, and we can decompose \\(A\\) as follows:\n\\[\nA = \\lambda _+ P_++\\lambda _-P_-,\n\\tag{2}\\]\nwith:\n\\[\nP_\\pm =\\pm\\dfrac{1}{\\lambda _+ - \\lambda _-}(A-\\lambda _\\mp),\n\\tag{3}\\]\nthat satisfy:\n\\[\n(P_\\pm)^2 = 1, \\quad P_+ P_- = P_- P_+ = 0.\n\\tag{4}\\]\nUsing Equations 3 and 4, one can immediately compute the exponential:\n\\[\ne^A = e^{\\lambda _+} P_+ + e^{\\lambda _-} P_- \\qquad (\\Delta \\neq 0)\n\\tag{5}\\]\nWe can obtain the case \\(\\Delta = 0\\) from the \\(\\Delta \\to 0\\) limit of Equation 5. Observing that:\n\\[\nP_+ + P_- = 1, \\qquad P_+-P_- = \\frac{1}{\\sqrt{\\Delta}}(A-\\frac{\\text {Tr}A}{2}),\n\\tag{6}\\]\nfrom Equation 5 we find:\n\\[\ne^{-\\frac{\\text{Tr}A}{2}}e^A =  A + 1-\\frac{\\text {Tr}A}{2}+O(\\sqrt \\Delta) \\quad(\\Delta \\to 0),\n\\tag{7}\\]\nthat yields:\n\\[\ne^A =  e^{\\frac{\\text{Tr}A}{2}}\\left(A + 1-\\frac{\\text {Tr}A}{2}\\right) \\quad(\\Delta = 0).\n\\tag{8}\\]\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {Exponential of a 2x2 Real Matrix},\n  date = {2024-11-04},\n  url = {https://vgherard.github.io/posts/2024-11-04-exponential-of-a-2x2-matrix/exponential-of-a-2x2-real-matrix.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “Exponential of a 2x2 Real\nMatrix.” November 4, 2024. https://vgherard.github.io/posts/2024-11-04-exponential-of-a-2x2-matrix/exponential-of-a-2x2-real-matrix.html."
  },
  {
    "objectID": "posts/2024-07-01-the-uv-diagram-for-a-pure-substance/the-uv-diagram-for-a-pure-substance.html",
    "href": "posts/2024-07-01-the-uv-diagram-for-a-pure-substance/the-uv-diagram-for-a-pure-substance.html",
    "title": "The UV diagram for a pure substance",
    "section": "",
    "text": "The thermodynamic states of pure substances and their phase transitions are often represented in \\(PT\\) (pressure-temperature) and \\(PV\\) (pressure-volume) diagrams. While reading the classic paper from Lieb and Yngvason (Lieb and Yngvason 1999a) ( see my commentary here) I learned about a third possible description, in terms of the extensive volume \\(V\\) and internal energy \\(U\\).\nBeside the important role that the \\((U,V)\\) parametrization plays in the axiomatic formulation of thermodynamics given in (Lieb and Yngvason 1999a), which makes \\(UV\\) diagrams interesting per se, there’s a practical advantage in these two variables, in the fact that they uniquely characterize pure substances everywhere in the phase diagram. In particular, a triple “point” becomes a triangle in the UV diagram, as can be seen by the parametrization:\n\\[\nU = m_gu_g+ m_\\ell u_\\ell+m_su_s,\\quad V = m_gv_g+m_\\ell v_\\ell+m_sv_s,\n\\] where \\(m_i\\), \\(u_i\\) and \\(v_i\\) are the masses, specific internal energy and volumes of the gaseous, liquid and solid phases, respectively (the total mass \\(m = m_g + m_\\ell + m_s\\) is assumed to be fixed). This triangle is projected into a line in the \\(PV\\) diagram, and into a single point in the \\(PT\\) diagram.\nThe subsets of the \\(UV\\) plane representing the fusion, sublimation and vaporization curves (or any other curve on the \\(PT\\) diagram representing the coexistence of two distinct phases) are still two dimensional submanifolds, but the parametrization is more involved:\n\\[\nU = m_A u_A(T) + m_B u_B(T),\\quad V=m_A v_A(T) + m_B v_B(T),\n\\] where \\(A\\) and \\(B\\) are the two coexisting phases, and the specific energies and volumes vary with temperature. These sets are obtained by joining for each value of \\(T\\) the two corresponding points on the curves \\(\\gamma _A(T) = m\\cdot(u_A(T),v_A(T))\\) and \\(\\gamma _B(T) = m\\cdot(u_B(T), v_B(T))\\) in the \\(UV\\) plane.\nBy pure coincidence, an example of the diagrams I am referring to is shown in (Lieb and Yngvason 1999b), the erratum to the original reference (Lieb and Yngvason 1999a).\n\n\n\n\nReferences\n\nLieb, Elliott H., and Jakob Yngvason. 1999a. “The Physics and Mathematics of the Second Law of Thermodynamics.” Physics Reports 310 (1): 1–96. https://doi.org/https://doi.org/10.1016/S0370-1573(98)00082-9.\n\n\n———. 1999b. “The Physics and Mathematics of the Second Law of Thermodynamics (Physics Reports 310 (1999) 1–96).” Physics Reports 314 (6): 669. https://doi.org/https://doi.org/10.1016/S0370-1573(99)00029-0.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {The {UV} Diagram for a Pure Substance},\n  date = {2024-07-01},\n  url = {https://vgherard.github.io/posts/2024-07-01-the-uv-diagram-for-a-pure-substance/the-uv-diagram-for-a-pure-substance.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “The UV Diagram for a Pure\nSubstance.” July 1, 2024. https://vgherard.github.io/posts/2024-07-01-the-uv-diagram-for-a-pure-substance/the-uv-diagram-for-a-pure-substance.html."
  },
  {
    "objectID": "posts/2024-06-03-data-fission-splitting-a-single-data-point-by-leiner-et-al/data-fission-splitting-a-single-data-point-by-leiner-et-al.html",
    "href": "posts/2024-06-03-data-fission-splitting-a-single-data-point-by-leiner-et-al/data-fission-splitting-a-single-data-point-by-leiner-et-al.html",
    "title": "“Data Fission: Splitting a Single Data Point” by Leiner et al.",
    "section": "",
    "text": "(James Leiner and Ramdas 2023). The arXiv version is actually a bit more comfortable to read. Abstract:\n\nSuppose we observe a random vector \\(X\\) from some distribution in a known family with unknown parameters. We ask the following question: when is it possible to split \\(X\\) into two pieces \\(f(X)\\) and \\(g(X)\\) such that neither part is sufficient to reconstruct \\(X\\) by itself, but both together can recover \\(X\\) fully, and their joint distribution is tractable? One common solution to this problem when multiple samples of \\(X\\) are observed is data splitting, but Rasines and Young offers an alternative approach that uses additive Gaussian noise — this enables post-selection inference in finite samples for Gaussian distributed data and asymptotically when errors are non-Gaussian. In this article, we offer a more general methodology for achieving such a split in finite samples by borrowing ideas from Bayesian inference to yield a (frequentist) solution that can be viewed as a continuous analog of data splitting. We call our method data fission, as an alternative to data splitting, data carving and \\(p\\)-value masking. We exemplify the method on several prototypical applications, such as post-selection inference for trend filtering and other regression problems, and effect size estimation after interactive multiple testing. Supplementary materials for this article are available online.\n\nThe paper offers a clear review and systematization of older work, most prominently (Rasines and Young 2022) (cited in the abstract), with some useful generalizations.\nThe idea is cool, but I find the applications to practical regression cases given in the paper somewhat… impractical. For usual linear regression with a continuous response, the applicability of the method relies on (1) noise being homoskedastic and gaussian, (2) the existence of a consistent estimator \\(\\hat \\sigma\\) of noise variance, and (3) samples being large enough (guarantees are only asymptotic). On the other hand, in the theoretically simpler case of logistic regression, there’s a technical complication in that, under the usual GLM assumption \\(\\theta(X) = X\\beta\\), the relevant log-likelihood for maximization in the inferential stage is not a concave function of \\(\\beta\\), possibly hindering optimization. If I got it right, the authors suggest to ignore the conditional dependence of \\(g(Y_i)\\) on \\(f(Y_i)\\) to circumvent these complications (see Appendix E.4), which I honestly don’t understand.\nA case in which planets align and results have a nice analytic form is that of Poisson regression, for which I will sketch the idea in some detail. Suppose that we are given data \\(\\mathcal D _0 = \\{(X_i,Y_i)\\}_{i=1}^N\\) independently drawn from a joint \\((X,Y)\\) distribution, and we assume \\(Y \\vert X \\sim \\text{Pois}(\\lambda (X))\\) for some unknown function \\(\\lambda (X)\\) we would like to model. The key observation is (cf. Appendix A of the reference) that if \\(Z \\vert Y \\sim \\text{Binom}(Y,\\,p)\\), then \\(Z \\sim \\text {Pois}(p\\lambda)\\) and \\(\\overline Z = Y - Z \\sim \\text{Pois}((1-p)\\lambda)\\), with \\(Z\\) and \\(\\overline Z\\) unconditionally independent. Hence, if we randomly draw \\(Z _i\\) according to \\(\\text{Binom}(Y_i,\\,p)\\), and set \\(\\overline Z _i = Y_i -Z_i\\), the two datasets \\(\\mathcal D = \\{(X_i,\\,Z_i)\\}\\) and \\(\\overline{\\mathcal D} = \\{(X_i,\\,\\overline Z_i)\\}\\), are conditionally independent given the observed covariates \\(X_i\\). This allows to decouple different aspects of modeling, such as model selection and inference, avoiding the usual biases associated with the intrinsic randomness of the selection step.\nThe authors focus on regression with fixed covariates, because in that setting the simpler option of data-splitting is less motivated, calling for alternatives. However, the method can be applied equally well to deal with selective inference in random covariates settings, since it leads - at least in principle - to inferences which are valid conditionally on the observed covariates and (in the general case) the randomized responses \\(f(Y_i)\\) of the selection stage.\n\n\n\n\nReferences\n\nJames Leiner, Larry Wasserman, Boyan Duan, and Aaditya Ramdas. 2023. “Data Fission: Splitting a Single Data Point.” Journal of the American Statistical Association 0 (0): 1–12. https://doi.org/10.1080/01621459.2023.2270748.\n\n\nRasines, D García, and G A Young. 2022. “Splitting strategies for post-selection inference.” Biometrika 110 (3): 597–614. https://doi.org/10.1093/biomet/asac070.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {“{Data} {Fission:} {Splitting} a {Single} {Data} {Point}” by\n    {Leiner} Et Al.},\n  date = {2024-06-03},\n  url = {https://vgherard.github.io/posts/2024-06-03-data-fission-splitting-a-single-data-point-by-leiner-et-al/data-fission-splitting-a-single-data-point-by-leiner-et-al.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “‘Data Fission: Splitting a Single\nData Point’ by Leiner Et Al.” June 3, 2024. https://vgherard.github.io/posts/2024-06-03-data-fission-splitting-a-single-data-point-by-leiner-et-al/data-fission-splitting-a-single-data-point-by-leiner-et-al.html."
  },
  {
    "objectID": "posts/2024-05-23-authorship-attribution-in-lennon-mccartney-songs/authorship-attribution-in-lennon-mccartney-songs.html",
    "href": "posts/2024-05-23-authorship-attribution-in-lennon-mccartney-songs/authorship-attribution-in-lennon-mccartney-songs.html",
    "title": "Authorship Attribution in Lennon-McCartney Songs",
    "section": "",
    "text": "(Glickman, Brown, and Song 2019). An enjoyable read. The authors present a statistical analysis of the Beatles’ repertoire from the point of view of authorship (Lennon vs. McCartney), a topic with which I’ve been lately involved. As a side-note, this also made me discover the Harvard Data Science Review.\nFrom the paper’s abstract:\n\nThe songwriting duo of John Lennon and Paul McCartney, the two founding members of the Beatles, composed some of the most popular and memorable songs of the last century. Despite having authored songs under the joint credit agreement of Lennon-McCartney, it is well-documented that most of their songs or portions of songs were primarily written by exactly one of the two. Furthermore, the authorship of some Lennon-McCartney songs is in dispute, with the recollections of authorship based on previous interviews with Lennon and McCartney in conflict. For Lennon-McCartney songs of known and unknown authorship written and recorded over the period 1962-66, we extracted musical features from each song or song portion. These features consist of the occurrence of melodic notes, chords, melodic note pairs, chord change pairs, and four-note melody contours. We developed a prediction model based on variable screening followed by logistic regression with elastic net regularization. Out-of-sample classification accuracy for songs with known authorship was 76%, with a c-statistic from an ROC analysis of 83.7%. We applied our model to the prediction of songs and song portions with unknown or disputed authorship.\n\nThe modeling approach looks to me very sound and appropriate to the small sample size available (\\(N = 70\\), the statistical unit corresponding to a song of known authorship). Effective model selection and testing is achieved through three nested layers of cross-validation (😱): one for elastic net hyperparameter tuning, one for feature screening, and finally one for estimating the prediction error.\nThe discussion of feature importance is insightful, in that it identifies concrete aspects of McCartney’s compositions that make them distinguishable from Lennon’s ones. This type of interpretability is a big plus for authorship analysis. The general qualitative conclusion, that McCartney’s music tended to exhibit more complex and unusual patterns kinda resonates with my perception of Beatles’ songs.\nArmed with the trained logistic regression model, together with a valid accuracy estimate (76%), the authors set out to apply their model to authorship prediction for controversial cases within the Beatles’ corpus (outside of the training sample). I don’t fully understand the authors approach in this part of the paper, and some points appear to be questionable, for the reasons I explain below.\nOne of the advantages of fitting a full probability model, such as logistic regression, rather than a conceptually simpler pure classification model (like a tree, for example), is that the output of the former is not a mere class (McCartney or Lennon), but rather a probability of belonging to that class. This allows one to make much more informative statements in the analysis of new cases, since the strength of evidence provided by the data towards the predicted class can be quantified on a case by case basis. All of this is true, of course, provided that the fitted model gives a decent approximation to the true data generating process.\nWith similar considerations in mind, I suppose, the authors produce probability estimates for each of the disputed cases considered, in the form of a point estimate and a confidence interval to represent uncertainty. I think there is room for improvement here, in two aspects.\nMy first objection is what I already pointed out above: nothing in the modeling process explained in the paper suggests that the final model provides a good approximation to the true class probability conditional on features. The model has, with reasonable confidence, a predictive performance close to the best achievable within the possibilities considered - quantified by 76% accuracy and 84% AUC - but this says nothing about its correct specification as a probability model. Without a careful specification study, it is impossible to conclude anything on the nature of the true estimation targets of the fitted “probabilities”: they may perfectly have nothing to do with the actual \\(\\text{Pr}(\\text{author}\\,\\vert\\, \\text{song features})\\) the authors are after. There is still value, I believe, in reporting fitted probabilities as qualitative measures of evidence, but these should not be conflated with the true (unknown) class probabilities… at least without some serious attempt to detect differences between the two.\nMy second point is a technical one and concerns how they construct confidence intervals for fitted probabilities. The construction resembles that of bootstrap percentile confidence intervals but, rather than the usual bootstrap synthetic datasets, the delete-one datasets used in leave-one-out cross-validation are used to obtain replicas of the fitted probabilities. This is nothing but Jackknife resampling in disguise, and it is well known that the resampling standard deviation of such Jackknife replicae is roughly \\(N ^{-1/2}\\) times the true standard deviation, see e.g. (Tibshirani and Efron 1993). Therefore, I have strong reasons to believe that the reported intervals strongly underestimate the uncertainty associated with these probability estimates.\nAll in all, the attempt to go beyond reporting simple classes - backed up by an overall 76% accuracy estimate - is well-motivated in principle, but the final outcome is not very dependable.\nAs usual, I’m more eloquent when criticizing than when praising, but let me end on a very positive note. The authors do a great favor to the reader, by including a discussion of the informal steps performed prior and in parallel to the formal analysis presented in the paper. This kind of transparency - which is also present in the rest of the discussion - is, I believe, not so common as it should, and is what makes it eventually possible to think critically about someone else’s work.\n\n\n\n\nReferences\n\nGlickman, Mark, Jason Brown, and Ryan Song. 2019. “(A) Data in the Life: Authorship Attribution in Lennon-McCartney Songs.” Harvard Data Science Review 1 (1).\n\n\nTibshirani, Robert J, and Bradley Efron. 1993. “An Introduction to the Bootstrap.” Monographs on Statistics and Applied Probability 57 (1): 1–436.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {Authorship {Attribution} in {Lennon-McCartney} {Songs}},\n  date = {2024-05-23},\n  url = {https://vgherard.github.io/posts/2024-05-23-authorship-attribution-in-lennon-mccartney-songs/authorship-attribution-in-lennon-mccartney-songs.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “Authorship Attribution in\nLennon-McCartney Songs.” May 23, 2024. https://vgherard.github.io/posts/2024-05-23-authorship-attribution-in-lennon-mccartney-songs/authorship-attribution-in-lennon-mccartney-songs.html."
  },
  {
    "objectID": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html",
    "href": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html",
    "title": "AIC in the well-specified linear model: theory and simulation",
    "section": "",
    "text": "Consider the AIC for the usual linear model \\(Y = X\\beta + \\varepsilon\\):\n\\[\n\\text{AIC} = \\frac{1}{2}\\ln(2\\pi e\\hat \\sigma^2)+\\frac{p+1}{N}\n\\tag{1}\\]\nwhere \\(p\\) is the dimension of the covariate vector \\(X\\) and \\(\\hat \\sigma ^2\\) is the ML estimate of the \\(Y\\vert X\\) conditional variance. The expectation of Equation 1 under model assumptions can be found by using the fact that, for a \\(\\chi^2\\) random variable with \\(\\nu\\) degrees of freedom1:\n\\[\n\\mathbb E(\\ln\\chi ^2 )=\\ln2+ \\psi(\\frac{\\nu}{2})\n\\tag{2}\\]\nwhere: \\[\n\\psi(x)\\equiv\\frac{\\text d}{\\text d x}\\ln \\Gamma(x) \\approx \\ln x-\\frac{1}{2x}\n\\tag{3}\\]\nand the second equality results from the Stirling approximation \\(\\Gamma(x) = \\sqrt{2\\pi}x^{x-\\frac{1}{2}}e^{-x}\\). We obtain:\n\\[\n\\mathbb E(\\text{AIC}) = \\frac{\\ln \\left[2\\pi e\\mathbb V(Y\\vert X)\\right] }{2}+\\frac{1}{2}\\ln\\left(\\frac{N-p}{2}\\right)-\\frac{1}{2}\\frac{1}{N-p}+\\frac{p+1}{N},\n\\tag{4}\\]\nwhere, according to standard assumptions, \\(\\mathbb V(Y \\vert X)\\) is assumed to be constant in \\(X\\).\nNow consider two such models, with different covariate vectors \\(X_1\\) and \\(X_2\\), of dimension \\(p_1\\) and \\(p_2\\) respectively, both assumed to be well specified. Denote, as before:\n\\[\n\\text{AIC}_i =\\frac{1}{2}\\ln(2\\pi e\\hat \\sigma^2_i)+\\frac{p_i+1}{N}\n\\tag{5}\\]\nfor \\(i = 1,\\,2\\). Equation 4 gives the unconditional expectation of \\(\\text{AIC}\\) for both models2, so that:\n\\[\n\\mathbb E(\\text{AIC}_1 - \\text{AIC}_2) = \\frac{1}{2}\\ln\\left(\\frac{\\mathbb V(Y\\vert X_1)}{\\mathbb V(Y\\vert X_2)}\\right)+\\frac{p_1-p_2}{2N}+\\mathcal O(N^{-2}).\n\\tag{6}\\]\nAssuming, without loss of generality, that \\(p_1 \\leq p_2\\), we have:\n\\[\n\\mathbb E(\\text{AIC}_1 - \\text{AIC}_2) &lt; 0 \\iff N &lt; \\frac{p_2-p_1}{\\ln\\left(\\frac{\\mathbb V(Y\\vert X_1)}{\\mathbb V(Y\\vert X_2)}\\right)}.\n\\tag{7}\\]\nTo gain some intuition, suppose that the set of variables contained in \\(X_1\\) is a subset of those contained in \\(X_2\\), so that the two corresponding models are nested. Equation 7 tells us that, for \\(N\\) below a certain threshold, AIC will prefer the more “parsimonious” model involving \\(X_1\\) only. In particular, if \\(\\mathbb V(Y\\vert X_1)\\approx \\mathbb V(Y\\vert X_2)\\), we can make a first-order approximation in the RHS of Equation 7, that yields:\n\\[\nN \\lesssim \\frac{\\mathbb V(Y\\vert X_2)}{\\mathbb V(Y\\vert X_1)-\\mathbb V(Y\\vert X_2)}(p_2-p_1).\n\\tag{8}\\]\n\n\n\nIn parallel to AIC, we can consider the exact “information criterion” provided by the model in-sample cross-entropy under the true data generating process. For a single linear model, the in-sample cross-entropy is:\n\\[\n\\text{CE}_{\\text {in}} = \\frac{1}{2}\\ln(2\\pi e \\hat \\sigma ^2) +\\frac{1}{2}\\frac{\\sigma ^2-\\hat \\sigma ^2+\\frac{1}{N}(\\beta-\\hat{\\beta})^{T}\\mathbf{X}^{T}\\mathbf{X}(\\beta-\\hat{\\beta})}{\\hat \\sigma ^2}.\n\\tag{9}\\]\n(“in-sample” refers to the fact that we fix, i.e. condition, on the covariate vector of the training sample, \\(\\mathbf X\\).) The \\(\\mathbf X\\) conditional expectation of \\(\\text{CE}_{\\text {in}}\\), again under model assumptions, can be computed by noticing two facts:\n\nThe numerator and denominator are conditionally independent \\(\\chi^2\\) variables with \\(p\\) and \\(N-p\\) degrees of freedom respectively. This can be seen by rewriting these as \\(\\boldsymbol \\epsilon ^T \\mathbf H \\boldsymbol \\epsilon\\), and \\(\\boldsymbol \\epsilon ^T (1-\\mathbf H) \\boldsymbol \\epsilon\\), respectively, where \\(\\mathbf H = \\mathbf X (\\mathbf X ^T \\mathbf X)^{-1} \\mathbf X ^T\\) as usual.\nFor a \\(\\chi ^2\\) random variable with \\(\\nu\\) degrees of freedom we have \\(\\mathbb E(\\frac{1}{\\chi ^2})=\\frac{1}{\\nu - 2}\\).\n\nUsing these results, we can show that:\n\\[\n\\mathbb E(\\text{CE}_{\\text {in}}\\vert \\mathbf X)=\\mathbb E(\\text{AIC}\\vert \\mathbf X)+\\mathcal O(N^{-2})\n\\tag{10}\\]\n(an equation which is true by design of AIC).\nBefore rushing to the (wrong) conclusion that \\(\\text{AIC}_1 - \\text{AIC}_2\\) will correspondingly estimate a difference of expected cross-entropies, let us notice that the relevant in-sample cross-entropy to be considered for model evaluation is Equation 9 with \\(\\mathbf X\\) corresponding to the full covariate vector: this is the target we should try to estimate (at least to the extent that our goal is predicting \\(Y\\) given \\(X\\)). For this reason, strictly speaking, Equation 10 is exact only if our model is well specified as a model of \\(Y \\vert X\\). Otherwise, in order to estimate consistently \\(\\mathbb E(\\text{CE}_{\\text {in}}\\vert \\mathbf X)\\), we should use Takeuchi’s Information Criterion (TIC) rather than AIC.\nA bit more pragmatically, in the real world we could assume the remainder of Equation 10 to be \\(\\mathcal O (N^{-1})\\) (rather than \\(\\mathcal O (N^{-2})\\)), but generally small with respect the leading order AIC correction (\\(\\frac{p+1}{N}\\)). This will be the case if the models being compared are approximately well specified."
  },
  {
    "objectID": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html#theory",
    "href": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html#theory",
    "title": "AIC in the well-specified linear model: theory and simulation",
    "section": "",
    "text": "Consider the AIC for the usual linear model \\(Y = X\\beta + \\varepsilon\\):\n\\[\n\\text{AIC} = \\frac{1}{2}\\ln(2\\pi e\\hat \\sigma^2)+\\frac{p+1}{N}\n\\tag{1}\\]\nwhere \\(p\\) is the dimension of the covariate vector \\(X\\) and \\(\\hat \\sigma ^2\\) is the ML estimate of the \\(Y\\vert X\\) conditional variance. The expectation of Equation 1 under model assumptions can be found by using the fact that, for a \\(\\chi^2\\) random variable with \\(\\nu\\) degrees of freedom1:\n\\[\n\\mathbb E(\\ln\\chi ^2 )=\\ln2+ \\psi(\\frac{\\nu}{2})\n\\tag{2}\\]\nwhere: \\[\n\\psi(x)\\equiv\\frac{\\text d}{\\text d x}\\ln \\Gamma(x) \\approx \\ln x-\\frac{1}{2x}\n\\tag{3}\\]\nand the second equality results from the Stirling approximation \\(\\Gamma(x) = \\sqrt{2\\pi}x^{x-\\frac{1}{2}}e^{-x}\\). We obtain:\n\\[\n\\mathbb E(\\text{AIC}) = \\frac{\\ln \\left[2\\pi e\\mathbb V(Y\\vert X)\\right] }{2}+\\frac{1}{2}\\ln\\left(\\frac{N-p}{2}\\right)-\\frac{1}{2}\\frac{1}{N-p}+\\frac{p+1}{N},\n\\tag{4}\\]\nwhere, according to standard assumptions, \\(\\mathbb V(Y \\vert X)\\) is assumed to be constant in \\(X\\).\nNow consider two such models, with different covariate vectors \\(X_1\\) and \\(X_2\\), of dimension \\(p_1\\) and \\(p_2\\) respectively, both assumed to be well specified. Denote, as before:\n\\[\n\\text{AIC}_i =\\frac{1}{2}\\ln(2\\pi e\\hat \\sigma^2_i)+\\frac{p_i+1}{N}\n\\tag{5}\\]\nfor \\(i = 1,\\,2\\). Equation 4 gives the unconditional expectation of \\(\\text{AIC}\\) for both models2, so that:\n\\[\n\\mathbb E(\\text{AIC}_1 - \\text{AIC}_2) = \\frac{1}{2}\\ln\\left(\\frac{\\mathbb V(Y\\vert X_1)}{\\mathbb V(Y\\vert X_2)}\\right)+\\frac{p_1-p_2}{2N}+\\mathcal O(N^{-2}).\n\\tag{6}\\]\nAssuming, without loss of generality, that \\(p_1 \\leq p_2\\), we have:\n\\[\n\\mathbb E(\\text{AIC}_1 - \\text{AIC}_2) &lt; 0 \\iff N &lt; \\frac{p_2-p_1}{\\ln\\left(\\frac{\\mathbb V(Y\\vert X_1)}{\\mathbb V(Y\\vert X_2)}\\right)}.\n\\tag{7}\\]\nTo gain some intuition, suppose that the set of variables contained in \\(X_1\\) is a subset of those contained in \\(X_2\\), so that the two corresponding models are nested. Equation 7 tells us that, for \\(N\\) below a certain threshold, AIC will prefer the more “parsimonious” model involving \\(X_1\\) only. In particular, if \\(\\mathbb V(Y\\vert X_1)\\approx \\mathbb V(Y\\vert X_2)\\), we can make a first-order approximation in the RHS of Equation 7, that yields:\n\\[\nN \\lesssim \\frac{\\mathbb V(Y\\vert X_2)}{\\mathbb V(Y\\vert X_1)-\\mathbb V(Y\\vert X_2)}(p_2-p_1).\n\\tag{8}\\]\n\n\n\nIn parallel to AIC, we can consider the exact “information criterion” provided by the model in-sample cross-entropy under the true data generating process. For a single linear model, the in-sample cross-entropy is:\n\\[\n\\text{CE}_{\\text {in}} = \\frac{1}{2}\\ln(2\\pi e \\hat \\sigma ^2) +\\frac{1}{2}\\frac{\\sigma ^2-\\hat \\sigma ^2+\\frac{1}{N}(\\beta-\\hat{\\beta})^{T}\\mathbf{X}^{T}\\mathbf{X}(\\beta-\\hat{\\beta})}{\\hat \\sigma ^2}.\n\\tag{9}\\]\n(“in-sample” refers to the fact that we fix, i.e. condition, on the covariate vector of the training sample, \\(\\mathbf X\\).) The \\(\\mathbf X\\) conditional expectation of \\(\\text{CE}_{\\text {in}}\\), again under model assumptions, can be computed by noticing two facts:\n\nThe numerator and denominator are conditionally independent \\(\\chi^2\\) variables with \\(p\\) and \\(N-p\\) degrees of freedom respectively. This can be seen by rewriting these as \\(\\boldsymbol \\epsilon ^T \\mathbf H \\boldsymbol \\epsilon\\), and \\(\\boldsymbol \\epsilon ^T (1-\\mathbf H) \\boldsymbol \\epsilon\\), respectively, where \\(\\mathbf H = \\mathbf X (\\mathbf X ^T \\mathbf X)^{-1} \\mathbf X ^T\\) as usual.\nFor a \\(\\chi ^2\\) random variable with \\(\\nu\\) degrees of freedom we have \\(\\mathbb E(\\frac{1}{\\chi ^2})=\\frac{1}{\\nu - 2}\\).\n\nUsing these results, we can show that:\n\\[\n\\mathbb E(\\text{CE}_{\\text {in}}\\vert \\mathbf X)=\\mathbb E(\\text{AIC}\\vert \\mathbf X)+\\mathcal O(N^{-2})\n\\tag{10}\\]\n(an equation which is true by design of AIC).\nBefore rushing to the (wrong) conclusion that \\(\\text{AIC}_1 - \\text{AIC}_2\\) will correspondingly estimate a difference of expected cross-entropies, let us notice that the relevant in-sample cross-entropy to be considered for model evaluation is Equation 9 with \\(\\mathbf X\\) corresponding to the full covariate vector: this is the target we should try to estimate (at least to the extent that our goal is predicting \\(Y\\) given \\(X\\)). For this reason, strictly speaking, Equation 10 is exact only if our model is well specified as a model of \\(Y \\vert X\\). Otherwise, in order to estimate consistently \\(\\mathbb E(\\text{CE}_{\\text {in}}\\vert \\mathbf X)\\), we should use Takeuchi’s Information Criterion (TIC) rather than AIC.\nA bit more pragmatically, in the real world we could assume the remainder of Equation 10 to be \\(\\mathcal O (N^{-1})\\) (rather than \\(\\mathcal O (N^{-2})\\)), but generally small with respect the leading order AIC correction (\\(\\frac{p+1}{N}\\)). This will be the case if the models being compared are approximately well specified."
  },
  {
    "objectID": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html#simulation",
    "href": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html#simulation",
    "title": "AIC in the well-specified linear model: theory and simulation",
    "section": "Simulation",
    "text": "Simulation\n\nSetup\nWe take the data generating process to be:\n\\[\nY = m X + q + \\varepsilon,\n\\tag{11}\\]\nwith:\n\\[\nX \\sim \\mathcal N (0,\\,1),\\quad \\varepsilon \\sim \\mathcal N(0,\\,1),\\quad \\varepsilon \\perp X.\n\\tag{12}\\]\n\nm &lt;- 0.1\nq &lt;- 0\n\nrxy &lt;- function(n) {\n    tibble(\n        x = rnorm(n, sd = 1),\n        y = m * x + q + rnorm(n, sd = 1)\n        )\n}\n\nWe compare the model with vs. without slope term (\\(m = 0\\) vs. \\(m \\neq 0\\)), which we will denote by suffixes \\(1\\) and \\(1\\oplus X\\), respectively. The functions below compute AIC and in-sample cross-entropy from the corresponding lm objects. We also define a “Naive Information Criterion” \\(\\text{NIC} \\equiv \\log(\\hat \\sigma)\\).\n\nnic &lt;- function(fit) {\n    p &lt;- length(coef(fit))\n    n &lt;- nobs(fit)\n    sigma_hat &lt;- sigma(fit) * sqrt((n - p) / n)\n    \n    log(sigma_hat)\n}\n\naic &lt;- function(fit) {\n    p &lt;- length(coef(fit))\n    n &lt;- nobs(fit)\n    sigma_hat &lt;- sigma(fit) * sqrt((n - p) / n)\n    \n    log(sigma_hat) + (p + 1) / n + 0.5 *(1 + log(2*pi))\n}\n\nce &lt;- function(fit, data) {\n    p &lt;- length(coef(fit))\n    n &lt;- nobs(fit)\n    sigma_hat &lt;- sigma(fit) * sqrt((n - p) / n)\n    y_hat &lt;- fitted(fit)\n    mu &lt;- data$x * m + q\n    \n    res &lt;- 0\n    res &lt;- res + 0.5 / (sigma_hat^2)\n    res &lt;- res + log(sigma_hat)\n    res &lt;- res + mean(0.5 * (y_hat - mu)^2 / (sigma_hat^2))\n    res &lt;- res + 0.5 * log(2 * pi)\n\n    return(res)\n}\n\nFrom our results above, we expect:\n\\[\n\\mathbb E(\\text{AIC}_{1\\oplus X}-\\text{AIC}_{1} )&lt;0 \\iff N \\geq \\frac{1}{\\ln(1+m^2)}\\left(1+\\mathcal O(m^2 )\\right)\n\\tag{13}\\]\nThe expected in-sample cross-entropies cannot be computed explicitly, but for relatively small \\(m^2\\) we expect (cf. Equation 10):\n\\[\n\\mathbb E((\\text{CE}_{\\text {in}})_i)=\\mathbb E(\\text{AIC}_i)+\\mathcal O(N^{-2},\\,m^2N^{-1}),\n\\tag{14}\\]\nI will use tidyverse for plotting results.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nIn order to make results reproducible let’s:\n\nset.seed(840)\n\n\n\nResults\nWe simulate fitting models \\(1\\) and \\(1\\oplus X\\) at different sample sizes from the data generating process described above.\n\nfits &lt;- tidyr::expand_grid(\n        n = 10 ^ seq(from = 1, to = 3, by = 0.5), b = 1:1e3\n        ) |&gt;\n    mutate(data = lapply(n, rxy)) |&gt;\n    group_by(n, b, data) |&gt;\n    tidyr::expand(model = c(y ~ 1, y ~ x)) |&gt;\n    ungroup() |&gt;\n    mutate(\n        fit = lapply(row_number(), \\(i) lm(model[[i]], data = data[[i]])),\n        ce = sapply(row_number(), \\(i) ce(fit[[i]], data[[i]])),\n        aic = sapply(fit, aic),\n        nic = sapply(fit, nic),\n        model = format(model)\n        ) |&gt;\n    select(-c(fit, data))\n\nThe plots below show the dependence from sample size of \\(\\mathbb E(\\Delta\\text{AIC})\\) and \\(\\mathbb E(\\Delta\\text{CE}_\\text{in})\\), as well as AIC selection frequencies. Notice that for \\(N = \\frac{1}{m^2}\\), even though \\(\\mathbb E(\\Delta\\text{AIC}) = 0\\), the selection frequency of the “complex” model \\(1\\oplus X\\) is still below \\(\\text{50 %}\\). This is because the distribution of \\(\\Delta\\text{AIC}\\) is asymmetric, as seen in the second plot, and \\(\\mathbb E(\\Delta\\text{AIC}) &lt; \\text {median}(\\Delta\\text{AIC})\\).\n\nfits |&gt;\n    mutate(\n        is_baseline = model == \"y ~ 1\",\n        delta_ce = ce - ce[is_baseline], \n        delta_aic = aic - aic[is_baseline],\n        delta_nic = nic - nic[is_baseline],\n        .by = c(n, b),\n        ) |&gt;\n    filter(!is_baseline) |&gt;\n    summarise(\n        `E( ΔCE )` = mean(delta_ce), \n        `E( ΔAIC )` = mean(delta_aic),\n        `E( ΔNIC )` = mean(delta_nic),\n        .by = n\n        ) |&gt;\n    tidyr::pivot_longer(\n        -n, names_to = \"metric\", values_to = \"value\"\n    ) |&gt;\n    ggplot(aes(x = n, y = value, color = metric)) +\n        geom_point() +\n        geom_line() +\n        geom_hline(yintercept = 0, linetype = \"dashed\") +\n        geom_vline(aes(xintercept = 1 / m^2), linetype = \"dotted\") +\n        scale_x_log10(\"Sample Size\") +\n        coord_cartesian(ylim = c(-0.025, 0.025)) + ylab(expression(IC)) +\n        theme(legend.position = \"bottom\", legend.title = element_blank()) +\n        ggtitle(\"AIC vs. in-sample cross-entropy\", \"Expected values\") +\n        NULL\n\n\n\n\n\n\n\n\n\nfits |&gt;\n    filter(aic == min(aic), .by = c(n, b)) |&gt;\n    summarise(count = n(), .by = c(n, model)) |&gt;\n    ggplot(aes(fill = model, x = n, y = count)) + \n        geom_col() + \n        scale_x_log10(\"Sample Size\") +\n        ylab(\"Count\") +\n        theme(legend.position = \"bottom\") +\n        ggtitle(\"AIC model selection frequencies\")\n\n\n\n\n\n\n\n\n\nfits |&gt;\n    filter(n %in% c(10, 100, 1000)) |&gt;\n    mutate(delta_aic = aic - aic[model == \"y ~ 1\"], .by = c(n, b)) |&gt;\n    filter(model != \"y ~ 1\") |&gt;\n    mutate(expec = -0.5 * log(1 + m^2) + 0.5 / n) |&gt;\n    ggplot(aes(x = delta_aic, color = as.factor(n))) +\n        geom_density() +\n        coord_cartesian(xlim = c(-0.1, NA)) +\n        labs(x = \"ΔAIC\", y = \"Density\", color = \"Sample Size\") +\n        ggtitle(\"ΔAIC probability density\")\n\n\n\n\n\n\n\n\nFinally, here is something I have no idea where it comes from. The plot below shows the scatterplot of in-sample cross-entropy differences vs. the AIC differences. It is well known that AIC only estimates the expectation of these differences, averaged over potential training samples. One may ask whether AIC has anything to say about the actual cross-entropy difference for the estimated models, conditional on the realized training sample.\nAssuming I have made no errors here, the tilted-U shape of this scatterplot is a clear negative answer. What’s especially interesting is that, apparently, these differences have a negative correlation. I fail to see where do the negative correlation and the U-shape come from.\n\nfits |&gt; \n    filter(n == 100) |&gt;\n    mutate(\n        is_baseline = model == \"y ~ 1\",\n        delta_ce = ce - ce[is_baseline], \n        delta_aic = aic - aic[is_baseline],\n        .by = c(n, b),\n        ) |&gt;\n    filter(!is_baseline) |&gt;\n    ggplot(aes(x = delta_aic, y = delta_ce)) +\n        geom_point(size = 1, alpha = 0.2) +\n        lims(x = c(-0.02, 0.01), y = c(-0.01, 0.03)) +\n        labs(x = \"ΔAIC\", y = \"ΔCE\") +\n        ggtitle(\"AIC vs. in-sample cross-entropy\", \"Point values for N = 100\") +\n        NULL"
  },
  {
    "objectID": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html#footnotes",
    "href": "posts/2024-05-09-aic-in-the-well-specified-linear-model-theory-and-simulation/aic-in-the-well-specified-linear-model-theory-and-simulation.html#footnotes",
    "title": "AIC in the well-specified linear model: theory and simulation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee e.g. 1503.06266↩︎\nThe same equation actually gives the expectation of \\(\\text{AIC}\\) conditional to the in-sample covariate vector \\(\\mathbb X\\). Since this conditioning differs for the two different models involving \\(X_1\\) and \\(X_2\\), in our comparison of expected values we must interpret this as unconditional expectations, in general.↩︎"
  },
  {
    "objectID": "posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/grammar-as-a-biometric-for-authorship-verification.html",
    "href": "posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/grammar-as-a-biometric-for-authorship-verification.html",
    "title": "Grammar as a biometric for Authorship Verification",
    "section": "",
    "text": "About a month ago we finally managed to drop (Nini et al. 2024), “Authorship Verification based on the Likelihood Ratio of Grammar Models”, on the arXiv. Delving into topics such as authorship verification, grammar and forensics, was quite a detour for me, and I’d like to summarize here some of the ideas and learnings I got from working with all this new and interesting material.\nThe main qualitative idea put forward by Ref. (Nini et al. 2024) is that grammar is a fundamentally personal and unique trait of an individual, therefore providing a sort of “behavioural biometric”. One first goal of this work was to put this general principle under test, by applying it to the problem of Authorship Verification (AV): the process of validating whether a certain document was written by a claimed author. Concretely, we built an algorithm for AV that relies entirely on the grammatical features of the examined textual data, and compared it with the state-of-the-art methods for AV.\nThe results were very encouraging. In fact, our method actually turned out to be generally superior to the previous state-of-the-art on the benchmarks we examined. This is a notable result, keeping also into account that our method uses less textual information (only the grammar part) than other methods to perform its inferences."
  },
  {
    "objectID": "posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/grammar-as-a-biometric-for-authorship-verification.html#the-algorithm",
    "href": "posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/grammar-as-a-biometric-for-authorship-verification.html#the-algorithm",
    "title": "Grammar as a biometric for Authorship Verification",
    "section": "The algorithm",
    "text": "The algorithm\nI sketch here a pseudo-implementation of our method in R. For the fit of \\(k\\)-gram models and perplexity computations, I use my package {kgrams}, which can be installed from CRAN. Model (hyper)parameters such as number of impostors, order of the \\(k\\)-gram models, etc. are hardcoded, see (Nini et al. 2024) for details.\nThis is just for illustrating the essence of the method. For practical reasons, in the code chunk below I’m not reproducing the definition of the function extract_grammar(), which in our work is embodied by the POS-noise algorithm. This function should transform a regular sentence, such as “He wrote a sentence”, to its underlying grammatical structure, say “[Pronoun] [verb] a [noun]”.\n\n#' @param q_doc character. Text document whose authorship is questioned.\n#' @param auth_corpus character. Text corpus of claimed author.\n#' @param imp_corpus character. Text corpus of impostors.\n#' @param n_imp a positive number. Number of \"impostor\" simulations.\n\nscore &lt;- function(q_doc, auth_corpus, imp_corpus, n_imp = 100) \n{\n    q_doc &lt;- extract_grammar(q_doc)\n    auth_corpus &lt;- extract_grammar(auth_corpus)\n    imp_corpus &lt;- extract_grammar(imp_corpus)\n\n    # Compute perplexity based on claimed author's language model.\n    auth_mod &lt;- train_language_model(auth_corpus)\n  auth_perp &lt;- kgrams::perplexity(q_doc, model = auth_mod)\n  \n  # Compute perplexity based on impostor language models.\n  #\n  # Each impostor is trained on a synthetic corpus obtained by sampling from\n  # the impostor corpus the same number of sentences as the corpus of the \n  # claimed author.\n  n_sents_auth &lt;- length(kgrams::tknz_sent(auth_corpus))\n  imp_corpus_sentences &lt;- kgrams::tknz_sent(imp_corpus)\n  imp_mod &lt;- replicate(n_imp, {\n    sample(imp_corpus_sentences, n_sents_auth) |&gt; train_language_model()\n  })\n  imp_perp &lt;- sapply(imp_mod, \\(m) kgrams::perplexity(q_doc, model = m))\n  \n  # Score is the fraction of impostor models that perform worse (higher \n  # perplexity) than the proposed authors language model\n  score &lt;- mean(auth_perp &lt; imp_perp)\n  \n  return(score)\n}\n\ntrain_language_model &lt;- function(text)\n{\n  text |&gt; \n    kgrams::kgram_freqs(N = 10, .tknz_sent = kgrams::tknz_sent) |&gt;\n    kgrams::language_model(smoother = \"kn\", D = 0.75)\n}\n\nextract_grammar &lt;- identity  # Just a placeholder - see above.\n\nTo be used as follows:\n\nq_doc &lt;- \"a a b a. b a. c b a. b a b. a.\" \nauth_corpus &lt;- \"a a b a b. b c b. a b c a. b a. b c a.\" \nimp_corpus &lt;- \"a a. b. a. b a. b a. c. a b a. d. a b. a d. a b a b c b a.\"\n\nset.seed(840)\nscore(q_doc, auth_corpus, imp_corpus)\n\n[1] 0.89\n\n\nThe “score” computed by this algorithm turns out to be a good truthfulness predictor for the claimed authorship, higher scores being correlated with true attributions. If the impostor corpus is fixed once and for all, and if the pairs q_doc and auth_corpus are randomly sampled from a fixed joint distribution, we can set a threshold for score in such a way that the attribution criterion score &gt; threshold maximizes some objective such as accuracy. This is, more or less, what we studied quantitatively in our paper."
  },
  {
    "objectID": "posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/grammar-as-a-biometric-for-authorship-verification.html#reflections-on-in-silico-authorship-verification",
    "href": "posts/2024-04-25-grammar-as-a-biometric-for-authorship-verification/grammar-as-a-biometric-for-authorship-verification.html#reflections-on-in-silico-authorship-verification",
    "title": "Grammar as a biometric for Authorship Verification",
    "section": "Reflections on in silico Authorship Verification",
    "text": "Reflections on in silico Authorship Verification\nThe various ifs at the end of the previous sections led me to reflexionate on the applicability of machine-learning approaches, such as the one we discussed in our work, to real-life contexts.\nAs implied above, in order for a metric such as accuracy to represent a sensible measure of predictive performance, we should be able to regard the AV problems encountered in our favorite practical use case as random samples from some fixed population. In other words, we consider a stationary source of random authorship claims, and assume that our trained model is routinely used to verify claims from this source.\nNow, while there are many circumstances in which the above assumptions make total sense, I think there are also interesting AV applications in which one is not interested in the long-run properties of the method but, rather, in a single inference. The real case of the poem “Shall I die?”, controversially attributed to Shakespeare in 1985, is an example of this kind. An approach to this case based on empirical Bayes is discussed in (Efron and Hastie 2021, vol. 6, sec. 6.2). Although we may be able to build a reasonable impostor corpus to be used with this problem, it is not clear how one should come up with a relevant testing dataset of AV problems to empirically quantify uncertainty.\nFor cases such as the “Shall I die?” controversy, the machine-learning setting considered in our study is just an in silico model of real AV. As such, I believe it still provides useful indications on what could be good authorship indicators and work in general, but we must acknowledge the practical limitations in our way to quantify uncertainty. Other approaches, such as classical null hypothesis testing, may be more suited to this specific kind of AV problems."
  },
  {
    "objectID": "posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey/the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey.html",
    "href": "posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey/the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey.html",
    "title": "“The Abuse of Power” by J. M. Hoenig and D. M. Heisey",
    "section": "",
    "text": "(Hoenig and Heisey 2001). From the paper’s abstract:\nThe point on observed power is very elementary: for a given hypothesis test at a fixed size \\(\\alpha\\), observed power is a function of the observed \\(p\\)-value, and thus cannot add any information to the one already contained in the latter.\nObserved power will be typically small for non-significant (\\(p&gt;\\alpha\\)) results, and high otherwise. The authors discuss the example of a one-tailed, one-sample \\(Z\\)-test for the null hypothesis that \\(Z \\sim \\mathcal N (\\mu, 1)\\) has mean \\(\\mu \\leq 0\\). The \\(p\\)-value and observed power \\(\\tilde \\beta\\) are, respectively:\n\\[\np = 1 - \\Phi(Z),\\quad \\tilde\\beta=1-\\Phi(Z_\\alpha-Z),\n\\]\nwhere \\(Z_\\alpha = \\Phi ^{-1}(1-\\alpha)\\) is the significance threshold at level \\(\\alpha\\). Below significance, one always has \\(Z&lt;Z_\\alpha\\), implying low observed power \\(\\tilde \\beta &lt;\\frac{1}{2}\\). This implies that observed power cannot be used to tell whether a null result comes from a small effect or from a low detection capability.\nThe authors also criticize the notion of “detectable effect size”, but their arguments look less convincing to me in this case. In their example we have an i.i.d. sample \\(\\{X_i\\}_{i=1}^N\\), where \\(X_i \\sim \\mathcal N(\\mu, \\sigma ^2)\\), and we again test the null \\(\\mu \\leq 0\\). For a fixed power \\(\\beta\\), the detectable effect size is that value of \\(\\mu\\) that would yield a type II error rate of exactly \\(1-\\beta\\), if \\(\\sigma ^2\\) is taken to be equal to the observer sample standard deviation. Their argument against this construct (Sec. 2.2) seems to rest on the premise that a smaller \\(p\\)-value should always be interpreted as stronger evidence against the null hypothesis, even when the \\(p\\)-value is not significant and the null hypothesis is accepted. But this is inconsistent, because \\(p\\)-values are uniformly distributed under the null hypothesis, so that their actual values should be given no meaning once this is accepted.\nIn fact, I would argue that the detectable effect size provides a decent heuristics to quantify the uncertainty of a non-significant result on the scale of the parameter of interest. The true point against its usage is that (as also recognized in this work) there is a tool available which is much more suited for the same purpose 1, the confidence interval, which has a clear probabilistic characterization in terms of its coverage probability."
  },
  {
    "objectID": "posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey/the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey.html#footnotes",
    "href": "posts/2024-04-18-the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey/the-abuse-of-power-by-j-m-hoenig-and-d-m-heisey.html#footnotes",
    "title": "“The Abuse of Power” by J. M. Hoenig and D. M. Heisey",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn the previous example, assuming a large sample size \\(N\\) so that we can approximate the \\(t\\) distribution with a normal one, the \\(1-\\alpha\\)-level lower limit on \\(\\mu\\) (appropriate for a one-sided test of the null hypothesis \\(\\mu \\leq 0\\)) is given by: \\[\n\\mu _\\text{lo} = \\overline X-\\frac{s}{\\sqrt N}\\Phi^{-1}(1-\\alpha),\n\\] where \\(\\overline X\\) and \\(s\\) are the observed sample mean and standard deviation, respectively. The detectable effect size \\(d\\) is the minimum value of \\(\\mu\\) such that \\(\\text{Pr}(\\mu _\\text{lo} &gt; 0) \\geq 1-\\beta\\), that is: \\[\nd = \\frac{s}{\\sqrt N}\\left[\\Phi^{-1}(1-\\alpha)+\\Phi^{-1}(1-\\beta)\\right].\n\\]↩︎"
  },
  {
    "objectID": "posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie/a-closer-look-at-the-deviance-by-t-hastie.html",
    "href": "posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie/a-closer-look-at-the-deviance-by-t-hastie.html",
    "title": "“A Closer Look at the Deviance” by T. Hastie",
    "section": "",
    "text": "(Hastie 1987). This short review provides a compendium of useful results on the deviance defined by \\(\\text -2 \\log \\mathcal L +2\\log\\mathcal L^*\\), where \\(\\mathcal L^*\\) denotes the likelihood of a “saturated” model, as explained in the paper. From the paper’s abstract:\n\nPrediction error and Kullback-Leibler distance provide a useful link between least squares and maximum likelihood estimation. This article is a summary of some existing results, with special reference to the deviance function popular in the GLIM literature.\n\nOf particular interest:\n\nClarifies the definition of a “saturated” model for i.i.d. samples.\nHighlights the parallels between \\(L_2\\) and Kullback-Leibler loss. In particular, the expectation is shown to be the optimal regression function for the general KL loss.\nDiscusses optimism in the training error estimate of the in-sample (fixed predictors) error rate in terms of KL loss, within the context of Generalized Linear models.\n\n\n\n\n\nReferences\n\nHastie, Trevor. 1987. “A Closer Look at the Deviance.” The American Statistician 41 (1): 16–20. https://doi.org/10.1080/00031305.1987.10475434.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {“{A} {Closer} {Look} at the {Deviance}” by {T.} {Hastie}},\n  date = {2024-03-07},\n  url = {https://vgherard.github.io/posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie/a-closer-look-at-the-deviance-by-t-hastie.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “‘A Closer Look at the\nDeviance’ by T. Hastie.” March 7, 2024. https://vgherard.github.io/posts/2024-03-07-a-closer-look-at-the-deviance-by-t-hastie/a-closer-look-at-the-deviance-by-t-hastie.html."
  },
  {
    "objectID": "posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems/on-the-first-and-second-laws-of-thermodynamics-for-open-systems.html",
    "href": "posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems/on-the-first-and-second-laws-of-thermodynamics-for-open-systems.html",
    "title": "On the first and second laws of thermodynamics for open systems",
    "section": "",
    "text": "The first and second laws of thermodynamics for closed systems are commonly expressed as:\n\\[\n\\text{d}U -\\delta W= \\delta Q \\leq T'\\,\\text dS \\qquad\\text{[closed system]},\n\\tag{1}\\]\nwhere \\(U\\), and \\(S\\) denote the internal energy and entropy of the system, \\(T'\\) is the temperature of the heat source, and \\(\\delta W\\) and \\(\\delta Q\\) are the amounts of energy transferred to the system in the form of heat and work, respectively. For concreteness, I will focus on volume work \\(\\delta W = -p\\,\\text d V\\) and reversible processes, so that the equal sign in Equation 1 holds with the temperature of the source \\(T'\\) being equal to \\(T\\), the temperature of the system. Equation 1 then implies:\n\\[\n\\text d U = T\\,\\text d S - p \\,\\text d V\\qquad\\text{[closed system]},\n\\tag{2}\\]\nfrom which we can identify:\n\\[\n\\left(\\frac{\\partial U}{\\partial S}\\right)_{V,N} = T, \\quad \\left(\\frac{\\partial U}{\\partial V}\\right)_{S,N} = -p\n\\tag{3}\\]\nIn the previous equation, \\(N\\) represents the quantity of matter (say number of moles) in the system. The suffixes indicate that the partial derivatives are taken at constant \\(N\\), which may look trivial for closed systems. In open systems, however, \\(N\\) can vary due to matter exchanges with the surrounding, so that the internal energy \\(U = U(S,V,N)\\) is also a function of \\(N\\), and this dependence defines the chemical potential:\n\\[\n\\mu \\equiv \\left(\\frac{\\partial U}{\\partial N}\\right)_{S,V}.\n\\tag{4}\\]\nPutting this together with Equation 3, we obtain a generalization of Equation 2 for an open system:\n\\[\n\\text d U = T\\text d S - p \\text d V + \\mu \\text dN.\n\\tag{5}\\]\nOne should realize that this equation represents, at the present stage, no more than a mathematical definition of the partial derivatives of \\(U\\). In order to attach some physical content to it, we should connect the various terms appearing in Equation 5 with operatively defined quantities.\nTo appreciate this point, let us make a step back to the closed system case, and examine the physical content of the first two laws of thermodynamics. For a closed system we have the relations \\(\\delta W = - p\\,\\text dV\\) and \\(\\delta Q = T\\,\\text d S\\). It is important to realize that \\(\\delta W\\) and \\(\\delta Q\\) have independent operative definitions: \\(\\delta W\\) is defined as the work performed by external forces during the process considered, whereas \\(\\delta Q\\) is defined as the difference \\(\\delta Q=\\text d U - \\delta W\\). It is in light of these operative definitions that the laws of thermodynamics acquire physical content1.\nIn order to establish a similar physical interpretation for the open system case, let us decompose the change in internal energy as follows:\n\\[\n\\text d U = \\delta Q + \\delta W + \\delta X.\n\\tag{6}\\]\nHere the first two terms correspond to heat and work, as before, while the new term \\(\\delta X\\) accounts for energy exchange due to matter transfer. Comparing Equation 6 and Equation 5, and given the expressions of \\(\\delta Q\\) and \\(\\delta W\\) in the closed system case, it is tempting to conclude that:\n\\[\n\\delta Q \\overset{?}{=} T \\text d S,\\quad \\delta W \\overset{?}{=}-p\\text d V,\\quad\n\\delta X \\overset{?}{=} \\mu \\text d N,\n\\tag{7}\\]\nbut these identifications are easily seen to be wrong.\nBefore discussing the correct version of Equation 7, let us comment why these identifications can be dangerously misleading. Consider a gas enclosed by rigid and thermally insulating walls, so that no energy exchange with the exterior in the form of heat is possible and, since volume is constant, also no work is possible (according to Equation 7). Suppose now that we have some mechanism to inject a number \\(\\delta N\\) of additional particles into the system. Due to what was said above, we would be lead to conclude that the corresponding variation of internal energy should be \\(\\text{d}U  \\overset{?}{=} \\mu \\text d N\\), which is incorrect (the correct answer is discussed below).\nThe physical reason why Equation 7 are wrong is that exchanged matter also carries an amount \\(\\text{d}S^{\\text{(e)}} = s\\,\\text dN\\) of entropy and has a volume \\(\\text{d}V^{\\text{(e)}} = v\\,\\text dN\\), where \\(s\\) and \\(v\\) are the entropy and volume per particle of the external source of matter (\\(s = \\frac{S}{N}\\) and \\(v = \\frac{V}{N}\\) if the exchanged particles are in thermal equilibrium with the open system). This additional entropy and volume flows must be kept into account in the corresponding variations for opens system, that become:\n\\[\n\\text{d} S = \\frac{\\delta Q}{T}+s\\,\\text dN,\\quad -p\\text dV= \\delta W-p\\text dV^{\\text{(e)}},\n\\tag{8}\\]\nPlugging this into Equation 5 and comparing with Equation 6, we obtain:\n\\[\n\\delta Q =T \\text d S-Ts\\,\\text dN,\\quad \\delta W =-p\\text d V+p v\\text dN,\\quad\n\\delta X = u\\text d N,\n\\tag{9}\\]\nwhere \\(u \\equiv \\mu + Ts-pv\\) is the internal energy per particle (the chemical potential can be shown to be equal to the Gibbs energy per particle).\nThe meaning of Equation 9 is best clarified with a few examples. Consider first a process which simply consists in bringing together two quantities \\(N\\) and \\(\\text d N\\) of gas molecules kept at the same temperature \\(T\\) and pressure \\(p\\). This amounts to a mere rescaling of the original system by a factor \\(\\lambda = (1+\\frac{\\text d N}{N})\\), so that all extensive quantities are simply scaled by this same factor:\n\\[\n\\text d S = s\\text dN=(\\lambda -1)S,\\quad \\text d V = v\\text dN= (\\lambda -1)V.\n\\] Clearly, this process involves no energy exchange in the form of heat or work, and we see indeed from Equation 9 that:\n\\[\n\\delta Q = \\delta W = 0,\\quad \\text d U = \\delta X = u \\text d N=(\\lambda - 1)U\n\\] Had we neglected the extra terms \\(-T\\text d S ^{\\text{(e)}}\\) and \\(+p\\text d V ^{\\text{(e)}}\\) in the equations for \\(\\delta Q\\) and \\(\\delta W\\), we would have concluded that the system has exchanged heat or performed work during such a null process.\nAs our second example, we consider a vapor-liquid phase transition. The vapor-liquid system, assumed to be in equilibrium, is enclosed in a cylinder with thermal conducting walls and surrounded by a medium at constant temperature \\(T\\). A piston on one extremity of the cylinder allows to condense vapor by compression.\nIf we consider either the vapor or liquid phases as open systems, in an isobaric and isothermal transformation in which a quantity \\(\\text d N\\) of vapor molecules is condensed, we have as in Equation 9:\n\\[\n\\begin{split}\n\\text d U _i &= \\delta Q_i + \\delta W_i + \\delta X_i,\\\\\n\\delta Q_i &= T\\,\\text dS_i-T\\,s_i \\,\\text dN_i,\\\\\n\\delta W_i &=-p\\,\\text d V_i+p\\,v_i\\,\\text dN_i,\\\\\n\\delta X_i &= u_i\\,\\text dN_i,\n\\end{split}\n\\] where \\(i = \\text {l or v}\\) (denoting liquid or vapor), and \\(\\text dN_{\\text{l}} = -\\text dN_{\\text{v}} \\equiv \\text d N\\). But, since specific quantities at the phase transition only depend on temperature, which is held constant, the overall changes in entropy and volume are simply equal to the amounts due to matter transfer \\(\\text d S_i = s_i\\,\\text d N_i\\) and \\(\\text d V_i = v_i\\,\\text d N_i\\), which implies:\n\\[\n\\delta Q_i = \\delta W_i = 0,\\quad \\delta X_i =u_i\\,\\text dN_i.\n\\] This is not unreasonable since, from the point of view of the open system, what is happening is simply that a quantity \\(\\text d N\\) of vapor or liquid (that was produced before, somehow), is getting transferred to the system. This is entirely analogous to the previous example, in which two chunks of identical substance were simply joined together.\nOn the other hand, the conventional approach to the same problem treats the vapor-liquid system as a closed system. For this system, we can directly relate the changes in entropy and volume to heat and work:\n\\[\n\\delta Q = T(s_\\text l-s_\\text v )\\text dN,\\quad\\delta W = -p(v_\\text l-v_\\text v )\\text dN, \\quad \\delta X=0,\n\\] which looks superficially different from the open system point of view.\nThere is no contradiction in the fact that \\(\\delta Q \\neq \\delta Q_1+\\delta Q _2\\) and \\(\\delta W \\neq \\delta W_1 + \\delta W_2\\), since the open and closed system points of view are describing the condensation process from a very different angle. In order to see this, let’s imagine breaking down the process as follows. Starting with our system with internal energy \\(U_0\\):\nThe crucial observation is that the open system point of view is only describing steps 1 and 3, while the closed system only describes step 2. The fact that \\(U_3 - U_0 = (u_\\text{l}-u_\\text{v})\\text d N\\), implies that the two points of view lead to the same energy balance, as it should be. This can be easily verified:\n\\[\n\\begin{split}\n\\text d U &= \\delta Q + \\delta W\\\\\n&=[T\\text(s_\\text l-s_\\text v)-p(v_\\text l-v_\\text v)]\\text dN\\\\\n&=\\delta X_\\text l+ \\delta X_\\text v\\\\\n&= \\text dU_\\text l+ \\text d U_\\text v\n\\end{split}\n\\]\nwhere in the third equality we used the fact that \\(\\mu_\\text l = \\mu_\\text v\\) at the phase transition, so that \\(u_\\text l - u_\\text v = T\\text(s_\\text l-s_\\text v)-p(v_\\text l-v_\\text v)\\).\nAs a final note, let me mention that some references (especially from the engineering field) include the work required to transfer matter across the open system boundary in the definition of \\(\\delta X\\), which thus becomes proportional to the molar enthalpy \\(h = u + pv\\) (see e.g. (Knuiman, Barneveld, and Besseling 2012)). As a consequence, the external work performed on an open system simply reads \\(\\delta W = - p \\text d V\\), as in the closed system case. The reason why this could make sense is that if the “open system” is defined in terms of a (physical or imaginary) spatial boundary surface, which allows the flow of matter through some injection mechanism, one could be interested in the work resulting from the expansion of the boundary only - sometimes called shaft work, in contrast with the flow work \\(-p \\,\\text d V^{\\text{(e)}}\\) included in the enthalpy. In the way I see it, this leads to a cumbersome physical description in the context of the examples mentioned above."
  },
  {
    "objectID": "posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems/on-the-first-and-second-laws-of-thermodynamics-for-open-systems.html#footnotes",
    "href": "posts/2024-02-29-on-the-first-and-second-laws-of-thermodynamics-for-open-systems/on-the-first-and-second-laws-of-thermodynamics-for-open-systems.html#footnotes",
    "title": "On the first and second laws of thermodynamics for open systems",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe first law, in its essence, postulates the existence of certain experimental conditions (thermal insulation) under which the work required by any transformation of a thermodynamic system depends only on the initial and final states - allowing the definition of a state function \\(U\\), the internal energy. Similarly, the second law postulates the existence of a state function \\(S\\) that bounds the heat exchange with a source at temperature \\(T'\\) by \\(\\delta Q \\leq T' \\,\\text d S\\).↩︎"
  },
  {
    "objectID": "posts/2024-01-29-binary-digits-of-uniform-random-variables/binary-digits-of-uniform-random-variables.html",
    "href": "posts/2024-01-29-binary-digits-of-uniform-random-variables/binary-digits-of-uniform-random-variables.html",
    "title": "Binary digits of uniform random variables",
    "section": "",
    "text": "Let \\(X\\) be a random number in the unit interval \\([0,\\,1]\\), and let \\(Z \\equiv (Z_k)_{k\\in \\mathbb N}\\) represent the sequence of its binary digits, so that \\(Z_k \\in \\{0,\\,1\\}\\) for all \\(k\\) and:\n\\[\nX = \\sum _{k = 1} ^\\infty Z_k \\cdot 2^{-k}\n\\] Notice that the representation \\(Z\\) is unique for all \\(X\\) outside of a countable subset of the unit interval.1\nThe cool theorem proved below is that \\(X\\) is uniformly distributed in \\([0,\\,1]\\) if and only if all \\(Z_k\\)’s are independent and \\(\\text{Pr}(Z_k = 1) = \\text{Pr}(Z_k = 0) = \\frac{1}{2}\\). That is to say, the binary representation \\(Z\\) of a random variable \\(X\\sim \\text{Unif}(0,\\,1)\\) amounts to a sequence of independent fair coin tosses.\nWe fix \\(n \\in \\mathbb N\\) and decompose the unit interval as follows:\n\\[\n[0,1) = \\cup _{j = 1} ^{2^n} I^n_j,\\quad I^n_j = [(j-1) \\cdot2^{-n},j\\cdot2^{-n})\n\\] Each interval \\(I^n_j\\) corresponds to a specific set of values for the first \\(n\\) digits \\(Z_1,\\,Z_2,\\,\\dots,\\,Z_n\\), that is \\(X\\in I^n _j\\) if and only if \\(Z_1 = z_1,\\,Z_2 =z_2,\\,\\dots,\\,Z_n=z_n\\) for some \\(z_1,\\,z_2,\\,\\dots,\\,z_n\\) that depend on the interval \\(I^n _j\\). Therefore:\n\\[\n\\text{Pr}(X\\in I^n _j) = \\text{Pr}(Z_1 = z_1,\\,Z_2 = z_2,\\,\\dots,\\,Z_n = z_n)\n\\] Now, \\(X\\) is uniformly distributed if and only if the left hand side of this equation equals \\(2^{-n}\\) for all \\(n\\in \\mathbb N\\) and \\(1\\leq j \\leq 2^{n}\\) 2. Furthermore, the \\(2^{n}\\) possible values of \\(j\\) correspond to the \\(2^{n}\\) possible values of \\(z_1,\\,z_2,\\,\\dots,\\,z_n\\) in the right hand side. Therefore, \\(X\\) is uniform if and only if:\n\\[\n\\text{Pr}(Z_1 = z_1,\\,Z_2 = z_2,\\,\\dots,\\,Z_n = z_n) = 2^{-n}\n\\] for all \\(z_1,\\,z_2,\\,\\dots,\\,z_n \\in \\{0,\\,1\\}\\). More generally, this implies that, for any \\(k \\in \\mathbb N \\cup \\{0\\}\\) we have:\n\\[\n\\text{Pr}(Z_{k+1} = z_1,\\,Z_{k+2} = z_2,\\,\\dots,\\,Z_{k+n} = z_n) = 2^{-n} = \\prod _{i=1}^{n}\\text{Pr}(Z_{k+i} = z_i),\n\\]\nwhere the second equality follows from the special case \\(n=1\\). This is equivalent to saying that all \\(Z_k\\)’s are independent, each having \\(\\text{Pr}(Z_k = 1) = \\text{Pr}(Z_k = 0) = \\frac{1}{2}\\)."
  },
  {
    "objectID": "posts/2024-01-29-binary-digits-of-uniform-random-variables/binary-digits-of-uniform-random-variables.html#footnotes",
    "href": "posts/2024-01-29-binary-digits-of-uniform-random-variables/binary-digits-of-uniform-random-variables.html#footnotes",
    "title": "Binary digits of uniform random variables",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThat is, the set of numbers that have a finite expansion \\(X = \\sum _{k = 1} ^N Z_k \\cdot 2^{-k}\\) for some finite \\(N\\), with \\(Z_N = 1\\). These numbers also have the equivalent infinite expansion \\(X = \\sum _{k = 1} ^{N-1} Z_k \\cdot 2^{-k} + \\sum _{k = N+1} ^{\\infty}2^{-k}\\). For these numbers we can make the convention of using the first (finite) representation.↩︎\nThat this is sufficient follows from the fact that any interval of the real line can be obtained by taking countable unions and intersections of intervals of the form \\(I^n _j\\).↩︎"
  },
  {
    "objectID": "posts/2023-11-03-conditional-probability/conditional-probability.html",
    "href": "posts/2023-11-03-conditional-probability/conditional-probability.html",
    "title": "Conditional Probability",
    "section": "",
    "text": "Let \\((\\Omega, \\,\\mathcal E,\\,P)\\) be a probability space, and let \\(X\\colon \\Omega \\to \\Omega _X\\) be a random variable with target space \\((\\Omega _X, \\mathcal X)\\). We denote the corresponding push-forward measure on \\(\\mathcal X\\) by \\(X_*P\\), so that:\n\\[\n(X_*P)(B)= P(X^{-1}(B))\n\\] for all \\(B\\in \\mathcal X\\). A measurable function \\(f\\colon \\Omega _X \\to \\mathbb R\\) is integrable with respect to \\(X_*P\\) if and only if \\(f\\circ X\\) is integrable with respect to \\(P\\), in which case1: \\[\n\\intop _\\mathcal X f\\,\\text d(X_*P) = \\intop _\\mathcal \\Omega (f \\circ X)\\,\\text dP.\n\\] Now, given an arbitrary event \\(E\\in \\mathcal E\\) define \\((X_*P)_E(A)=P(E\\cap X^{-1}(A))\\). Then \\((X_*P)_E\\) is a measure on \\(\\mathcal X\\) which is clearly dominated by \\(X_*P\\), and there exists a Radon-Nikodym derivative \\(\\frac{\\text d (X_*P)_E}{\\text d (X_*P)} \\in L_1(X_*P)\\). We define the conditional probability of event \\(E\\) with respect to the random variable \\(X\\) as the random variable:\n\\[\nP(E\\vert X)\\equiv \\frac{\\text d (X_*P)_E}{\\text d (X_*P)}.\n\\]\nThe intuition behind this definition comes from the tautology (given the definition in terms of Radon-Nikodym derivative):\n\\[\nP(E \\cap (X\\in A)) = \\intop _{A} P(E\\vert X)\\,\\text d(X_*P).\n\\] On one hand, from elementary probability theory, one would expect any sensible definition of conditional probability to satisfy this theorem. On the other hand, the theorem univocally identifies \\(P(E\\vert X)\\) as the Radon-Nikodym derivative \\(\\frac{\\text d (X_*P)_E}{\\text d (X_*P)}\\), modulo a set of \\(X_*P\\) measure zero.\nIt is fairly easy to verify the following properties of conditional probability:\nThis, however, does not generally imply that \\(P(\\cdot \\vert X = x)\\) is a probability measure for almost all \\(x\\in \\Omega_X\\)2. Functions \\(\\nu \\colon \\mathcal E \\times \\Omega _X \\to \\mathbb R^+\\) such that \\(\\nu(\\cdot, x)\\) is a measure for all \\(x\\in \\Omega _X\\), and \\(\\nu (E,\\cdot)\\) is \\(\\mathcal X\\)-measurable for all \\(E\\in \\mathcal E\\) are called random measures. If \\(\\nu\\) satisfies \\[\nP(E \\cap (X\\in A)) = \\intop _{A} \\nu (E,\\cdot)\\,\\text d(X_*P)\n\\] (or, equivalently, if \\(\\nu (E,\\cdot)\\) is a version of \\(\\frac{\\text d (X_*P)_E}{\\text d (X_*P)}\\)) for all \\(E\\in \\mathcal E\\), \\(\\nu\\) is called a regular conditional probability for the random variable \\(X\\). If the space \\((\\Omega,\\, \\mathcal E)\\) is regular enough (e.g. if it is a Borel space) one can prove that a regular conditional probability exists for any random variable \\(X\\), see e.g. (Kallenberg 1997).\nIf \\(X = \\chi _A \\colon \\Omega \\to \\{0,1\\}\\), where \\(A\\in \\mathcal E\\) has positive probability \\(0&lt;P(A)&lt;1\\), we can easily compute:\n\\[\nP(E\\vert \\chi _A) = \\chi _A\\cdot \\frac{P(E\\cap A)}{P(A)} + (1-\\chi _A)\\cdot \\frac{P(E\\cap A^c)}{P(A^c)}\n\\] In particular, \\(P(E\\vert A) \\equiv P(E\\vert \\chi _A = 1)\\) agrees with the usual elementary definition of conditional probability.\nMore generally, if \\(X = \\text {id} _\\Omega\\), where the target space is equipped with a sub-\\(\\sigma\\)-algebra \\(\\mathcal F \\subseteq \\mathcal E\\), we have:\n\\[\nP(E\\vert \\mathcal F)\\equiv \\frac{\\text d (P\\vert _\\mathcal F)_E}{\\text d (P\\vert _\\mathcal F)},\n\\] which is sometimes taken as the definition of conditional probability with respect to a sub-\\(\\sigma\\)-algebra. When \\(\\mathcal F\\) is the \\(\\sigma\\)-algebra generated by a finite or countable partition \\(\\mathcal A = (A_i)_{i\\in I}\\) of \\(\\mathcal \\Omega\\) such that \\(P(A_i)&gt;0\\) for all \\(i\\in I\\), we find:\n\\[\nP(E\\vert \\mathcal A)=\\sum _{i\\in I} \\frac{P(E\\cap A_i)}{P(A_i)}\\chi _{A_i},\n\\] again in agreement with elementary definitions.\nFinally, if \\(X\\colon \\Omega \\to \\mathbb R\\) is a real-valued random variable, where \\(\\mathbb R\\) is equipped with the Borel \\(\\sigma\\)-algebra, \\(X_*P\\) coincides with the Stieltjes measure generated by the cumulative distribution function \\(P_X\\) of \\(X\\). Denoting \\(P(E\\vert X)(x) \\equiv P(E\\vert X = x)\\), we may write:\n\\[\nP(E \\cap (X \\in B))=\\intop _B P(E\\vert X=x) \\,\\text dP_X(x).\n\\] and, in particular:\n\\[\nP(E)=\\intop _\\mathbb R P(E\\vert X=x) \\,\\text dP_X(x).\n\\]"
  },
  {
    "objectID": "posts/2023-11-03-conditional-probability/conditional-probability.html#footnotes",
    "href": "posts/2023-11-03-conditional-probability/conditional-probability.html#footnotes",
    "title": "Conditional Probability",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese claims can be proved by a standard argument using approximations by simple functions.↩︎\nFor instance, denoting by \\(N_E = \\{x \\in \\Omega_X \\vert P(E\\vert X = x) \\geq 0\\}\\), positivity implies that \\((X_*P)(N_E)=0\\). However, there’s no guarantee that \\(\\cup _{E\\in \\mathcal E} N_E\\) is also a measure zero set (and in fact it does not need to be measurable, since the union is generally uncountable).↩︎"
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html",
    "title": "AB tests and repeated checks",
    "section": "",
    "text": "“How is the experiment going?”\n\nAlso:\n\n“Do we already see something?”\n\nAnd my favorite one:\n\n“Did we already hit significance, or do we need more data?”\n\nIf you have dealt with experiments with relatively high outcome expectations, you will likely have received (or perhaps asked yourself) similar questions from time to time.\nIn many data analysis contexts, including but not limited to for-profit ones, researchers are always trying to come up with positive results as fast as they can. Therefore, it is not at all surprising to see questions such as the ones above regularly arise during the course of an experiment. This is natural and not a problem per se. What I want to highlight and quantify in this post is how, if not done carefully, such “real-time” monitoring schedules can seriously invalidate data analysis - by inflating false positive and false negative rates.\nGenerally speaking, repeated and ad-hoc checks lead to problems of selective/simultaneous inference (a topic which I have touched in other places in this blog). Avoiding them is not the only valid solution - if you want to learn about some proper method you may give a look into Sequential Hypothesis Testing, a topic that I may explore in future posts. Here my goal is to understand the consequences of naive repeated checking, which can be easily found out through simulation."
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#intro",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#intro",
    "title": "AB tests and repeated checks",
    "section": "",
    "text": "“How is the experiment going?”\n\nAlso:\n\n“Do we already see something?”\n\nAnd my favorite one:\n\n“Did we already hit significance, or do we need more data?”\n\nIf you have dealt with experiments with relatively high outcome expectations, you will likely have received (or perhaps asked yourself) similar questions from time to time.\nIn many data analysis contexts, including but not limited to for-profit ones, researchers are always trying to come up with positive results as fast as they can. Therefore, it is not at all surprising to see questions such as the ones above regularly arise during the course of an experiment. This is natural and not a problem per se. What I want to highlight and quantify in this post is how, if not done carefully, such “real-time” monitoring schedules can seriously invalidate data analysis - by inflating false positive and false negative rates.\nGenerally speaking, repeated and ad-hoc checks lead to problems of selective/simultaneous inference (a topic which I have touched in other places in this blog). Avoiding them is not the only valid solution - if you want to learn about some proper method you may give a look into Sequential Hypothesis Testing, a topic that I may explore in future posts. Here my goal is to understand the consequences of naive repeated checking, which can be easily found out through simulation."
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#whats-the-matter-with-repeated-checks",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#whats-the-matter-with-repeated-checks",
    "title": "AB tests and repeated checks",
    "section": "What’s the matter with repeated checks?",
    "text": "What’s the matter with repeated checks?\nTo understand why problems can arise, recall that the classical Frequentist framework 1 operates by providing a priori guarantees (bounds) on the probabilities of 2:\n\nA false positive outcome in the absence of any signal: rejecting the null hypothesis when this is actually true.\nA false negative outcome in the presence of some (well-defined) signal.\n\nThe a priori nature of these guarantees means that they are stipulated before running the experiment and assuming a certain experimental schedule 3. This implies that any departure from the original schedule can in principle invalidate the claimed False Positive Rate (FPR) and False Negative Rate (FNR).\nFor instance, the most basic experimental schedule (actually the one implicitly assumed by virtually all sample size calculators ) is:\n\nCollect data until reaching a prefixed sample size.\nRun an hypothesis test (with a prefixed significance threshold for claiming a signal).\n\nCommon examples of departures from the original schedule include:\n\nRunning several tests on partial data (before reaching the established sample size), to look for an early signal.\nStopping the experiment beforehand, because partial data doesn’t show any signal.\nProlonging the experiment after reaching the established sample size, because there’s a “hint” to a signal, but the significance threshold was not reached.\n\nIn what follows, I will focus on the first behavior, whose result is to inflate the FPR. Again, there are various ways to perform repeated checks while keeping the FPR under control, but that’s not the focus of this post. Instead, I want to understand how FPR is affected when the same test is repeated several times on partial data."
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#example",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#example",
    "title": "AB tests and repeated checks",
    "section": "Example",
    "text": "Example\nLet me illustrate the idea with an imaginary marketing experiment. Suppose you are optimizing an advertising campaign, say you want to test whether a new ad design performs better than the existing one in terms of click through rates. You start sending batches of two thousands ads4 to randomized users, half using the new design and half using the old one.\nIf the new design does actually perform better, you want to fully switch to it as soon as possible, so that after each batch send, you compare the click through rates of all ads sent so far, with the idea of switching as soon as a statistically significant improvement is observed.\nConcretely, you propose to do the following:\n\nAt each step, calculate the click through rates for the new and old designs.\nCompute a \\(p\\)-value for the hypothesis test5 that tests whether the new design leads to an higher click through rate than the old one.\nIf the \\(p\\)-value is smaller than a certain fixed threshold \\(\\alpha\\), stop the experiment and declare the new design as the winner.\nIf no \\(p\\)-value smaller than \\(\\alpha\\) is observed after a certain number \\(n\\) of iterations, stop the experiment and declare the old design as the winner.\n\nNow, the question is: how often would the above procedure declare the new design as the winner, if it doesn’t truly perform better than the old one? (i.e. what is the FPR of the whole procedure?)"
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#simulation",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#simulation",
    "title": "AB tests and repeated checks",
    "section": "Simulation",
    "text": "Simulation\nTo compute the FPR, we assume that both the new and old designs have in fact the same click through rate \\(p = 10 \\%\\). The following function generates a sequence of \\(n\\) consecutive \\(p\\)-values, computed as described above, that one could observe under these circumstances:\n\ngenerate_p_values &lt;- function(n = 28,      # maximum number of iterations\n                                                            size = 1e3,  # ad sends per batch\n                                                            p = 0.1      # true common click through rate\n                                                            ) \n    {\n    successes_a &lt;- cumsum( rbinom(n = n, size = size, prob = p) )  # clicks old ad\n    successes_b &lt;- cumsum( rbinom(n = n, size = size, prob = p) )  # clicks new ad\n    \n    sapply(1:n, \\(k) {\n        prop.test(\n            x = c(successes_a[k], successes_b[k]), \n            n = k * size * c(1, 1), \n            alternative = \"greater\",\n            )$p.value\n    })\n}\n\nFor instance:\n\nset.seed(999)\n( p_example &lt;- generate_p_values(n = 5) )\n\n[1] 0.4704229 0.3932333 0.1669308 0.2219066 0.2592812\n\n\nThe function below evaluates such a sequence of \\(p\\)-values with a fixed threshold \\(\\alpha\\):\n\nevaluate_p_values &lt;- function(p, alpha = 0.05, checkpoints = seq_along(p)) {\n    p &lt;- p[checkpoints]\n    as.logical(cumsum(p &lt; alpha))\n}\n\nFor instance, with \\(\\alpha = 20\\%\\), the sequence above would lead to a (false) positive result, which would be claimed at the third check. Output looks as follows:\n\nevaluate_p_values(p_example, alpha = 0.2)\n\n[1] FALSE FALSE  TRUE  TRUE  TRUE\n\n\nLet me now simulate a large number of such “experiments”. I will fix \\(\\alpha = 5\\%\\), a popular choice:\n\nset.seed(840)\nsim_data &lt;- replicate(1e4, generate_p_values(n = 100) |&gt; evaluate_p_values())\n\nThe result is a matrix whose columns are logical vectors such as the one above:\n\nsim_data[,1]\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE\n\n\n(a true negative result). Hence, the averages of this matrix rows provide the false positive rates after \\(n\\) checks:\n\nfpr &lt;- rowMeans(sim_data)\nplot(fpr, type = \"l\", xlab = \"Checks\", ylab = \"False Positive Rate\")\nabline(h = 0.05, col = \"red\", lty = \"dashed\")\n\n\n\n\n\n\n\n\nThe curve above shows how the FPR depends on the number of checks performed, according to the procedure described in the previous section. For a single check, this coincides with FPR of an individual binomial test6. However, allowing for repeated checks, we see that the overall FPR steadily increases with number of checks. With \\(n = 3\\) checks, the FPR is already close to \\(10 \\%\\), almost twice the nominal FPR of each individual test:\n\nfpr[3]\n\n[1] 0.0929\n\n\nWith \\(n \\approx 40\\) checks, the FPR is about \\(25 \\%\\), the same FPR of an experiment that involves tossing a coin twice, declaring it biased if the result is two consecutive “tails”.\n\nfpr[40]\n\n[1] 0.2471\n\n\nHere we are assuming that data is re-checked after the arrival of every single batch, but there are of course infinite alternative possibilities. For instance, the plot below shows what happens when checks are performed after the collection of \\(n = 1, \\,4, \\,16, \\,64\\) batches of data (at each checkpoint, the expected size of statistical fluctuations is reduced by a factor of \\(2\\)).\n\n\nCode\ncheckpoints &lt;- c(1, 4, 16, 64)\n\nset.seed(840)\nfpr2 &lt;- replicate(1e4, \n                    generate_p_values(n = 64) |&gt; \n                        evaluate_p_values(checkpoints = checkpoints)\n                    ) |&gt;\n    rowMeans()\n\nplot(fpr2, \n         type = \"b\", \n         xlab = \"Checks\", \n         ylab = \"False Positive Rate\", \n         xaxt = \"n\"\n         )\n\nabline(h = 0.05, col = \"red\", lty = \"dashed\")\naxis(1, at = seq_along(checkpoints))\naxis(3, at = seq_along(checkpoints), labels = paste(checkpoints, \"K\"))\nmtext(\"Sample Size\", side = 3, line = 2)\n\n\n\n\n\n\n\n\n\nAs a third possible variation, we may think of applying different \\(p\\)-value thresholds at different checks (a scheme that can be actually made to work in practice, see for instance the Wikipedia article on the Haybittle–Peto boundary). The following plot illustrates this, assuming three (equally spaced) checks after the collection of \\(n = 1,\\,2,\\,3\\) data batches, using the significance thresholds \\(\\alpha = 0.01, \\,0.025, \\,0.05\\), respectively.\n\n\nCode\nset.seed(840)\n\nalpha &lt;- c(0.01, 0.025, 0.05)\n\nfpr3 &lt;- replicate(1e5, \n                    generate_p_values(n = 3) |&gt; \n                        evaluate_p_values(alpha = alpha)\n                    ) |&gt;\n    rowMeans()\n\nplot(fpr3, \n         type = \"b\", \n         xlab = \"Checks\", \n         ylab = \"False Positive Rate\", \n         xaxt = \"n\"\n         )\n\nabline(h = alpha[3], col = \"red\", lty = \"dashed\")\nabline(h = alpha[2], col = \"blue\", lty = \"dashed\")\naxis(1, at = seq_along(fpr3))\naxis(3, at = seq_along(fpr3), labels = alpha)\nmtext(\"p-value threshold\", side = 3, line = 2)"
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#conclusions",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#conclusions",
    "title": "AB tests and repeated checks",
    "section": "Conclusions",
    "text": "Conclusions\nThis post illustrated quantitatively how the performance of repeated checks during the process of data collection can affect the overall False Positive Rate of an experimental analysis. The code provided above can be easily adapted to simulate other types of experiments and schemes for interim checks.\nA question that may possibly arise is: should I really care? You could argue that what I’ve shown here represents a simple trade-off between FPR on one side, FNR and efficiency (speed) in detection of a signal on the other.\nMy answer is a resounding yes, irrespective of whether you are running experiments for purely scientific or utilitaristic purposes. If you are unable to characterize (at least approximately) the FPR and FNR of your analysis, the whole point of running a formal test looks very dubious to me. You may as well simply collect some data and draw an educated guess.\nOther story is if you are able to tell in advance how interim checks affect FPR/FNR, and use this knowledge to optimize your analysis strategy. This note provides some clues on how to do so."
  },
  {
    "objectID": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#footnotes",
    "href": "posts/2023-07-24-ab-tests-and-repeated-checks/ab-tests-and-repeated-checks.html#footnotes",
    "title": "AB tests and repeated checks",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI move within this framework because it is the only one I’m reasonably comfortable with, and for which I have a decent understanding of the decision dynamics that follow from it. That said, I suspect that also Bayesian hypothesis testing can be affected by the kind of issues discussed here, although perhaps in a less transparent way, due to working with formal a posteriori probabilities.↩︎\nThe statistical jargon used to indicate these two types of errors, and the corresponding a priori guarantees on their probabilities, sounds very mysterious to me (Type I/II errors, size and power…). I like to think in terms of “False Positive” and “False Negative” rates, which is the same thing.↩︎\nThis is generally true, also in the aforementioned sequential settings. In that case, the difference is that the schedule takes into account that continuous and/or interim checks will be performed.↩︎\nThe actual numbers in this example may be totally unrealistic, but that’s beside the point.↩︎\nTechnically, this would be a two-sample, one-sided binomial test.↩︎\nThe fact that this is not exactly equal to \\(\\alpha\\), but in fact slightly smaller, is due to the discreteness of the underlying binomial distributions. The \\(p\\)-value of the binomial test is defined in such a way to satisfy \\(\\text{Pr}(p &lt; \\alpha)\\leq \\alpha\\).↩︎"
  },
  {
    "objectID": "posts/2023-06-14-sum-and-ratio-of-independent-random-variables/sum-and-ratio-of-independent-random-variables.html",
    "href": "posts/2023-06-14-sum-and-ratio-of-independent-random-variables/sum-and-ratio-of-independent-random-variables.html",
    "title": "Sum and ratio of independent random variables",
    "section": "",
    "text": "Let \\(X\\) and \\(Y\\) be two continuous independent random variables, with joint density \\(f_{XY}(x,y)=f_X(x)f_Y(y)\\). Define: \\[\ns = x+y, \\qquad r = x/y,\n\\] with inverse transformation given by:\n\\[\ny = \\frac{s}{1+r},\\qquad x = \\frac{rs}{1+r}.\n\\] The Jacobian of the \\((x,y) \\mapsto (s,r)\\) transformation is:\n\\[\n\\left|\\dfrac{\\partial (s,r)}{\\partial(x,y)}\\right|= \\dfrac{(1+r)^2}{s}.\n\\] Hence the joint density of \\(S = X+Y\\) and \\(R = X/Y\\) is given by:\n\\[\nf_{SR}(s,r) = f(x,y)\\left|\\dfrac{\\partial (x,y)}{\\partial(s,r)}\\right|=f_X(\\frac{rs}{1+r})f_Y(\\frac{s}{1+r})\\frac{s}{(1+r)^2}.\n\\]\nThe necessary and sufficient condition for this to factorize into a product, \\(f_{SR}(s,r)\\equiv f_S(s)f_R(r)\\), is that \\(f_X(x)f_Y(y) = g_S(s)g_R(r)\\) for some functions \\(g_S\\) and \\(g_R\\).\nThis is true for all functions \\(f_X\\) and \\(f_Y\\) from the family:\n\\[\n\\phi(t) = \\text{const} \\times  t^\\alpha e^{-\\beta t}.\n\\] This includes some important special cases:\n\nThe \\(\\chi ^2\\) distribution (\\(\\alpha = \\frac{\\nu}{2}-1,\\,\\beta = \\frac{1}{2}\\)).\n\nThe exponential distribution: \\(\\alpha = 0,\\,\\beta &gt;0\\).\nThe “homogeneous” distribution: \\(\\beta = 0\\) (restricted to the appropriate domain).\nThe uniform distribution: \\(\\alpha = \\beta = 0\\).\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2023,\n  author = {Gherardi, Valerio},\n  title = {Sum and Ratio of Independent Random Variables},\n  date = {2023-06-14},\n  url = {https://vgherard.github.io/posts/2023-06-14-sum-and-ratio-of-independent-random-variables/sum-and-ratio-of-independent-random-variables.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2023. “Sum and Ratio of Independent Random\nVariables.” June 14, 2023. https://vgherard.github.io/posts/2023-06-14-sum-and-ratio-of-independent-random-variables/sum-and-ratio-of-independent-random-variables.html."
  },
  {
    "objectID": "posts/2023-06-07-fishers-randomization-test/fishers-randomization-test.html",
    "href": "posts/2023-06-07-fishers-randomization-test/fishers-randomization-test.html",
    "title": "Fisher’s Randomization Test",
    "section": "",
    "text": "Let \\(N\\in \\mathbb N\\) be fixed, and let:\n\n\\(\\mathbf Y(1),\\,\\mathbf Y(0)\\in \\mathbb R ^N\\) be random vectors, with components \\(Y_i(1),Y_i(0)\\in \\mathbb R\\),\n\\(\\mathbf Z\\) be a random vector with components \\(Z_i \\in \\{0,1\\}\\), independent from \\(\\mathbf Y(1)\\) and \\(\\mathbf Y(0)\\) above,\n\\(\\mathbf Y = \\mathbf Z\\times \\mathbf Y(1)+(1-\\mathbf Z)\\times \\mathbf Y(0)\\) (multiplication is component-wise).\n\nGiven a scalar function \\(t = t(\\mathbf Z, \\,\\mathbf Y)\\in \\mathbb R\\), define:\n\\[\nP(t,\\mathbf Z, \\mathbf Y)=\\sum _{\\mathbf Z '}\\text{Pr}_\\mathbf Z(\\mathbf Z')\\cdot I(t(\\mathbf Z',\\mathbf Y)\\geq t(\\mathbf Z,\\mathbf Y)),\n\\] where \\(\\text{Pr}_\\mathbf Z(\\cdot)\\) is the marginal distribution of treatment assignments.\nTheorem. If \\(\\mathbf Y(0) = \\mathbf Y(1)\\) then:\n\\[\n\\text{Pr}(P(t,\\mathbf Z,\\mathbf Y)\\leq \\alpha) \\leq \\alpha.\n\\]\nProof. Let \\(\\mathbf Z'\\) be distributed according to \\(\\text{Pr}_\\mathbf Z(\\cdot)\\), and define \\(\\mathbf Y' = \\mathbf Z'\\times \\mathbf Y(1)+(1-\\mathbf Z')\\times \\mathbf Y(0)\\). Given \\(t_0\\in \\mathbb R\\), we observe that:\n\\[\n\\text {Pr}(t(\\mathbf Z',\\mathbf Y')\\geq t_0 \\,\\vert\\,\\mathbf Y(0),\\,\\mathbf Y(1)) = \\sum _{\\mathbf Z '}\\text{Pr}_\\mathbf Z(\\mathbf Z')\\cdot I(t(\\mathbf Z',\\mathbf Y')\\geq t_0).\n\\] Now, if \\(\\mathbf Y(0) = \\mathbf Y(1)\\), we have \\(t(\\mathbf Z',\\mathbf Y') = t(\\mathbf Z',\\mathbf Y)\\), so that we may replace \\(\\mathbf Y'\\) with \\(\\mathbf Y\\) in the RHS of the previous equation. If, moreover, we choose \\(t_0= t(\\mathbf Z , \\mathbf Y)\\) we obtain:\n\\[\nP(t, \\mathbf Z, \\mathbf Y) = \\text {Pr}(t(\\mathbf Z',\\mathbf Y')\\geq t(\\mathbf Z,\\mathbf Y) \\,\\vert\\,\\mathbf Y(0),\\mathbf Y(1)).\n\\] In other words, \\(P(t,\\mathbf Z, \\mathbf Y)\\) is a conditional \\(p\\)-value. Therefore:\n\\[\n\\text{Pr}(P(t,\\mathbf Z,\\mathbf Y)\\leq \\alpha \\,\\vert\\,\\mathbf Y(0),\\mathbf Y(1)) \\leq \\alpha.\n\\]\nSince this is valid for any value of \\(\\mathbf Y (0)\\) and \\(\\mathbf Y(1)\\), the thesis follows.\n\nIn the usual setting of causal inference, we interpret:\n\n\\(Z_i\\) as the treatment assignment for the \\(i\\)-th statistical unit, \\(Z_i = 0,1\\) standing for “treatment” and “control”, respectively.\n\\(Y_i(1)\\) and \\(Y_i(0)\\) as the potential outcomes for the \\(i\\)-th unit under treatment and control, respectively.\n\\(Y_i\\) as the observed outcome for the \\(i\\)-th unit.\n\\(t(\\cdot)\\) as a test statistic used to test the null hypothesis \\(\\mathbf Y(1)= \\mathbf Y (0)\\).\n\\(P(t,\\mathbf Z,\\mathbf Y)\\) is the randomization \\(p\\)-value of \\(t(\\mathbf Z, \\mathbf Y)\\) in a Fisher Randomization Test.\n\nFisher’s “sharp” null hypothesis is an equality between random variables, the potential outcomes. Typical examples for the distribution \\(\\text{Pr}_\\mathbf Z(\\cdot)\\) are:\n\nCompletely Randomized Experiment (CRE):\n\n\\[\n\\text{Pr}_\\mathbf Z (\\mathbf Z) = \\begin{cases}\n\\binom N {n_1} ^{-1} & \\sum _{i=1}^N Z_i =n_1, \\\\\n0 & \\text{otherwise.}\n\\end{cases}\n\\]\n\nBernoulli Randomized Experiment (BRE):\n\n\\[\n\\text{Pr}_\\mathbf Z (\\mathbf Z) = \\prod _{i=1} ^N \\pi^{Z_i}(1-\\pi)^{1-Z_i}.\n\\]\nAn example of test statistic is the difference in means between the treatment and control group, that can be written:\n\\[\nt(\\mathbf Z , \\mathbf Y) = \\sum_i c_i Y_i,\\qquad c_i=\\frac{Z_i}{\\sum _iZ_i} - \\frac{1-Z_i}{\\sum _i(1-Z_i)}.\n\\]\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2023,\n  author = {Gherardi, Valerio},\n  title = {Fisher’s {Randomization} {Test}},\n  date = {2023-06-07},\n  url = {https://vgherard.github.io/posts/2023-06-07-fishers-randomization-test/fishers-randomization-test.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2023. “Fisher’s Randomization Test.”\nJune 7, 2023. https://vgherard.github.io/posts/2023-06-07-fishers-randomization-test/fishers-randomization-test.html."
  },
  {
    "objectID": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html",
    "href": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html",
    "title": "Model Misspecification and Linear Sandwiches",
    "section": "",
    "text": "Traditional linear models, such as the output of the R function lm(), are often loaded with a set of strong assumptions. Take univariate regression:\n\\[\nY = q+mX+\\varepsilon.\n\\tag{1}\\]\nThis equation assumes that:\n\nThe conditional mean \\(\\mathbb E(Y\\vert X) = q + mX\\), a linear function of \\(X\\).\nThe conditional variance \\(\\mathbb {V}(Y \\vert X)=\\mathbb{V}(\\varepsilon\\vert X)\\) is independent of \\(X\\).\nThe conditional distribution \\(Y\\vert X\\) is gaussian.\nIn a set of measurements \\(\\left\\{\\left(X_i,Y_i\\right)\\right\\}_{i = 1,\\, \\dots, \\,N}\\), \\(Y_i\\) and the set \\(\\left\\{ X_j, Y_j\\right\\} _{j\\neq i}\\) are conditionally independent of each other, given the value of the corresponding regressor \\(X_i\\).1\n\nThe last assumption is satisfied in many practical situations, and we will take it here for granted2. What happens when the first three assumptions are violated (that is “frequently” to “almost always”, depending on context)?\nA comprehensive discussion is provided by (Buja et al. 2019). These authors show that:\n\nIf the conditional mean \\(\\mathbb E (Y \\vert X)\\) is not linear (“first order misspecification”), then the Ordinary Least Squares (OLS) regression coefficients \\(\\hat \\beta\\) consistently estimate: \\[\n\\beta \\equiv \\text{arg } \\min _{\\beta^\\prime} \\mathbb E((Y-X\\beta^\\prime)^2)\n\\tag{2}\\]\n\nwhich can be thought as the “best linear approximation of the response”3.\n\nBoth non-linearity in the sense of the previous point, and \\(X\\)-dependence in \\(\\mathbb{V}(Y \\vert X)\\) (“second order misspecification”) affect the sampling distribution of \\(\\hat \\beta\\) and, in particular, \\(\\mathbb{V}(\\hat \\beta)\\), which is the relevant quantity for inference in the large-sample limit.\nBoth problems can be efficiently addressed through the so-called “sandwich” estimators for the covariance matrix of \\(\\hat \\beta\\) (White 1980), whose consistency is robust to both type of misspecification.\n\nDetails can be found in the mentioned reference. The rest of the post illustrates with examples how to compute “sandwich” estimates in R, and why you may want to do so."
  },
  {
    "objectID": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#introduction",
    "href": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#introduction",
    "title": "Model Misspecification and Linear Sandwiches",
    "section": "",
    "text": "Traditional linear models, such as the output of the R function lm(), are often loaded with a set of strong assumptions. Take univariate regression:\n\\[\nY = q+mX+\\varepsilon.\n\\tag{1}\\]\nThis equation assumes that:\n\nThe conditional mean \\(\\mathbb E(Y\\vert X) = q + mX\\), a linear function of \\(X\\).\nThe conditional variance \\(\\mathbb {V}(Y \\vert X)=\\mathbb{V}(\\varepsilon\\vert X)\\) is independent of \\(X\\).\nThe conditional distribution \\(Y\\vert X\\) is gaussian.\nIn a set of measurements \\(\\left\\{\\left(X_i,Y_i\\right)\\right\\}_{i = 1,\\, \\dots, \\,N}\\), \\(Y_i\\) and the set \\(\\left\\{ X_j, Y_j\\right\\} _{j\\neq i}\\) are conditionally independent of each other, given the value of the corresponding regressor \\(X_i\\).1\n\nThe last assumption is satisfied in many practical situations, and we will take it here for granted2. What happens when the first three assumptions are violated (that is “frequently” to “almost always”, depending on context)?\nA comprehensive discussion is provided by (Buja et al. 2019). These authors show that:\n\nIf the conditional mean \\(\\mathbb E (Y \\vert X)\\) is not linear (“first order misspecification”), then the Ordinary Least Squares (OLS) regression coefficients \\(\\hat \\beta\\) consistently estimate: \\[\n\\beta \\equiv \\text{arg } \\min _{\\beta^\\prime} \\mathbb E((Y-X\\beta^\\prime)^2)\n\\tag{2}\\]\n\nwhich can be thought as the “best linear approximation of the response”3.\n\nBoth non-linearity in the sense of the previous point, and \\(X\\)-dependence in \\(\\mathbb{V}(Y \\vert X)\\) (“second order misspecification”) affect the sampling distribution of \\(\\hat \\beta\\) and, in particular, \\(\\mathbb{V}(\\hat \\beta)\\), which is the relevant quantity for inference in the large-sample limit.\nBoth problems can be efficiently addressed through the so-called “sandwich” estimators for the covariance matrix of \\(\\hat \\beta\\) (White 1980), whose consistency is robust to both type of misspecification.\n\nDetails can be found in the mentioned reference. The rest of the post illustrates with examples how to compute “sandwich” estimates in R, and why you may want to do so."
  },
  {
    "objectID": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#fitting-misspecified-linear-models-in-r",
    "href": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#fitting-misspecified-linear-models-in-r",
    "title": "Model Misspecification and Linear Sandwiches",
    "section": "Fitting misspecified linear models in R",
    "text": "Fitting misspecified linear models in R\nThe {sandwich} package (available on CRAN) provides estimators for the regression coefficients’ variance-covariance matrix \\(\\mathbb V (\\hat \\beta)\\) that are robust to first and second order misspecification. These can be readily used with lm objects, as in the example below:\n\nfit &lt;- lm(mpg ~ wt, data = mtcars)\n\nstats::vcov(fit)  # standard vcov (linear model trusting estimate)\n\n            (Intercept)        wt\n(Intercept)    3.525484 -1.005693\nwt            -1.005693  0.312594\n\nsandwich::vcovHC(fit)  # sandwich vcov (model-robust estimate)\n\n            (Intercept)         wt\n(Intercept)    5.889249 -1.7418581\nwt            -1.741858  0.5448011\n\n\nIt is important to note that both functions stats::vcov() and sandwich::vcovHC() employ the same point estimates of regression coefficients\nto compute \\(\\mathbb V (\\hat \\beta)\\):\n\nfit\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\n\nThe difference between these functions lies in the different assumptions they make on the linear model residuals, which leads to different estimates for \\(\\mathbb{V}(\\hat \\beta)\\)."
  },
  {
    "objectID": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#effects-of-misspecification",
    "href": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#effects-of-misspecification",
    "title": "Model Misspecification and Linear Sandwiches",
    "section": "Effects of misspecification",
    "text": "Effects of misspecification\nThis section illustrates some consequences of model misspecification through simulation. The examples use:\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nFor convenience, we define some helpers to be used in the following examples. The function below returns random generators for the generic additive error model \\(Y = f(X) + \\varepsilon\\), where the distribution of the noise term \\(\\varepsilon\\) may in general depend on \\(X\\). Both \\(X\\) and \\(Y\\) are assumed here and below to be 1-dimensional.\n\nrxy_fun &lt;- function(rx, f, reps) {\n    res &lt;- function(n) {\n        x &lt;- rx(n)  # X has marginal distribution 'rx'\n        y &lt;- f(x) + reps(x)  # Y has conditional mean 'f(x)' and noise 'reps(x)'\n        return(tibble(x = x, y = y))  \n    }\n    return(structure(res, class = \"rxy\"))\n}\n\nplot.rxy &lt;- function(x, N = 1000, seed = 840) {\n    set.seed(seed)\n    \n    ggplot(data = x(N), aes(x = x, y = y)) +\n        geom_point(alpha = 0.3) + \n        geom_smooth(method = \"lm\", se = FALSE)\n}\n\nThe following function simulates fitting the linear model y ~ x over multiple datasets generated according to a function rxy().\n\nlmsim &lt;- function(rxy, N = 100, vcov = stats::vcov, B = 1e3, seed = 840) \n{ \n    set.seed(seed)\n    \n    res &lt;- list(coef = matrix(nrow = B, ncol = 2), vcov = vector(\"list\", B))\n    colnames(res$coef) &lt;- c(\"(Intercept)\", \"x\")\n    class(res) &lt;- \"lmsim\"\n                                \n    for (b in 1:B) {\n        .fit &lt;- lm(y ~ ., data = rxy(N))\n        res$coef[b, ] &lt;- coef(.fit)  # Store intercept and slope in B x 2 matrix\n        res$vcov[[b]] &lt;- vcov(.fit)  # Store vcov estimates in length B list. \n    }\n    \n    return(res)\n}\n\nprint.lmsim &lt;- function(x) \n{\n    cat(\"Simulation results:\\n\\n\")\n    cat(\"* Model-trusting vcov (average of vcov estimates):\\n\")\n    print( avg_est_vcov &lt;- Reduce(\"+\", x$vcov) / length(x$vcov) )\n    cat(\"\\n* Simulation-based vcov (vcov of coefficient estimates):\\n\")\n    print( emp_vcov &lt;- cov(x$coef))\n    cat(\"\\n* Ratio (1st / 2nd):\\n\")\n    print( avg_est_vcov / emp_vcov )\n    return(invisible(x))\n}\n\nThe print method defined above shows a comparison of the covariance matrices obtained by:\n\nAveraging variance-covariance estimates from the various simulations, and\nTaking the variance-covariance matrix of regression coefficients obtained in the simulations.\n\nThe first one can be considered a “model-trusting” estimate (where the actual “model” is specified by the vcov argument of lmsim(), i.e. stats::vcov and sandwich::vcovHC for the traditional and sandwich estimates, respectively). The second one is a model-free simulation-based estimate of the true \\(\\mathbb{V}(\\hat \\beta)\\). The comparison between the two4 provides a measure of the asymptotic bias of the model-trusting estimate.\n\nExample 1: First order misspecification\n\\[\nY = X ^ 2 + \\varepsilon,\\quad X \\sim \\text{Unif} (0,1),\\qquad \\varepsilon \\sim \\mathcal N (0,0.01)\n\\]\n\nrxy_01 &lt;- rxy_fun(\n    rx = runif,\n    f = \\(x) x^2,\n    reps = \\(x) rnorm(length(x), sd = .01)\n    )\n\nIn this model, \\(\\mathbb E (Y \\vert X)\\) is not linear in \\(X\\) (first order misspecification), but the remaining assumptions of the linear model hold. This is how a typical linear fit of data generated from this model looks like:\n\nplot(rxy_01, N = 300)\n\n\n\n\n\n\n\n\nHere the effect of misspecification on the variance-covariance model trusting estimates is to underestimate true covariance values (by a factor as large as 40%!):\n\nlmsim(rxy_01)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n              (Intercept)             x\n(Intercept)  0.0002277348 -0.0003417356\nx           -0.0003417356  0.0006833282\n\n* Simulation-based vcov (vcov of coefficient estimates):\n              (Intercept)             x\n(Intercept)  0.0003367876 -0.0005662584\nx           -0.0005662584  0.0011488351\n\n* Ratio (1st / 2nd):\n            (Intercept)         x\n(Intercept)   0.6761971 0.6034976\nx             0.6034976 0.5948009\n\n\nThis is fixed by the sandwich::vcovHC() estimators:\n\nlmsim(rxy_01, vcov = sandwich::vcovHC)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n              (Intercept)             x\n(Intercept)  0.0003475834 -0.0005732957\nx           -0.0005732957  0.0011443449\n\n* Simulation-based vcov (vcov of coefficient estimates):\n              (Intercept)             x\n(Intercept)  0.0003367876 -0.0005662584\nx           -0.0005662584  0.0011488351\n\n* Ratio (1st / 2nd):\n            (Intercept)         x\n(Intercept)    1.032055 1.0124276\nx              1.012428 0.9960916\n\n\n\n\nExample 2: Second order misspecification\n\\[\nY = X + \\varepsilon,\\quad X \\sim \\text{Unif} (0,1),\\qquad \\varepsilon \\sim \\mathcal N (0,X)\n\\]\n\nrxy_02 &lt;- rxy_fun(\n    rx = runif,\n    f = \\(x) x,\n    reps = \\(x) rnorm(length(x), sd = x)\n    )\n\nplot(rxy_02, N = 300)\n\n\n\n\n\n\n\n\nThis model is first-order consistent, but second-order misspecified (variance is not independent of \\(X\\)). The effects on vcov model-trusting estimates is mixed: some covariances are underestimated, some are overestimated.\n\nlmsim(rxy_02)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n            (Intercept)           x\n(Intercept)  0.01344466 -0.02014604\nx           -0.02014604  0.04008595\n\n* Simulation-based vcov (vcov of coefficient estimates):\n             (Intercept)           x\n(Intercept)  0.005456494 -0.01417346\nx           -0.014173461  0.04834196\n\n* Ratio (1st / 2nd):\n            (Intercept)         x\n(Intercept)    2.463974 1.4213920\nx              1.421392 0.8292164\n\n\nAgain, this large bias is corrected by the sandwich estimator:\n\nlmsim(rxy_02, vcov = sandwich::vcovHC)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n             (Intercept)           x\n(Intercept)  0.005637138 -0.01451506\nx           -0.014515056  0.04909868\n\n* Simulation-based vcov (vcov of coefficient estimates):\n             (Intercept)           x\n(Intercept)  0.005456494 -0.01417346\nx           -0.014173461  0.04834196\n\n* Ratio (1st / 2nd):\n            (Intercept)        x\n(Intercept)    1.033106 1.024101\nx              1.024101 1.015653\n\n\n\n\nExample 3: sample size effects\nThe sandwich estimators only become unbiased in the large sample limit. For instance, in our previous Example 1, the sandwich covariance estimates require sample sizes of \\(N \\approx 50\\) or larger, in order for their bias to be relatively contained (\\(\\lesssim 10\\%\\)). With a small sample size:\n\nlmsim(rxy_01, N = 10, vcov = sandwich::vcovHC)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n             (Intercept)           x\n(Intercept)  0.008253143 -0.01356350\nx           -0.013563503  0.02691423\n\n* Simulation-based vcov (vcov of coefficient estimates):\n             (Intercept)            x\n(Intercept)  0.005084963 -0.008573385\nx           -0.008573385  0.017136158\n\n* Ratio (1st / 2nd):\n            (Intercept)        x\n(Intercept)    1.623049 1.582048\nx              1.582048 1.570611\n\n\nFor such small sample sizes, however, one should probably also keep into account the bias in the point estimate \\(\\hat \\beta\\) itself, so that the bias in the variance \\(\\mathbb V (\\hat \\beta)\\) becomes a kinda second-order problem.\n\n\nExample 4: variance underestimation and overestimation\nAccording to the heuristics of (Buja et al. 2019), the linear model trusting variances \\(\\mathbb V (\\hat \\beta)_{ii}\\) tend to underestimate (overestimate) the true variances:\n\nIn the presence of non-linearity, when the strong deviations from linearity are far away from (close to) the center of the regressor distribution.\nIn the presence of heteroskedasticity, when the regions of high variance are far away from the (close to) the center of the regressor distribution.\n\nWe illustrate the second case. Consider the following two models:\n\\[\nY = X + \\varepsilon,\\quad X \\sim \\text{Unif} (0,1),\\qquad \\varepsilon \\sim \\mathcal N (0,\\vert X-\\frac{1}{2}\\vert )\n\\]\n\nrxy_04a &lt;- rxy_fun(\n    rx = runif,\n    f = \\(x) x,\n    reps = \\(x) rnorm(length(x), sd = abs(0.5 - x))\n    )\n\nplot(rxy_04a)\n\n\n\n\n\n\n\n\n\\[\nY = X + \\varepsilon,\\quad X \\sim \\text{Unif} (0,1),\\qquad \\varepsilon \\sim \\mathcal N (0,\\frac{1}{2}-\\vert X-\\frac{1}{2}\\vert )\n\\]\n\nrxy_04b &lt;- rxy_fun(\n    rx = runif,\n    f = \\(x) x,\n    reps = \\(x) rnorm(length(x), sd = 0.5 - abs(0.5 - x))\n    )\n\nplot(rxy_04b)\n\n\n\n\n\n\n\n\nIn agreement with the heuristics, we have, for the first model:\n\nlmsim(rxy_04a)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n             (Intercept)            x\n(Intercept)  0.003326042 -0.004989057\nx           -0.004989057  0.009977552\n\n* Simulation-based vcov (vcov of coefficient estimates):\n             (Intercept)            x\n(Intercept)  0.005390525 -0.009154439\nx           -0.009154439  0.018296535\n\n* Ratio (1st / 2nd):\n            (Intercept)         x\n(Intercept)   0.6170162 0.5449878\nx             0.5449878 0.5453247\n\n\nand, for the second model:\n\nlmsim(rxy_04b)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n             (Intercept)            x\n(Intercept)  0.003420946 -0.005150512\nx           -0.005150512  0.010300847\n\n* Simulation-based vcov (vcov of coefficient estimates):\n             (Intercept)            x\n(Intercept)  0.001590907 -0.001503471\nx           -0.001503471  0.003131620\n\n* Ratio (1st / 2nd):\n            (Intercept)        x\n(Intercept)    2.150312 3.425748\nx              3.425748 3.289303\n\n\nIt is interesting to notice that, far away from the large-sample limit, the sandwich estimates also have a bias (as discussed in the previous example), but the bias leads to an overestimate of \\(\\mathbb V (\\hat \\beta)\\) in both cases5:\n\nlmsim(rxy_04a, N = 10, vcov = sandwich::vcovHC)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n            (Intercept)          x\n(Intercept)  0.07714254 -0.1302820\nx           -0.13028198  0.2595908\n\n* Simulation-based vcov (vcov of coefficient estimates):\n            (Intercept)          x\n(Intercept)  0.05560994 -0.0957307\nx           -0.09573070  0.1947398\n\n* Ratio (1st / 2nd):\n            (Intercept)        x\n(Intercept)    1.387208 1.360922\nx              1.360922 1.333013\n\nlmsim(rxy_04b, N = 10, vcov = sandwich::vcovHC)\n\nSimulation results:\n\n* Model-trusting vcov (average of vcov estimates):\n            (Intercept)           x\n(Intercept)  0.05301354 -0.07223407\nx           -0.07223407  0.13959714\n\n* Simulation-based vcov (vcov of coefficient estimates):\n            (Intercept)           x\n(Intercept)  0.02725563 -0.03408101\nx           -0.03408101  0.06735272\n\n* Ratio (1st / 2nd):\n            (Intercept)        x\n(Intercept)    1.945049 2.119481\nx              2.119481 2.072628"
  },
  {
    "objectID": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#conclusions",
    "href": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#conclusions",
    "title": "Model Misspecification and Linear Sandwiches",
    "section": "Conclusions",
    "text": "Conclusions\nSandwich estimators provide valid inference for parameter covariances and standard errors in misspecified linear regression settings. These model-robust tools are available in R through {sandwich} (which also provides\nmethods for more general glm objects).\nFor fairly large datasets, this model-robust approach can be coupled with data splitting, leading to a modeling procedure which I’m finding to be quite solid and versatile in practice:\n\nPerform data exploration and model selection on a separate portion of data. This is to avoid biasing inferential results with random selective procedures.\nOnce a reasonable model is found, fit the model on the remaining data, adopting robust covariance estimates for model parameters.\n\nThis works very well with independent data for which a (generalized) linear model can provide a useful parametric description. Generalizations may be discussed in a separate post."
  },
  {
    "objectID": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#footnotes",
    "href": "posts/2023-05-14-model-misspecification-and-linear-sandwiches/misspecification-and-linear-sandwiches.html#footnotes",
    "title": "Model Misspecification and Linear Sandwiches",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is already somewhat implicit in Equation 1, that models \\(Y\\) and \\(X\\) as single random variables. The reason for stating this condition in an apparently convoluted way, rather than a simpler “data points* \\((X_i,Y_i)\\) are independent draws from the same joint distribution”, is that this formulation includes cases where the \\(X_i\\)’s are not* independent, cf. the following note.↩︎\nThere are of course important exceptions, like time series or spatial data. Noteworthy, our formulation of strict linear model assumptions can also cover some cases of temporal or spatial dependence in the regressors \\(X_i\\), provided that such dependence is not reflected on \\(Y_i \\vert X_i\\).↩︎\nAccording to an \\(L_2\\) loss criterion.↩︎\nI use an element-wise ratio, in order to avoid confusion from the different scales involved in the various entries of \\(\\mathbb V (\\hat \\beta)\\).↩︎\nI don’t know whether this result (that sandwich estimates are, at worst, overestimates) is a general one.↩︎"
  },
  {
    "objectID": "posts/2023-05-01-magic-piggy-bank/magic-piggy-bank.html",
    "href": "posts/2023-05-01-magic-piggy-bank/magic-piggy-bank.html",
    "title": "Bayes, Neyman and the Magic Piggy Bank",
    "section": "",
    "text": "Frequentist and Bayesian approaches to statistical inference are motivated by different interpretations of the concept of probability. These philosophical differences can, at times, shadow the comparably important operational differences between the two frameworks, whose methods proceed, at the end of the day, from the same mathematical theory.\nFrom the purely operational point of view, the question “Bayesian or Frequentist?” can (and should) be answered by objective criteria, rather than subjective opinions. As one could expect, the answer is in general neither “Frequentist” nor “Bayesian”, but rather “It depends”.\nTo illustrate this, I will discuss an hypothetical game that revolves around reporting measurements and correctly quantifying uncertainty. As we shall see, the winning strategies can be either Frequentist or Bayesian in spirit, depending on a variation of the actual rules of the game."
  },
  {
    "objectID": "posts/2023-05-01-magic-piggy-bank/magic-piggy-bank.html#footnotes",
    "href": "posts/2023-05-01-magic-piggy-bank/magic-piggy-bank.html#footnotes",
    "title": "Bayes, Neyman and the Magic Piggy Bank",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe introduction of bets as an expedient to operationally define subjective probabilities is historically due to the Italian mathematician Bruno de Finetti. The statistical analysis of the game proposed below can be given a Frequentist interpretation.↩︎\nReaders are free to imagine this process in the way they find more convenient.↩︎\nWe assume that both players know from the outset which variant of the game they are playing to.↩︎\nWe denote (with some abuse of notation) by \\(\\text{d}P(\\Theta \\vert X)\\) the conditional probability measure of \\(\\Theta\\) conditioned on \\(X\\).↩︎\nIn the Bayesian spirit of Equation 5, the Gambler could for instance estimate \\(\\pi(\\Theta)\\) through Bayesian updates of a Dirichlet prior.↩︎\nNoteworthy, the random quantity in this equation is \\(I\\), whereas \\(\\Theta\\) is regarded as fixed. This is in stark contrast with Equation 5, where \\(X\\) and \\(I\\) were fixed, and \\(\\Theta\\) was random.↩︎\nThere are, in fact, infinitely many more ways to produce intervals with the unconditional coverage property Equation 13.↩︎\nI see that Jaynes (the father of the Maximum Entropy foundation of Statistical Mechanics, among other things) has a full essay paper on Confidence Intervals vs. Bayesian Intervals, which I haven’t read - the abstract sounds a bit loaded to me, but it’s probably definitely worth to read.↩︎"
  },
  {
    "objectID": "posts/2022-11-07-posi-2/posi-2.html",
    "href": "posts/2022-11-07-posi-2/posi-2.html",
    "title": "How to get away with selection. Part II: Mathematical Framework",
    "section": "",
    "text": "In a previous post I introduced the problem of Selective Inference and illustrated, in a simplified setting, how selection generally affects the coverage of confidence intervals - when they are both selected and constructed using the same data. While the example was (hopefully) helpful to build some intuition, in order to discuss “How to get away with selection” in a comprehensive manner we need to make a few clarifications. In particular, we need to answer the following questions:\n\nWhat is the target of our Selective Inference?\nWhat statistical properties would we like our inferences to have?\n\nSearching through the literature, I realized there exist a bunch of variations on these two themes, which give rise to different mathematical formalisms. Specifying these points is mandatory for any further discussion, so my main goal here is to present these different points of view and explain some of their pros and cons."
  },
  {
    "objectID": "posts/2022-11-07-posi-2/posi-2.html#footnotes",
    "href": "posts/2022-11-07-posi-2/posi-2.html#footnotes",
    "title": "How to get away with selection. Part II: Mathematical Framework",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhere what’s to be considered best is defined in terms of some reasonable metric. For instance, for the conditional mean \\(f(X)\\) of a continuous response \\(Y\\), a convenient target \\(f^*(X)\\) within a prescribed family of functions \\(\\mathcal F\\) can be defined by \\(f^* =\\arg\\min _{\\phi \\in \\mathcal F} \\mathbb E (\\vert f(X) - \\phi (X)\\vert^2)\\).↩︎\nThere’s also a third advantage, which is that I find much harder to think about selective inference from the Model Trusting point of view, hence to write blog posts about it - but that’s likely a limitation of my imagination, rather than of the point of view itself.↩︎\nA cool word for “wrong”.↩︎\nWhy \\(q\\) and not \\(\\alpha\\)? Ask (Benjamini and Yekutieli 2005).↩︎\nIt is assumed that the selection is performed from a from a fixed family of models \\(\\mathcal M\\).↩︎"
  },
  {
    "objectID": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html",
    "href": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html",
    "title": "kgrams v0.1.2 on CRAN",
    "section": "",
    "text": "Version v0.1.2 of my R package kgrams was just accepted by CRAN. This package provides tools for training and evaluating k-gram language models in R, supporting several probability smoothing techniques, perplexity computations, random text generation and more."
  },
  {
    "objectID": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html#summary",
    "href": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html#summary",
    "title": "kgrams v0.1.2 on CRAN",
    "section": "",
    "text": "Version v0.1.2 of my R package kgrams was just accepted by CRAN. This package provides tools for training and evaluating k-gram language models in R, supporting several probability smoothing techniques, perplexity computations, random text generation and more."
  },
  {
    "objectID": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html#short-demo",
    "href": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html#short-demo",
    "title": "kgrams v0.1.2 on CRAN",
    "section": "Short demo",
    "text": "Short demo\n\nlibrary(kgrams)\n# Get k-gram frequency counts from Shakespeare's \"Much Ado About Nothing\"\nfreqs &lt;- kgram_freqs(kgrams::much_ado, N = 4)\n\n# Build modified Kneser-Ney 4-gram model, with discount parameters D1, D2, D3.\nmkn &lt;- language_model(freqs, smoother = \"mkn\", D1 = 0.25, D2 = 0.5, D3 = 0.75)\n\n# Sample sentences from the language model at different temperatures\nset.seed(840)\nsample_sentences(model = mkn, n = 3, max_length = 10, t = 1)\n\n[1] \"i have studied eight or nine truly by your office [...] (truncated output)\"\n[2] \"ere you go : &lt;EOS&gt;\"                                                        \n[3] \"don pedro welcome signior : &lt;EOS&gt;\"                                         \n\nsample_sentences(model = mkn, n = 3, max_length = 10, t = 0.1)\n\n[1] \"i will not be sworn but love may transform me [...] (truncated output)\" \n[2] \"i will not fail . &lt;EOS&gt;\"                                                \n[3] \"i will go to benedick and counsel him to fight [...] (truncated output)\"\n\nsample_sentences(model = mkn, n = 3, max_length = 10, t = 10)\n\n[1] \"july cham's incite start ancientry effect torture tore pains endings [...] (truncated output)\"   \n[2] \"lastly gallants happiness publish margaret what by spots commodity wake [...] (truncated output)\"\n[3] \"born all's 'fool' nest praise hurt messina build afar dancing [...] (truncated output)\""
  },
  {
    "objectID": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html#news",
    "href": "posts/2021-11-13-kgrams-v012-released/kgrams-v012-released.html#news",
    "title": "kgrams v0.1.2 on CRAN",
    "section": "NEWS",
    "text": "NEWS\n\nOverall Software Improvements\n\nThe package’s test suite has been greatly extended.\nImproved error/warning conditions for wrong arguments.\nRe-enabled compiler diagnostics as per CRAN policy (#19)\n\n\n\nAPI Changes\n\nverbose arguments now default to FALSE.\nprobability(), perplexity() and sample_sentences() are restricted to accept only language_model class objects as their model argument.\n\n\n\nNew features\n\nas_dictionary(NULL) now returns an empty dictionary.\n\n\n\nBug Fixes\n\nFixed bug causing .preprocess and .tknz_sent arguments to be ignored in process_sentences().\nFixed previously wrong defaults for max_lines and batch_size arguments in kgram_freqs.connection().\nAdded print method for class dictionary.\nFixed bug causing invalid results in dictionary() with batch processing and non-trivial size constraints on vocabulary size.\n\n\n\nOther\n\nMaintainer’s email updated"
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "Notebooks",
    "section": "",
    "text": "Title\n\n\nDate\n\n\nModified\n\n\nDescription\n\n\n\n\n\n\nMaximum Likelihood\n\n\nMar 14, 2024\n\n\n10/15/24, 4:27:52 PM\n\n\n\n\n\n\n\nExponential Dispersion Models\n\n\nMar 7, 2024\n\n\n10/15/24, 4:15:16 PM\n\n\n\n\n\n\n\nBootstrap\n\n\nFeb 7, 2024\n\n\n10/15/24, 3:57:04 PM\n\n\n\n\n\n\n\nOrdinary Least Squares\n\n\nFeb 7, 2024\n\n\n10/15/24, 3:25:03 PM\n\n\n\n\n\n\n\nThermodynamics\n\n\nJul 31, 2024\n\n\n10/15/24, 3:11:16 PM\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html",
    "title": "Ordinary Least Squares",
    "section": "",
    "text": "Ordinary Least Squares (OLS) is a regression algorithm for estimating the best linear predictor (BLP) \\(f^*(X) = X\\beta\\) of a response \\(Y \\in \\mathbb R\\) in terms of a vector of regressors \\(X\\in \\mathbb R ^p\\), which we will frequently identify with an \\(1\\times p\\) row matrix. Here, “best” is understood in terms of the \\(L_2\\) error:\n\\[\n\\beta = \\arg \\min _{\\beta '}  \\mathbb E[(Y - X\\beta ^\\prime)^2]=\\mathbb E (X^TX)^{-1}\\mathbb E(X^T Y),\n\\tag{1}\\]\nwhere the first equation is the defining one, while the second one follows from elementary calculus.\nGiven i.i.d. data \\(\\{(X_i,\\,Y_i)\\}_{i=1,\\,2,\\,\\dots,\\,N}\\), and denoting by \\(\\mathbf Y\\) and \\(\\mathbf X\\) the \\(N\\times 1\\) and \\(N\\times p\\) matrices obtained by vertically stacking independent observations of \\(Y\\) and \\(X\\), respectively, the OLS estimate of Equation 1 is defined by:\n\\[\n\\hat \\beta = \\arg \\min _{\\beta '}  \\sum _{i=1} ^N \\frac{1}{N}(Y_i - X_i\\beta ^\\prime)^2 = (\\mathbf X ^T \\mathbf X) ^{-1} \\mathbf X ^T \\mathbf Y,\n\\tag{2}\\]\nwhich is readily recognized to be the plugin estimate of \\(\\beta\\). Correspondingly, we define the OLS predictor:\n\\[\n\\hat Y (x) = x \\hat \\beta.\n\\tag{3}\\]\nWhat motivates the use of an \\(L_2\\) criterion in Equation 1?\n\nMathematical tractability. The fact that Equation 1 admits a closed form solution, which is furthermore linear in the response variable \\(Y\\), greatly simplifies the analysis of the properties of \\(\\beta\\) and its estimators such as the OLS one Equation 2, making it a perfect study case.\nNumerical tractability. A consequence of the previous point, but worth a separate mention. Computing the plugin estimate in Equation 2 is just a matter of basic linear algebra manipulations, which, with modern software libraries, is a relatively cheap operation.\nNormal theory. Focusing on the consequence of Equation 1, namely the plugin estimate Equation 2, if the conditional distribution of \\(Y\\) given \\(X\\) is normal with constant variance, and if \\(\\mathbb E(Y\\vert X)\\) is truly linear, \\(\\beta\\) coincides with the maximum likelihood estimate of \\(\\beta\\).\n\n\n\nThe term generally refers to a model for the conditional distribution of \\(Y\\vert X\\) that requires the conditional mean \\(\\mathbb E(Y\\vert X)\\) to be a linear function of \\(X\\). In its most parsimonious form, this is just:\n\\[\nY = X \\beta + \\varepsilon, \\quad \\mathbb E(\\varepsilon\\vert X) = 0.\n\\tag{4}\\]\nThat said, depending on context, Equation 4 is usually supplemented with additional assumptions that further characterise the conditional distribution of the error term1, typically (with increasing strength of assumptions):\n\nConstant Variance. \\(\\mathbb V(\\varepsilon \\vert X) = \\sigma ^2\\), independently of \\(X\\).\n\\(X\\)-Independent Errors. \\(\\varepsilon \\perp X\\).\nNormal Errors. \\(\\varepsilon \\vert X \\sim \\mathcal N (0,\\sigma ^2)\\).\n\nWhile the OLS estimator is well-defined irrespective of the validity of any of these models, it is clear that, in order for \\(\\hat \\beta\\) to represent a meaningful summary of the \\(Y\\)-\\(X\\) dependence, one should require at least Equation 4 to hold in some approximate sense. Correspondingly, while some general features of \\(\\hat \\beta\\) can be discussed independently of linear model assumptions, its most important properties crucially depend on Equation 4."
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html#the-linear-model",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html#the-linear-model",
    "title": "Ordinary Least Squares",
    "section": "",
    "text": "The term generally refers to a model for the conditional distribution of \\(Y\\vert X\\) that requires the conditional mean \\(\\mathbb E(Y\\vert X)\\) to be a linear function of \\(X\\). In its most parsimonious form, this is just:\n\\[\nY = X \\beta + \\varepsilon, \\quad \\mathbb E(\\varepsilon\\vert X) = 0.\n\\tag{4}\\]\nThat said, depending on context, Equation 4 is usually supplemented with additional assumptions that further characterise the conditional distribution of the error term1, typically (with increasing strength of assumptions):\n\nConstant Variance. \\(\\mathbb V(\\varepsilon \\vert X) = \\sigma ^2\\), independently of \\(X\\).\n\\(X\\)-Independent Errors. \\(\\varepsilon \\perp X\\).\nNormal Errors. \\(\\varepsilon \\vert X \\sim \\mathcal N (0,\\sigma ^2)\\).\n\nWhile the OLS estimator is well-defined irrespective of the validity of any of these models, it is clear that, in order for \\(\\hat \\beta\\) to represent a meaningful summary of the \\(Y\\)-\\(X\\) dependence, one should require at least Equation 4 to hold in some approximate sense. Correspondingly, while some general features of \\(\\hat \\beta\\) can be discussed independently of linear model assumptions, its most important properties crucially depend on Equation 4."
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html#algebraic-properties-of-blp-and-ols-estimates",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html#algebraic-properties-of-blp-and-ols-estimates",
    "title": "Ordinary Least Squares",
    "section": "Algebraic properties of BLP and OLS estimates",
    "text": "Algebraic properties of BLP and OLS estimates\nConsider the BLP \\(f^*(X) = X\\beta\\), with \\(\\beta\\) defined as in Equation 1. We usually assume that the covariate vector \\(X\\) contains an intercept term, that is\n\\[\nX=\\begin{pmatrix}1 & Z\\end{pmatrix},\\quad Z\\in \\mathbb R^{p-1}\n\\tag{5}\\]\nfor some \\(p-1\\) dimensional random vector \\(Z\\). The presence of an intercept term leads to \\(f^*(X)\\) having a bunch of nice properties, such as being unconditionally unbiased (\\(\\mathbb E(Y-f^*(X))=0\\)), as we show below.\nLet us decompose \\(\\beta = \\begin{pmatrix}a & b\\end{pmatrix}\\), where \\(a\\in \\mathbb R\\) is the intercept term, and \\(b \\in \\mathbb R^{p-1}\\) is the coefficient of \\(Z\\). We can easily prove that:\n\\[\n\\begin{split}\nb  &=\n\\mathbb V (Z)^{-1}\\mathbb V(Z,Y),\\\\\na  &= \\mathbb E(Y)-\\mathbb E(Z)b,\n\\end{split}\n\\tag{6}\\]\nwhere we denote by \\(\\mathbb V (A,B)\\) the covariance matrix of \\(A\\) and \\(B\\), and by \\(\\mathbb V (A)\\equiv \\mathbb V (A,A)\\). These expressions can be used to recast the error term as:\n\\[\nY-X\\beta = (Y-\\mathbb E(Y))-(Z-\\mathbb E(Z))\\mathbb V (Z)^{-1}\\mathbb V(Z,Y).\n\\tag{7}\\]\nFrom this expression we can easily find the first two moments:\n\\[\n\\begin{split}\n\\mathbb E(Y-X\\beta)&=0,\\\\\n\\mathbb E((Y-X\\beta)^2)&=\\mathbb V(Y)-\\mathbb V(Z,Y)^T\\mathbb V(Z)^{-1}\\mathbb V(Z,Y),\n\\end{split}\n\\tag{8}\\]\nIn particular, as anticipated the best linear predictor is unconditionally unbiased. More generally, from Equation 7 it follows one has:\n\\[\n\\mathbb E(X^T(Y-X\\beta))=0\n\\tag{9}\\] which, since \\(\\mathbb E(Y-X\\beta) = 0\\), can also be interpreted as saying that the error term \\(Y-X\\beta\\) and the covariate vector \\(X\\) are uncorrelated.\nThese properties directly translate to corresponding properties of the empirical residuals \\(\\mathbf Y-\\mathbf X\\hat \\beta\\). Notice that, up to now no result depends on the particular probability measure to which expectations refer to. In particular, we can choose this measure to be the empirical distribution realized in a specific sample, which amounts to replace all expectations with sample means. Thus, Equation 9 translates to:\n\\[\n\\frac{1}{N}\\mathbf X^T(\\mathbf Y-\\mathbf X\\hat \\beta)=0,\n\\tag{10}\\]\nwhich implies in particular that sample residuals have vanishing sample means."
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html#distribution-of-coefficient-estimates-hat-beta",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html#distribution-of-coefficient-estimates-hat-beta",
    "title": "Ordinary Least Squares",
    "section": "Distribution of coefficient estimates \\(\\hat \\beta\\)",
    "text": "Distribution of coefficient estimates \\(\\hat \\beta\\)\nAs an estimator of \\(\\beta\\) as defined in Equation 1, the OLS estimator \\(\\hat \\beta\\) is consistent (converges in probability to \\(\\beta\\)) but generally biased (an example is provided here). However, due to the plugin nature of \\(\\hat \\beta\\), the bias is generally of order \\(\\mathcal O (N^{-1})\\), which makes it often negligible in comparison to its \\(\\mathcal O(N^{-1/2})\\) sampling variability (see below).\nExplicitly, the bias is given by:\n\\[\n\\mathbb E(\\hat \\beta) - \\beta = \\mathbb E\\lbrace((\\mathbf X ^T \\mathbf X) ^{-1}-\\mathbb E[(\\mathbf X ^T \\mathbf X) ^{-1}])\\cdot \\mathbf X ^T f (\\mathbf X)\\rbrace,\n\\tag{11}\\]\nwhere \\(f(X) \\equiv \\mathbb E(Y \\vert X)\\) is the true conditional mean function. In general, this vanishes only if \\(f(X)=X\\beta\\), as in the linear expectation model Equation 4.\nThe \\(\\mathbf X\\)-conditional variance of \\(\\hat \\beta\\) can be derived directly from Equation 2:\n\\[\n\\mathbb V (\\hat \\beta \\vert \\mathbf X)=(\\mathbf X ^T \\mathbf X) ^{-1} \\mathbf X ^T  \\mathbb V (\\mathbf Y\\vert \\mathbf X) \\mathbf X (\\mathbf X ^T \\mathbf X),\n\\tag{12}\\]\nwhere \\(\\mathbb V (\\mathbf Y\\vert \\mathbf X)\\) is diagonal for i.i.d. observations. For homoskedastic errors we get:\n\\[\n\\mathbb V (\\hat \\beta \\vert \\mathbf X)=(\\mathbf X ^T \\mathbf X) ^{-1} \\sigma ^2 \\quad (\\mathbb V(Y\\vert X)=\\sigma ^2).\n\\tag{13}\\]\nUnder the normal linear model, this allows to obtain finite-sample correct confidence sets for \\(\\beta\\). In the general case, confidence sets can be derived from the Central Limit Theorem satisfied by \\(\\hat \\beta\\) (Buja et al. 2019):\n\\[\n\\sqrt N (\\hat \\beta -\\beta) \\to \\mathcal N (0,V )\n\\tag{14}\\]\nwhere the asymptotic variance is given by:\n\\[\nV = \\mathbb E[X^TX] ^{-1} \\cdot \\mathbb E[X^T(Y-X\\beta)^2X] \\cdot \\mathbb E[X^TX] ^{-1}.\n\\tag{15}\\]\nThe plugin estimate of Equation 15 leads to the so called Sandwich variance estimator:\n\\[\nV_\\text{sand} \\equiv  (\\mathbf X^T \\mathbf X)^{-1} \\mathbf X^T D_\\mathbf {r^2}\\mathbf X (\\mathbf X^T \\mathbf X)^{-1},\n\\tag{16}\\]\nwhere \\(D_{\\mathbf r^2}\\) is the diagonal matrix whose \\(i\\)-th entry is the squared residual \\(r_i ^2 = (Y_i-X_i\\beta)^2\\)."
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html#variance-estimates",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html#variance-estimates",
    "title": "Ordinary Least Squares",
    "section": "Variance estimates",
    "text": "Variance estimates\nThese can be based on:\n\\[\ns ^2 = \\frac{1}{N}(\\mathbf Y-\\mathbf X \\hat \\beta)^T(\\mathbf Y-\\mathbf X \\hat \\beta)\n\\] which has expectation\n\\[\n\\mathbb E\\left[s^2\\right]=\\frac{1}{N}\\text {Tr}\\,\\mathbb E \\left[ (1-\\mathbf H) \\cdot \\left(\\mathbb E(\\mathbf Y \\vert \\mathbf X)\\mathbb E(\\mathbf Y \\vert \\mathbf X)^T + \\mathbb V(\\mathbf Y\\vert\\mathbf X)\\right) \\right]\n\\tag{17}\\]\nwhere the hat matrix \\(\\mathbf H\\) is defined as usual:\n\\[\n\\mathbf H \\equiv \\mathbf X(\\mathbf X^T\\mathbf X)^{-1}\\mathbf X^T\n\\tag{18}\\]\nIf the general linear model Equation 4 holds, so that \\(E(\\mathbf Y \\vert \\mathbf X) = \\mathbf X \\beta\\), we have \\((1-\\mathbf H) \\mathbb E(\\mathbf Y \\vert \\mathbf X) = 0\\). If we furthermore assume homoskedasticity, we obtain:\n\\[\n\\mathbb E\\left[s^2\\right]=\\frac{N-p}{N}\\sigma^2 \\quad(\\text{Homoskedastic linear model}), {#eq-variance-estimate-homo}\n\\]\nwhere \\(p = \\text {Tr}(\\mathbf H)\\) is the number of independent covariates. On the other hand, if homoskedasticity holds, but \\(E(\\mathbf Y \\vert \\mathbf X)\\) is not linear, the left-hand side of the previous equation is an overestimate of \\(\\mathbf V \\vert X\\)."
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html#proof-of-central-limit-theorem-for-hat-beta",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html#proof-of-central-limit-theorem-for-hat-beta",
    "title": "Ordinary Least Squares",
    "section": "Proof of Central Limit Theorem for \\(\\hat \\beta\\)",
    "text": "Proof of Central Limit Theorem for \\(\\hat \\beta\\)\nConvergence to the normal distribution Equation 14 with variance Equation 15 can be proved using the formalism of influence functions. From Equation 1, we see that a small variation \\(P\\to P+\\delta P\\) to the joint \\(XY\\) probability measure induces a first order shift:\n\\[\n\\delta \\beta =  \\intop \\mathbb E(X^TX)^{-1}X^T (Y-\\beta X) \\text d(\\delta P)\n\\tag{22}\\]\nin the best linear predictor. The influence function of \\(\\beta\\) is defined by the measurable representation of \\(\\delta \\beta\\), namely:\n\\[\n\\phi _\\beta = \\mathbb E(X^TX)^{-1}X^T (Y-\\beta X).\n\\tag{23}\\]\nA general result for plugin estimates then tells us that \\(\\sqrt N (\\hat \\beta -\\beta) \\to \\mathcal N (0, \\mathbb E (\\phi _\\beta ^2))\\) in distribution, and using the explicit form of Equation 23 we readily obtain Equation 15."
  },
  {
    "objectID": "notebooks/ordinary-least-squares/ordinary-least-squares.html#footnotes",
    "href": "notebooks/ordinary-least-squares/ordinary-least-squares.html#footnotes",
    "title": "Ordinary Least Squares",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI use the notation \\(A\\perp B\\) to indicate that the random variables \\(A\\) and \\(B\\) are statistically independent.↩︎"
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html",
    "title": "Exponential Dispersion Models",
    "section": "",
    "text": "Exponential Dispersion Models (EDMs) provide a natural generalization of the normal distribution, in which the modeled variable \\(Y\\) is assumed to follow a probability density:\n\\[\n\\text d P _{\\lambda,\\,\\mu}(y)=e^{-\\frac{\\lambda}{2}d(y,\\,\\mu)}\\text d \\nu _{\\lambda}(y)\n\\]\nwith respect to a certain dominating measure \\(\\nu _{\\lambda}\\). Here \\(\\mu = \\intop y\\,\\text d P_{\\lambda,\\,\\mu}(y)\\) and \\(d(y,\\,\\mu) \\geq 0\\), with equality only for \\(y = \\mu\\). The function \\(d(y,\\,\\mu)\\) is called the unit deviance, and plays for EDMs the same role of squared distance \\((y-\\mu)^2\\) for the normal model. Not surprisingly, EDMs provide a sound framework for the maximum-likelihood based formulation of generalized linear models, additive models, and similar beasts."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#intro",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#intro",
    "title": "Exponential Dispersion Models",
    "section": "",
    "text": "Exponential Dispersion Models (EDMs) provide a natural generalization of the normal distribution, in which the modeled variable \\(Y\\) is assumed to follow a probability density:\n\\[\n\\text d P _{\\lambda,\\,\\mu}(y)=e^{-\\frac{\\lambda}{2}d(y,\\,\\mu)}\\text d \\nu _{\\lambda}(y)\n\\]\nwith respect to a certain dominating measure \\(\\nu _{\\lambda}\\). Here \\(\\mu = \\intop y\\,\\text d P_{\\lambda,\\,\\mu}(y)\\) and \\(d(y,\\,\\mu) \\geq 0\\), with equality only for \\(y = \\mu\\). The function \\(d(y,\\,\\mu)\\) is called the unit deviance, and plays for EDMs the same role of squared distance \\((y-\\mu)^2\\) for the normal model. Not surprisingly, EDMs provide a sound framework for the maximum-likelihood based formulation of generalized linear models, additive models, and similar beasts."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#exponential-dispersion-models",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#exponential-dispersion-models",
    "title": "Exponential Dispersion Models",
    "section": "Exponential Dispersion Models",
    "text": "Exponential Dispersion Models\nWe start with a probability measure on \\(\\mathbb R ^n\\) in the form of an additive EDM:\n\\[\n\\text d P ^* _{\\lambda, \\theta} (z) = e^{\\theta ^T z-\\lambda\\kappa(\\theta)}\\text dQ^*_\\lambda (z)\n\\tag{1}\\]\nwhere \\(\\lambda &gt; 0\\), \\(\\text Q^*_\\lambda\\) is a Borelian probability measure on \\(\\mathbb R\\), and \\(\\kappa(\\theta)\\) is a differentiable strictly convex function, with \\(\\kappa''(\\theta) &gt; 0\\) and \\(\\kappa(0) =0\\). For a random variable \\(Z\\) distributed according to Equation 3 we write \\(Z\\sim \\text{ED}^*(\\lambda, \\,\\theta,\\,\\kappa)\\).\nFor any given \\(\\lambda\\), normalization of Equation 1 requires:\n\\[\ne^{\\lambda \\kappa(\\theta)}=\\intop e^{\\theta ^Ty}\\text dQ^*_\\lambda(z)\n\\tag{2}\\]\nto hold for all \\(\\theta\\) and \\(\\lambda\\). In other words, \\(M_\\lambda(\\theta) \\equiv e^{\\lambda \\kappa(\\theta)}\\) must be the moment generating function of the measure \\(Q^* _\\lambda(y)\\) for a given \\(\\theta\\), which we assume to be uniquely determined by its moments1, so that we can omit the mention of the measure \\(Q^*_\\lambda\\) in the notation \\(\\text{ED}^*(\\lambda, \\,\\theta,\\,\\kappa)\\)^. This requires, in particular \\(\\kappa (0) = 0\\).\nA closely related parametrization is the so-called reproductive EDM:\n\\[\n\\text d P _{\\lambda, \\theta} (y) = e^{\\lambda(\\theta ^T y-\\kappa(\\theta))}\\text dQ_\\lambda (y)\n\\tag{3}\\]\nFor a random variable \\(Y\\) distributed according to Equation 3 we write \\(Y\\sim \\text{ED}(\\lambda, \\,\\theta,\\,\\kappa)\\). The link between Equation 3 and Equation 1 is that \\(Y\\sim \\text{ED}(\\lambda, \\,\\theta,\\,\\kappa)\\) if and only if \\(Z=\\lambda Y\\sim \\text{ED}^*(\\lambda, \\,\\theta,\\,\\kappa)\\), so that reproductive and additive EDMs can be interchanged whenever convenient, at least for theoretical considerations. The probability measures \\(\\text d Q_\\lambda\\) and \\(\\text d Q ^*_\\lambda\\), which are uniquely determined by normalization, are related by push-forward:\n\\[\nQ_\\lambda ^* = (m_\\lambda )_*(Q_\\lambda),\n\\tag{4}\\]\nwhere \\(m_\\lambda\\) denotes multiplication by \\(\\lambda\\), i.e. \\(m_\\lambda(y)=\\lambda y\\).\nIn cases of practical interest (see the examples below), \\(Q_\\lambda\\) and \\(Q_\\lambda^*\\) are absolutely continuous either with respect to the Lebesgue measure, or with respect some measure concentrated on \\(c \\cdot \\mathbb N\\) for some \\(c&gt;0\\). The two cases are referred to as the “continuous” and “discrete” case, respectively, for obvious reasons."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#general-properties",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#general-properties",
    "title": "Exponential Dispersion Models",
    "section": "General Properties",
    "text": "General Properties\n\nMoment generating function\nConsider first the reproductive EDM Equation 3. If \\(Y\\sim \\text {ED}(\\lambda,\\,\\theta,\\,\\kappa)\\), its moment generating function is:\n\\[\nM_Y(s)=\\mathbb E(e^{sY})=\\exp\\left[\\lambda\\left(\\kappa(\\theta +\\frac{s}{\\lambda})-\\kappa(\\theta)\\right)\\right],\n\\tag{5}\\]\nfrom which we can derive, in particular:\n\\[\n\\begin{split}\n\\mathbb E(Y) &= \\frac{\\text d}{\\text ds}\\vert_{s=0}\\log M(s) =\\kappa'(\\theta),\\\\\n\\mathbb V(Y) &= \\frac{\\text d^2}{\\text ds ^2}\\vert_{s=0}\\log M(s) =\\frac{\\kappa''(\\theta)}{\\lambda}.\\\\\n\\end{split}\n\\tag{6}\\]\nFor the additive EDM Equation 1, the corresponding results for \\(Z\\sim \\text{ED}^*(\\lambda,\\,\\theta,\\,\\kappa)\\) are:\n\\[\n\\begin{split}\nM_Z(s)&=\\exp\\left[\\lambda\\left(\\kappa(\\theta + s)-\\kappa(\\theta)\\right)\\right],\\\\\n\\mathbb E(Z) &= \\lambda\\kappa'(\\theta),\\\\\n\\mathbb V(Z) &= \\lambda \\kappa''(\\theta).\n\\end{split}\n\\tag{7}\\]\n\n\nLegendre Transform of \\(\\kappa (\\theta)\\)\nSince \\(\\kappa\\) is strictly convex, the mapping:\n\\[\n\\mu = \\frac{\\partial\\kappa}{\\partial\\theta}\n\\tag{8}\\]\nis invertible, and we may equivalently parametrize the reproductive EDM in terms of \\(\\mu\\) and \\(\\lambda\\) as follows:\n\\[\n\\text d P _{\\lambda, \\mu} (y) = e^{\\lambda(\\theta(\\mu) ^T (y-\\mu)+\\tau(\\mu))}\\text dQ_\\lambda (y).\n\\tag{9}\\]\nwhere:\n\\[\n\\tau(\\mu) = \\theta(\\mu)^T\\mu - \\kappa(\\theta(\\mu)).\n\\tag{10}\\]\nis the Legendre transform of \\(\\kappa\\)."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#deviance",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#deviance",
    "title": "Exponential Dispersion Models",
    "section": "Deviance",
    "text": "Deviance\nConsider two reproductive EDMs \\(P _{\\lambda,\\mu _1}\\) and \\(P _{\\lambda,\\mu _2}\\) with the same dispersion parameter \\(\\lambda\\) (the function \\(\\kappa\\) is assumed to be fixed throughout). The likelihood ratio at a given \\(Y=y\\) is:\n\\[\n\\ln (\\frac{\\text d P_{\\lambda,\\mu_1}}{\\text d P_{\\lambda,\\mu_2}}(y))=\\lambda\\cdot\\left[(\\theta_1-\\theta_2)y-(\\kappa_1-\\kappa_2)\\right],\n\\tag{11}\\]\nwhere \\(\\theta _1 = \\theta(\\mu_1)\\), \\(\\kappa_1= \\kappa(\\theta(\\mu _1))\\), etc.. Setting \\(\\mu _1 = y\\) and \\(\\mu _2 = \\mu\\) in this expression and multiplying by a convenient factor, we obtain the so called unit scaled deviance:\n\\[\n\\begin{split}\nd_\\lambda(y,\\mu) &\\equiv 2\\left.\\ln (\\frac{\\text d P_{\\lambda,\\mu_0}}{\\text d P_{\\lambda,\\mu}}(y)) \\right \\vert _{\\mu_0=y}\\\\&=2\\lambda\\cdot\\left[(\\theta(y)-\\theta(\\mu))y-\\kappa(\\theta(y))+\\kappa(\\theta(\\mu))\\right].\n\\end{split}\n\\tag{12}\\]\nThe unit deviance is defined as:\n\\[\n\\begin{split}\nd(y,\\mu) &\\equiv d_1(y,\\mu)\\\\&=2\\cdot\\left[(\\theta(y)-\\theta(\\mu))y-\\kappa(\\theta(y))+\\kappa(\\theta(\\mu))\\right]\n\\end{split}\n\\tag{13}\\]\nIt is also useful to express \\(d_\\lambda\\) in terms of the Legendre transform \\(\\tau\\) of \\(\\kappa\\), as defined in Equation 10:\n\\[\nd_\\lambda(y,\\mu) =2\\lambda\\cdot\\left[-\\theta(\\mu)^T(y-\\mu)+\\tau(y)-\\tau(\\mu)\\right]\n\\tag{14}\\]\nUsing the convexity of \\(\\kappa\\), it is easy to show that \\(d_\\lambda(y,\\mu) \\geq 0\\) for all \\(y\\) and \\(\\mu\\), and that \\(d_\\lambda(y,\\mu) = 0\\) requires \\(\\mu = y\\). The probability measure can be expressed in terms of the unit deviance as:\n\\[\n\\text d P _{\\lambda, \\mu} (y) = e^{-\\frac{\\lambda}{2}d(y,\\,\\mu)}e^{\\lambda \\tau(y)}\\text dQ_\\lambda (y).\n\\tag{15}\\]"
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#maximum-likelihood-estimation",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#maximum-likelihood-estimation",
    "title": "Exponential Dispersion Models",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\nLet \\(Y_i\\sim \\text{ED}(\\lambda,\\,\\mu^{(0)}_ i ,\\,\\kappa)\\) be independent for \\(i=1,\\,2,\\,\\dots,\\,N\\) and let \\(M\\subseteq \\mathbb R ^N\\) be a family of models for the mean \\(\\boldsymbol \\mu ^{(0)} = (\\mu _1^{(0)},\\,\\mu_2^{(0)},\\dots,\\,\\mu_N^{(0)})^T\\) (in a GLM context, \\(M\\) would be the linear subspace spanned by the covariates, \\(\\boldsymbol \\mu _\\beta = \\mathbf X \\beta\\)). From Equation 15, we see that the likelihood of a model \\(\\boldsymbol \\mu \\in M\\) is, modulo a \\(\\boldsymbol \\mu\\)-independent term, equal to its total deviance:\n\\[\n\\log \\mathcal L (\\boldsymbol \\mu,\\,\\lambda;\\mathbf Y) = -\\frac{\\lambda}{2}\\mathcal D(\\mathbf Y,\\boldsymbol \\mu)+g_\\lambda(\\mathbf Y),\n\\tag{16}\\] with:\n\\[\n\\mathcal D (\\mathbf Y,\\boldsymbol \\mu)\\equiv\\sum_{i=1}^Nd(Y_i,\\mu_i)\n\\tag{17}\\]\nHence, the Maximum Likelihood Estimate (MLE) of \\(\\boldsymbol \\mu\\) corresponds to the minimum deviance estimate:\n\\[\n\\hat {\\boldsymbol \\mu}\\equiv \\arg \\max _{\\boldsymbol \\mu \\in M} \\mathcal L (\\boldsymbol \\mu,\\,\\lambda;\\,\\mathbf Y)=\\arg \\min _{\\boldsymbol \\mu \\in M} \\mathcal D (\\mathbf Y;\\boldsymbol \\mu).\n\\tag{18}\\]\nIn particular, the MLE \\(\\hat {\\boldsymbol \\mu}\\) is obtained by minimizing a function of \\(\\boldsymbol \\mu\\) only, and is independent on whether the dispersion parameter \\(\\lambda\\) is being estimated itself or not.\nThese results are sometimes formulated in terms of a “saturated” model \\(\\boldsymbol \\mu _\\text{s} = \\mathbf Y\\). From Equation 16 we see that such a model has likelihood equal to \\(g_{\\lambda}(\\boldsymbol \\mu)\\), implying that:\n\\[\n\\lambda\\mathcal D(\\mathbf Y,\\boldsymbol \\mu) = -2\\log \\left(\\frac{\\mathcal L (\\boldsymbol \\mu,\\lambda;\\mathbf Y)}{\\mathcal L (\\mathbf Y,\\lambda;\\mathbf Y)}\\right)\n\\] {#eq-deviance-log-lik}.\nWe note the asymptotic results (B. Jørgensen 1992, sec. 3.6):\n\\[\n\\lambda \\mathcal D(\\mathbf Y,\\,\\hat {\\boldsymbol \\mu})\\overset{d}{\\to}  \\chi ^2 _{N-p} \\qquad (\\lambda \\to \\infty),\\\\\n\\tag{19}\\]\nfor a correctly specified model family \\(M\\) with \\(\\dim (M) = p\\), and:\n\\[\n\\lambda \\mathcal D(\\mathbf Y,\\,\\hat {\\boldsymbol \\mu}_1)-\\lambda D(\\mathbf Y,\\,\\hat {\\boldsymbol \\mu}_2)\\overset{d}{\\to} \\chi ^2 _{p_2-p_1} \\qquad (\\lambda \\to \\infty \\text { or } N\\to \\infty),\n\\tag{20}\\]\nfor a correctly specified model family \\(M_1\\) and \\(M_2 \\supseteq M_1\\), with \\(p_i =\\dim (M_i)\\). Equation 19 can be seen as the limiting case of Equation 20 when \\(M_2 = \\mathbb R ^N\\), as in the saturated model. The manifolds \\(M\\) and \\(M_i\\) are not strictly required to be linear subspaces of \\(\\mathbb R^N\\), because in the limits and under the null hypotheses implied by Eqs. Equation 19 and Equation 20 the distributions of MLEs are concentrated around the true value \\(\\boldsymbol \\mu ^{(0)}\\), so that the manifolds \\(M\\) and \\(M_i\\) can be effectivley approximated by their tangent spaces.\nNoteworthy, limit Equation 19 holds in the small dispersion limit \\(\\lambda \\to \\infty\\) only, whereas limit Equation 20 is also valid in the large sample limit, essentially due to Wilks’ theorem."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#examples-of-edms",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#examples-of-edms",
    "title": "Exponential Dispersion Models",
    "section": "Examples of EDMs",
    "text": "Examples of EDMs\n\nUnivariate Gaussian\nThe univariate gaussian family \\(N (\\mu, \\sigma^2)\\), with probability density function (PDF):\n\\[\nf_{\\mu,\\sigma}(y)=\\frac{1}{\\sqrt {2 \\pi \\sigma ^2}}\\exp\\left[-\\frac{(y-\\mu)^2}{2\\sigma ^2}\\right]\n\\tag{21}\\]\ncorresponds to the reproductive EDM \\(\\text{ED}(\\lambda, \\,\\theta,\\,\\kappa)\\) with:\n\\[\n\\kappa (\\theta) = \\frac{\\theta ^2}{2},\\quad \\theta \\in \\mathbb R,\\quad \\lambda \\in \\mathbb R^+.\n\\tag{22}\\]\nThe correspondence is given by:\n\\[\n\\theta = \\mu,\\quad \\lambda = \\frac{1}{\\sigma^2}.\n\\tag{23}\\]\nThe base probability measure is given by:\n\\[\n\\text d Q_\\lambda (y)=\\sqrt{\\frac \\lambda {2\\pi}}e^{-\\lambda y^2/2} \\text dy\n\\tag{24}\\]\nThe Legendre transform of \\(\\kappa\\) is:\n\\[\n\\tau(\\mu) = \\frac{\\mu ^2}{2}\n\\tag{25}\\]\nand the unit deviance reads:\n\\[\nd(y, \\hat \\mu) =(y-\\hat \\mu)^2.\n\\tag{26}\\]\n\n\nBinomial\nThe binomial family \\(\\mathcal B(p,N)\\) with probability mass function (PMF):\n\\[\nf_{p,N}(z) = \\binom{N}{z} p^z(1-p)^{N-z}\n\\tag{27}\\]\ncorresponds to the additive EDM \\(\\text{ED}^*(\\lambda, \\,\\theta;\\,\\kappa)\\) with:\n\\[\n\\kappa(\\theta) = \\ln (\\dfrac{1+e^\\theta}{2}),\\quad \\theta\\in \\mathbb R ,\\quad \\lambda \\in \\mathbb N.\n\\tag{28}\\]\nThe correspondence is given by:\n\\[\n\\theta = \\ln\\frac{p}{1-p},\\quad\\lambda =N.\n\\tag{29}\\]\nThe base probability measure reads:\n\\[\n\\frac{\\text d Q_\\lambda^*(z)}{\\text d z} =2^{-\\lambda}\\sum_{i=0} ^\\lambda \\binom{\\lambda}{i} \\delta (z-i).\n\\tag{30}\\]\nThe Legendre transform of \\(\\kappa\\) (using \\(p\\) for the mean parameter) is:\n\\[\n\\tau(p)= \\ln2+p\\ln p+(1-p)\\ln(1-p)\n\\tag{31}\\]\nand the unit deviance for the reproductive EDM:\n\\[\nd(y,\\hat p)=-2y\\ln (\\dfrac{\\hat p}{y})-2(1-y)\\ln (\\dfrac{1-\\hat p}{1-y}).\n\\tag{32}\\]\nFor the additive EDM, appropriate to an integer valued binomial variable, this is given by:\n\\[\nd(z,\\hat p)=-2\\frac{z}{N}\\ln (\\dfrac{N\\hat p}{z})-2(1-\\frac{z}{N})\\ln (\\dfrac{N-N\\hat p}{N-z}).\n\\tag{33}\\]\n\n\nMultinomial\nThe multinomial family \\(\\text{Mult} _{K+1}(p_1,\\,p_2,\\dots ,p_{K+1},\\,N)\\) for \\(K+1\\) categories is given by the PMF:\n\\[\nf_{\\boldsymbol p ,N}(z) = \\binom{N}{z_1,\\,z_2,\\,\\dots,\\,z_{K+1}}\\prod _{k=1}^{K+1}p_k^{z_k},\n\\tag{34}\\]\nIn order to identify this with an EDM, we use the constraints \\(\\sum _{i=1}^{M+1}z_i =1\\) and \\(\\sum _{i=1}^{M+1}p_i =1\\) to eliminate one dependent variable and parameter, say \\(z_{M+1}\\) and \\(p_{M+1}\\), respectively. The family of densities for the resulting \\(M\\)-dimensional vector \\(\\boldsymbol z=(z_1\\,z_2\\,\\dots\\,z_M)^T\\) corresponds to the additive EDM \\(\\text{ED}^*(\\lambda, \\,\\theta;\\,\\kappa)\\) with:\n\\[\n\\quad \\kappa(\\theta) = \\ln(\\dfrac{1+\\sum_{i=1}^K e^{\\theta _k}}{K+1}), \\quad \\theta \\in \\mathbb R^K,\\quad \\lambda \\in \\mathbb N,\n\\tag{35}\\]\nthe correspondence being given by:\n\\[\n\\theta _i = \\ln \\frac{p_i}{p_{K+1}},\\quad \\lambda = N.\n\\tag{36}\\]\nThe base measure:\n\\[\n\\frac{\\text d Q_\\lambda^*(z)}{\\text d \\boldsymbol z} =(K+1)^{-\\lambda}\\sum_{\\boldsymbol i\\in \\mathbb N ^{K}\\,\\colon \\,\\sum _{k=1}^{K}i_k\\leq\\lambda} \\binom{\\lambda}{i_1,\\,i_2,\\dots,i_{K+1}} \\delta (\\boldsymbol z-\\boldsymbol i),\n\\tag{37}\\]\nwhere \\(i_{K+1} = N - \\sum _{k=1} ^{K} i_k\\). The Legendre transform of \\(\\kappa\\) is:\n\\[\n\\tau(\\boldsymbol p)= \\ln (K+1)+\\sum _{k=1}^{K+1}p_k\\ln p_k\n\\tag{38}\\]\nand the deviance is:\n\\[\nd(y,\\hat {\\boldsymbol p}) = -2\\sum _{k=1}^{K+1}y_k\\ln (\\frac{\\hat p_k}{y_k}).\n\\tag{39}\\]\nFor the additive EDM, appropriate to an integer valued multinomial variable, this is given by:\n\\[\nd(z,\\hat p)=-2\\sum _{k=1}^{K+1}\\frac{z_k}{N}\\ln (\\dfrac{N\\hat p}{z_k}).\n\\tag{40}\\]\n\n\nPoisson\nThe Poisson PMF is:\n\\[\nf(y) = \\frac {\\nu ^z} {z!} e^{-\\nu}\n\\tag{41}\\]\nThis can be interpreted as coming from an additive EDM with:\n\\[\n\\kappa(\\theta)=e^\\theta-1,\\quad \\theta \\in \\mathbb R,\\quad \\lambda \\in \\mathbb R^+.\n\\tag{42}\\]\nHowever, the correspondence is not unique, being given by the single relation:\n\\[\n\\lambda e^\\theta = \\nu\n\\tag{43}\\]\nwhich describes a curve in the \\(\\Theta \\times \\Lambda\\) space. The corresponding base measure is:\n\\[\n\\dfrac{\\text d Q _\\lambda (z)}{\\text d z} = e^{-\\lambda}\\sum _{k=0}^{\\infty}\\frac{\\lambda ^k\\delta(z-k)}{k!}\n\\tag{44}\\]\nwhich is nothing but the Poisson measure itself."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#references",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#references",
    "title": "Exponential Dispersion Models",
    "section": "References",
    "text": "References\nI have mostly followed (Bent Jørgensen 1987). References (B. Jørgensen 1992) (Jorgensen 1997) from the same author provide more extensive expositions. A good reference for GLMs is (McCullagh 2019)."
  },
  {
    "objectID": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#footnotes",
    "href": "notebooks/exponential-dispersion-models/exponential-dispersion-models.html#footnotes",
    "title": "Exponential Dispersion Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhether a set of moments determines a unique probability measure is called the Hamburger moment problem.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Valerio Gherardi’s Personal Website",
    "section": "",
    "text": "Exponential of a 2x2 real matrix\n\n\n\n\n\n\nMathematics\n\n\n\nExplicit formulae \n\n\n\n\n\nNov 4, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nDutch book arguments\n\n\n\n\n\n\nBayesian Methods\n\n\nStatistics\n\n\n\nReviewing the classical “Dutch book” derivations of the probability axioms in the subjectivist interpretation of probability. \n\n\n\n\n\nAug 12, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nThe UV diagram for a pure substance\n\n\n\n\n\n\nThermodynamics\n\n\nPhysics\n\n\n\nDescribing a pure substance at a phase transition in terms of internal energy and volume removes all degeneracies. \n\n\n\n\n\nJul 1, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\n“The Physics and Mathematics of the Second Law of Thermodynamics” by E.H. Lieb and J. Yngvason\n\n\n\n\n\n\nComment on…\n\n\nThermodynamics\n\n\nPhysics\n\n\n\nA seminal article with enlightening views on the logical structure of Thermodynamics. \n\n\n\n\n\nJun 25, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\n“Data Fission: Splitting a Single Data Point” by Leiner et al.\n\n\n\n\n\n\nComment on…\n\n\nSelective Inference\n\n\nModel Selection\n\n\nStatistics\n\n\n\nAn interesting idea for dealing with selective inference. \n\n\n\n\n\nJun 3, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nStatements of the Second Law of Thermodynamics\n\n\n\n\n\n\nThermodynamics\n\n\nPhysics\n\n\n\nClose-up on the equivalence between Kelvin’s/Clausius’ postulates and Clausius’ theorem. \n\n\n\n\n\nJun 1, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nAuthorship Attribution in Lennon-McCartney Songs\n\n\n\n\n\n\nComment on…\n\n\nAuthorship Verification\n\n\nNatural Language Processing\n\n\nMachine Learning\n\n\nMusic\n\n\nStatistics\n\n\n\nAn open access paper by M. Glickman, J. Brown, and R. Song. \n\n\n\n\n\nMay 23, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nFrequentist bounds for Bayesian sequential hypothesis testing\n\n\n\n\n\n\nSequential Hypothesis Testing\n\n\nBayesian Methods\n\n\nFrequentist Methods\n\n\nStatistics\n\n\n\nA general bound on the type I error rate of Bayesian sequential hypothesis testing based on the Bayes factor. \n\n\n\n\n\nMay 22, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nAIC in the well-specified linear model: theory and simulation\n\n\n\n\n\n\nModel Selection\n\n\nLinear Models\n\n\nRegression\n\n\nStatistics\n\n\nR\n\n\n\nSome illustrations of the Akaike Information Criterion (AIC) at work in a toy example. \n\n\n\n\n\nMay 17, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nGrammar as a biometric for Authorship Verification\n\n\n\n\n\n\nAuthorship Verification\n\n\nNatural Language Processing\n\n\nForensic Science\n\n\nMachine Learning\n\n\nStatistics\n\n\nR\n\n\n\nNotes on preprint 2403.08462 by A. Nini, O. Halvani, L. Graner, S. Ishihara and myself. \n\n\n\n\n\nApr 25, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\n“Induction and Deduction in Bayesian Data Analysis” by A. Gelman\n\n\n\n\n\n\nComment on…\n\n\nBayesian Methods\n\n\nStatistics\n\n\n\nOn the importance of model checks in Bayesian data analysis. \n\n\n\n\n\nApr 25, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\n“The Abuse of Power” by J. M. Hoenig and D. M. Heisey\n\n\n\n\n\n\nComment on…\n\n\nHypothesis Testing\n\n\nStatistics\n\n\n\nWhy observed power calculations are useless (plus a few other points I don’t buy). \n\n\n\n\n\nApr 18, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nAIC for the linear model: known vs. unknown variance\n\n\n\n\n\n\nModel Selection\n\n\nLinear Models\n\n\nRegression\n\n\nStatistics\n\n\n\nDoes knowledge of noise variance have any effect on model selection for the mean? \n\n\n\n\n\nMar 13, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\n“A Closer Look at the Deviance” by T. Hastie\n\n\n\n\n\n\nComment on…\n\n\nMaximum Likelihood Estimation\n\n\nLinear Models\n\n\nStatistics\n\n\n\nA nice review of properties of Deviance for one parameter exponential families. \n\n\n\n\n\nMar 7, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nNo binomial overdispersion from variations at the individual level\n\n\n\n\n\n\nPopulation Dynamics\n\n\nBiology\n\n\nEcology\n\n\nStatistics\n\n\n\nSome notes on the causes of overdispersion in count data. \n\n\n\n\n\nMar 6, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nOn the first and second laws of thermodynamics for open systems\n\n\n\n\n\n\nOpen Systems\n\n\nThermodynamics\n\n\nPhysics\n\n\n\nMatter transfer in open systems changes the relationship between heat and entropy, and work and volume. \n\n\n\n\n\nMar 4, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nGravity waves in an ideal fluid\n\n\n\n\n\n\nAtmospheric Physics\n\n\nFluid Dynamics\n\n\nWaves\n\n\nPhysics\n\n\n\nCompares the “parcel” method with standard linearization of fluid dynamics equations. \n\n\n\n\n\nFeb 22, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nBinary digits of uniform random variables\n\n\n\n\n\n\nProbability Theory\n\n\n\n… are independent fair coin tosses. \n\n\n\n\n\nJan 29, 2024\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Likelihood Ratio cost\n\n\n\n\n\n\nForensic Science\n\n\nBayesian Methods\n\n\nInformation Theory\n\n\nProbability Theory\n\n\nR\n\n\n\nAnalysis of infinite sample properties and comparison with cross-entropy loss. \n\n\n\n\n\nNov 15, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nConditional Probability\n\n\n\n\n\n\nProbability Theory\n\n\nMeasure Theory\n\n\n\nNotes on the formal definition of conditional probability. \n\n\n\n\n\nNov 3, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nPrefix-free codes\n\n\n\n\n\n\nInformation Theory\n\n\nEntropy\n\n\nProbability Theory\n\n\n\nGeneralities about prefix-free (a.k.a. instantaneous) codes \n\n\n\n\n\nOct 31, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nAB tests and repeated checks\n\n\n\n\n\n\nAB testing\n\n\nSequential Hypothesis Testing\n\n\nFrequentist Methods\n\n\nStatistics\n\n\nR\n\n\n\nFalse Positive Rates under repeated checks - a simulation study using R. \n\n\n\n\n\nJul 27, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nTesting functional specification in linear regression\n\n\n\n\n\n\nStatistics\n\n\nModel Misspecification\n\n\nRegression\n\n\nLinear Models\n\n\nR\n\n\n\nSome options in R, using the {lmtest} package. \n\n\n\n\n\nJul 11, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nSum and ratio of independent random variables\n\n\n\n\n\n\nMathematics\n\n\nProbability Theory\n\n\n\nSufficient conditions for independence of sum and ratio. \n\n\n\n\n\nJun 14, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nFisher’s Randomization Test\n\n\n\n\n\n\nStatistics\n\n\nFrequentist Methods\n\n\nCausal Inference\n\n\n\nNotes and proofs of basic theorems \n\n\n\n\n\nJun 7, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\np-values and measure theory\n\n\n\n\n\n\nProbability Theory\n\n\nMeasure Theory\n\n\nFrequentist Methods\n\n\nStatistics\n\n\n\nSelf-reassurance that p-value properties don’t depend on regularity assumptions on the test statistic. \n\n\n\n\n\nJun 7, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regression with autocorrelated noise\n\n\n\n\n\n\nStatistics\n\n\nRegression\n\n\nTime Series\n\n\nLinear Models\n\n\nModel Misspecification\n\n\nR\n\n\n\nEffects of noise autocorrelation on linear regression. Explicit formulae and a simple simulation. \n\n\n\n\n\nMay 25, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nModel Misspecification and Linear Sandwiches\n\n\n\n\n\n\nStatistics\n\n\nRegression\n\n\nLinear Models\n\n\nModel Misspecification\n\n\nR\n\n\n\nBeing wrong in the right way. With R excerpts. \n\n\n\n\n\nMay 14, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nConsistency and bias of OLS estimators\n\n\n\n\n\n\nStatistics\n\n\nRegression\n\n\nLinear Models\n\n\nModel Misspecification\n\n\n\nOLS estimators are consistent but generally biased - here’s an example. \n\n\n\n\n\nMay 12, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nBayes, Neyman and the Magic Piggy Bank\n\n\n\n\n\n\nStatistics\n\n\nConfidence Intervals\n\n\nFrequentist Methods\n\n\nBayesian Methods\n\n\n\nCompares frequentist properties of credible intervals and confidence intervals in a gambling game involving a magic piggy bank. \n\n\n\n\n\nMay 1, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelation Without Causation\n\n\n\n\n\n\nStatistics\n\n\n\nCum hoc ergo propter hoc \n\n\n\n\n\nMar 30, 2023\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nHow to get away with selection. Part II: Mathematical Framework\n\n\n\n\n\n\nStatistics\n\n\nSelective Inference\n\n\nModel Misspecification\n\n\n\nMathematicals details on Selective Inference, model misspecification and coverage guarantees. \n\n\n\n\n\nNov 25, 2022\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nHow to get away with selection. Part I: Introduction\n\n\n\n\n\n\nStatistics\n\n\nSelective Inference\n\n\nR\n\n\n\nIntroducing the problem of Selective Inference, illustrated through a simple simulation in R. \n\n\n\n\n\nNov 14, 2022\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\nkgrams v0.1.2 on CRAN\n\n\n\n\n\n\nNatural Language Processing\n\n\nR\n\n\n\nkgrams: Classical k-gram Language Models in R. \n\n\n\n\n\nNov 13, 2021\n\n\nValerio Gherardi\n\n\n\n\n\n\n\n\n\n\n\n\n{r2r} now on CRAN\n\n\n\n\n\n\nData Structures\n\n\nR\n\n\n\nIntroducing {r2r}, an R implementation of hash tables. \n\n\n\n\n\nJul 6, 2021\n\n\nValerio Gherardi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website serves as a repository for my thoughts, things I am studying or working on, and notes I have accumulated across the years. Central topics are Statistics, Mathematics and Physics1."
  },
  {
    "objectID": "about.html#this-website",
    "href": "about.html#this-website",
    "title": "About",
    "section": "",
    "text": "This website serves as a repository for my thoughts, things I am studying or working on, and notes I have accumulated across the years. Central topics are Statistics, Mathematics and Physics1."
  },
  {
    "objectID": "about.html#me",
    "href": "about.html#me",
    "title": "About",
    "section": "Me",
    "text": "Me\nI am Valerio, class 1992, Italian based in València (Spain).\nI am generally passionate about Science, and mathematical sciences in particular. I studied Physics, specializing in Particle Phenomenology, on which I did my PhD. More recently, my interests have been gravitating more around Statistics, both theoretical and applied.\nI worked as data scientist for a few years. Currently, I’m a research technician in the ERAHUMED project carried forward by the Universitat de València.\nIf you want to get in touch with me, you can follow the contact links in the navigation bar above. My CV can be downloaded here."
  },
  {
    "objectID": "about.html#footnotes",
    "href": "about.html#footnotes",
    "title": "About",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPhysics is an experimental science, a part of natural science. Mathematics is the part of physics where experiments are cheap. - V.I. Arnold, On Teaching Mathematics.↩︎"
  },
  {
    "objectID": "files.html",
    "href": "files.html",
    "title": "Files",
    "section": "",
    "text": "Documents which, for various reasons (including laziness), cannot be converted to the main website’s format.\n\nNew Physics Hints from Flavour. My PhD thesis.\nSolving the homogeneous Bethe-Salpeter equation for a fermion-scalar system in Minkowski space. My Master thesis.\nTeoria della Decoerenza Quantistica. My Bachelor thesis (in Italian).\nTeoria della Misura e Analisi Funzionale. Lecture notes on measure theory (in Italian)."
  },
  {
    "objectID": "notebooks/bootstrap/bootstrap.html",
    "href": "notebooks/bootstrap/bootstrap.html",
    "title": "Bootstrap",
    "section": "",
    "text": "The Bootstrap (B. Efron 1979; Bradley Efron and Tibshirani 1994) is a set of computational techniques for statistical inference that generally operate by approximating the distribution of a population of interest with an empirical estimate obtained from a finite sample. Such methods find practical use in all those situations when the true distribution is either unknown, due to limited knowledge of the data generating process, or impossible to compute in practice.\nIn general, bootstrap algorithms consist of two ingredients:\n\nA plugin principle, i.e. a substitution rule \\(P\\to\\hat P\\) that replaces the true data distribution \\(P\\) with an empirical estimate \\(\\hat P\\) obtained from a finite sample.\nA calculation scheme for computing functionals of the plugin distribution \\(\\hat P\\), usually involving simulation."
  },
  {
    "objectID": "notebooks/bootstrap/bootstrap.html#introduction",
    "href": "notebooks/bootstrap/bootstrap.html#introduction",
    "title": "Bootstrap",
    "section": "",
    "text": "The Bootstrap (B. Efron 1979; Bradley Efron and Tibshirani 1994) is a set of computational techniques for statistical inference that generally operate by approximating the distribution of a population of interest with an empirical estimate obtained from a finite sample. Such methods find practical use in all those situations when the true distribution is either unknown, due to limited knowledge of the data generating process, or impossible to compute in practice.\nIn general, bootstrap algorithms consist of two ingredients:\n\nA plugin principle, i.e. a substitution rule \\(P\\to\\hat P\\) that replaces the true data distribution \\(P\\) with an empirical estimate \\(\\hat P\\) obtained from a finite sample.\nA calculation scheme for computing functionals of the plugin distribution \\(\\hat P\\), usually involving simulation."
  },
  {
    "objectID": "notebooks/bootstrap/bootstrap.html#the-plugin-principle",
    "href": "notebooks/bootstrap/bootstrap.html#the-plugin-principle",
    "title": "Bootstrap",
    "section": "The plugin principle",
    "text": "The plugin principle\nThe main theoretical idea behind the bootstrap can be sketched with a non-parametric example. Consider a functional \\(t=t(P)\\) of a probability measure \\(P\\) which admits a first order expansion :\n\\[\nt(Q) \\approx t(P) + L(P; Q - P),\n\\tag{1}\\]\nwhere \\(L(P;\\nu)\\) is assumed to be a linear functional of \\(\\nu\\). If \\(Q\\) has finite support, linearity implies that:\n\\[\nL(P,Q-P) = \\intop \\psi _P\\,\\text dQ,\n\\tag{2}\\]\nand we shall further assume that such a representation is valid for any \\(Q\\)1. Notice in particular, that from this definition we have:\n\\[\n\\mathbb E(\\psi _P) = L(P,P-P) = 0\n\\tag{3}\\]\nSuppose now that we have a sample of \\(N\\) i.i.d. observations \\(\\{X_1,\\,X_2,\\,\\dots,\\,X_N\\}\\) coming from \\(P\\), and let \\(Q=\\hat P _N\\) in the previous expression, where \\(\\hat P _N = \\frac{1}{N}\\sum _{i=1}^N\\delta _{X_i}\\) stands for the empirical distribution. Then:\n\\[\nt(\\hat P _N) \\approx t(P) + L(P; \\hat P _N - P) = t(P) + \\frac{1}{N}\\sum _{i = 1} ^N \\psi(X_i).\n\\tag{4}\\]\nIt follows that \\(t(\\hat P _N)\\), i.e. the so-called “plugin” estimate, is a consistent estimate of \\(t(P)\\), with:\n\\[\n\\mathbb E(t(\\hat P _N)) \\approx t(P),\\quad \\mathbb V(t(\\hat P_N)) \\approx \\frac{1}{N}\\mathbb V(\\psi(X)),\n\\tag{5}\\]\nwhere the first equation follows from Equation 3, while the second one follows from the i.i.d. nature of the sample.\nThe main idea behind the non-parametric bootstrap is to estimate \\(t(P)\\) with \\(t(\\hat P _N)\\), which is justified by Equation 5 whenever the \\(\\mathcal O (N^{-1})\\) variance can be considered negligible (as is often the case in concrete bootstrap applications). In a parametric setting, the role of \\(\\hat P_N\\) could be played by some parametric estimate of \\(P\\). Similarly, sampling schemes other than i.i.d. (e.g. if dealing with time series data) require different empirical estimates of \\(P\\), but the basic principle - estimating \\(t(P)\\) with \\(t(\\hat P_N)\\) - remains the same.\nEstimates such as \\(t(\\hat P_N)\\) are usually referred to as ideal bootstrap estimates. As implied by the name, they can rarely be computed exactly in practice, because no analytic formula exists, and exact numerical calculations rapidly become prohibitive with growing \\(N\\). This leads to \\(t(\\hat P_N)\\) being estimated through simulation from \\(\\hat P _N\\), as explained below.\n\nA technical refinement\nIn many practical applications, the functional of interest \\(t(P)\\) would itself depend on \\(N\\), so that we should actually write \\(t_N(P)\\). A relevant example would be the variance of a plugin estimate \\(v_N(P)\\equiv\\mathbb V (t(\\hat P _N))\\). In this and similar cases, in which \\(v_N=\\mathcal O (N^{-\\alpha})\\) the argument can be repeated mutatis mutandis for the functional \\(V_N = N^\\alpha \\cdot v_N\\), which has a finite limit \\(V_N \\to V\\), assumed to be different from zero. Specifically, if we let \\(V_N = V+\\Delta _N\\) we have:\n\\[\nV_N(\\hat P_N) -V_N(P) = V(\\hat P_N)-V(P)+\\Delta _N (\\hat P_N)-\\Delta_N(P).\n\\]\nSince both terms in the right hand side have vanishing (to first order) expectation and \\(\\mathcal O (N^{-1})\\) variance, this shows that we can use \\(V_N(\\hat P _N)\\) to approximate the target quantity \\(V_N(P)\\), or equivalently \\(v_N(\\hat P _N)\\) to approximate \\(v_N(P)\\), since \\(\\frac{\\mathbb E(v_N(\\hat P_N))}{v_N(P)}\\approx 1\\) and \\(\\frac{\\sqrt {\\mathbb V(v_N(\\hat P_N))}}{v_N(P)}=\\mathcal O (N^{-1/2})\\)."
  },
  {
    "objectID": "notebooks/bootstrap/bootstrap.html#the-role-of-simulation",
    "href": "notebooks/bootstrap/bootstrap.html#the-role-of-simulation",
    "title": "Bootstrap",
    "section": "The role of simulation",
    "text": "The role of simulation\nThe second, more case specific, ingredient of a practical bootstrap estimate is an approximation scheme for effectively computing \\(t(\\hat P _N)\\). These methods typically involve simulating from \\(\\hat P_N\\), the reason being that the functional \\(t(Q)\\) usually involves expectations and/or quantiles of random variables of samples from \\(Q\\). When \\(Q = \\hat P_N\\), simulation allows to obtain \\(t(\\hat P_N)\\) by brute force.\nThis is best clarified with an example. Given a functional \\(\\theta(P)\\), we let:\n\\[\nv_N (P) = \\mathbb V_P(\\theta (\\hat P_N))\n\\tag{6}\\]\ndenote the variance (with respect to the original measure \\(P\\)) of its plugin estimate from a dataset of \\(N\\) i.i.d. observations. The ideal bootstrap estimate is given by:\n\\[\nv_N(\\hat P_N) = \\mathbb V_{\\hat P _N}(\\theta(\\hat P_N^*)),\n\\tag{7}\\]\nwhere \\(\\hat P _N ^*\\) denotes the empirical distribution of an i.i.d. sample of \\(N\\) elements from \\(\\hat P_N\\) - obviously, i.i.d. sampling from \\(\\hat P _N\\) is the same as sampling with replacement from the original dataset. Suppose now we generate \\(B\\) synthetic datasets of size \\(N\\) by sampling with replacement, and let \\(\\hat P_N ^{(b)*}\\) denote the corresponding empirical distributions. We can then estimate Equation 7 by:\n\\[\n\\widetilde {v_N(\\hat P_N)} = \\dfrac{1}{B-1}\\sum_{b=1}^{B}(\\theta(\\hat P_N ^{(b)*})- \\overline \\theta^*)^2,\n\\tag{8}\\]\nwhere \\(\\overline \\theta^* = \\frac{1}{B}\\sum_{b=1}^{B}\\theta(\\hat P_N ^{(b)*})\\). This would be our practical (as opposed to ideal) bootstrap estimate of \\(v_N(P)\\).\nStrictly speaking, the practical bootstrap estimate involves again an application of the plugin principle mentioned in the previous section, in which however the role of the true distribution \\(P\\) is played by the empirical estimate \\(\\hat P_N\\), from which we can sample without any limits. This means that (re)sampling variability associated with Equation 8 can be always made arbitrarily small, at least in principle, simply by increasing \\(B\\)."
  },
  {
    "objectID": "notebooks/bootstrap/bootstrap.html#footnotes",
    "href": "notebooks/bootstrap/bootstrap.html#footnotes",
    "title": "Bootstrap",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe integral representation Equation 2 with bounded \\(\\psi _P\\) automatically follows if \\(L\\) is (weak-star) continuous and Frechét differentiable (Huber 2004). In the most general case, the sense in which Equation 1 is assumed to hold is that of a directional (Gateaux) derivative, and we assume Equation 2 to hold for some measurable (not necessarily bounded) function \\(\\psi _P\\), which is usually easy to verify in concrete cases.↩︎"
  },
  {
    "objectID": "notebooks/maximum-likelihood/maximum-likelihood.html",
    "href": "notebooks/maximum-likelihood/maximum-likelihood.html",
    "title": "Maximum Likelihood",
    "section": "",
    "text": "Disclaimer. These are wild notes on Maximum Likelihood that require some deep labor limae session. Use at your own risk!\nLet \\(\\mathcal Q \\equiv\\{\\text d Q_{\\theta} = q_\\theta \\,\\text d \\mu\\}_{\\theta \\in \\Theta}\\) be a parametric family of probability measures dominated by some common measure \\(\\mu\\). Consider the functional1:\n\\[\n\\theta ^* (P) = \\arg \\min_{\\theta \\in \\Theta} \\intop \\text dP\\,\\ln \\left(\\frac{1}{q_\\theta}\\right).\n\\] {#eq-functional-theta-star}.\nThis is the parameter of the best (in the cross-entropy sense) approximation of \\(P\\) within \\(\\mathcal Q\\), which we assume to be unique.\nIf \\(P\\) represents the true probability distribution of the data under study, \\(\\theta ^*(P)\\) is the target of ML estimation, in the general case in which \\(P\\) is not necessarily in \\(\\mathcal Q\\). The ML estimate \\(\\hat \\theta _N\\) of \\(\\theta^*\\) from an i.i.d. sample of \\(N\\) observations is2:\n\\[\n\\hat \\theta _N \\equiv \\theta ^*(\\hat P _N)=\\arg \\max_{\\theta \\in \\Theta} \\sum_{i=1}^N \\ln ({q_\\theta(Y_i)}),\n\\tag{1}\\]\nwhere \\(\\hat P _N\\) is the empirical distribution of the sample.\nDenoting:\n\\[\nc_{P}(\\theta) = \\intop \\text dP\\,\\ln \\left(\\frac{1}{q_\\theta}\\right),\n\\tag{2}\\]\nwe see that \\(\\theta^*\\) is determined by the condition \\(c_{P}'(\\theta^*)=0\\). From this, we can easily derive the first order variation of \\(\\theta ^*\\) under a variation \\(P \\to P + \\delta P\\):\n\\[\n\\delta \\theta ^* =\\left(\\intop \\text dP\\,I_{\\theta ^*} \\right)^{-1}\\left(\\intop \\text d(\\delta P)u_{\\theta ^*}\\right)\n\\tag{3}\\]\nwhere we have defined:\n\\[\nu_\\theta = \\frac{\\partial }{\\partial \\theta} \\ln q_\\theta,\\quad I_\\theta = -\\frac{\\partial^2 }{\\partial \\theta ^2}  \\ln q_\\theta.\n\\tag{4}\\]\nFrom Equation 3 we can identify the influence function of the \\(\\theta ^*\\) functional:\n\\[\n\\psi_P(y)=\\left(\\intop \\text dP\\,I_{\\theta ^*} \\right)^{-1}u_{\\theta ^*}(y)\n\\tag{5}\\]\nThen, from the standard theory of influence functions, we have:\n\\[\n\\hat \\theta _N \\approx \\theta ^*+J ^{-1} U\n\\tag{6}\\]\nwhere we have defined:\n\\[\nJ\\equiv \\intop \\text dP\\,I_{\\theta ^*},\\quad U\\equiv\\frac{1}{N}\\sum _{i=1}^Nu_{\\theta ^*}(Y_i).\n\\tag{7}\\] In particular, we obtain the Central Limit Theorem (CLT)\n\\[\n\\sqrt N(\\hat \\theta _N - \\theta ^*) \\overset{d}{\\to} \\mathcal N(0, J^{-1}KJ^{-1}),\n\\tag{8}\\]\nwith:\n\\[\nK = \\mathbb V(u_{\\theta ^*}(Y)).\n\\tag{9}\\]\nThe matrices \\(K\\) and \\(J\\) depend on the unknown value \\(\\theta ^*\\), but we can readily construct plugin estimators:\n\\[\n\\hat J_N = -\\frac{1}{N}\\sum _{i=1}^NI_{\\hat \\theta _N}(Y_i),\\quad\\hat K_N = \\frac{1}{N}\\sum _{i=1}^Nu_{\\hat \\theta _N}(Y_i)u_{\\hat \\theta _N}(Y_i)^T,\n\\tag{10}\\]\nand estimate the variance of \\(\\hat \\theta _N\\) as:\n\\[\n\\widehat {\\mathbb V}(\\hat \\theta _N) = \\frac{\\hat J _N ^{-1}\\hat K_N\\hat J_N ^{-1}}{N},\n\\tag{11}\\]\nwhich is the usual Sandwich estimator. Finally, if \\(P = Q_{\\theta^*}\\), then \\(J = K\\), and the CLT Equation 8 becomes simply\n\\[\n\\sqrt N(\\hat \\theta _N - \\theta ^*) \\overset{d}{\\to} \\mathcal N(0, J^{-1}).\n\\]\nLet us now consider the following expansion of \\(c_P(\\hat \\theta _N)\\) which, we recall, is the cross-entropy of the ML model on the true distribution \\(P\\) (cf. Equation 2):\n\\[\n\\begin{split}\nc_P(\\hat \\theta _N)\n    &= -\\intop \\text d P(y')\\,\\ln (q_{\\hat \\theta}(y'))\\\\\n    & \\approx -\\mathbb E'(\\ln q_{\\theta^*})+\\frac{1}{2}(\\hat \\theta-\\theta ^*)^TJ (\\hat \\theta-\\theta ^*)\\\\\n    & \\approx -\\mathbb E'(\\ln q_{\\theta^*})+\\frac{1}{2}U^TJ^{-1}U\n\\end{split}\n\\]\nTaking the expectation with respect to the training dataset, noting that \\(\\mathbb E(U_{\\theta ^*}U_{\\theta ^*}^T)=K_{\\theta ^*}\\), we get:\n\\[\n\\mathbb E (c_P(\\hat \\theta _N))\\approx -\\mathbb E'(\\ln q_{\\theta^*})+\\frac{1}{2N}\\text {Tr}(J^{-1}K)\n\\tag{12}\\]\nNow consider the in-sample estimate:\n\\[\n\\begin{split}\nc_{\\hat P _N}(\\hat \\theta _N) &= -\\frac{1}{N}\\sum _{i=1}^N\\ln q_{\\hat \\theta}(Y_i)\\\\\n& \\approx - \\frac{1}{N}\\sum _{i=1} ^N \\ln q_{\\theta^*}(Y_i)- U^T(\\hat \\theta _N-\\theta^*)+ \\frac{1}{2}(\\hat \\theta _N-\\theta^*)^TJ(\\hat \\theta _N-\\theta^*)\\\\\n& \\approx - \\frac{1}{N}\\sum _{i=1} ^N \\ln q_{\\theta^*}(Y_i)- U^TJ ^{-1} U+ \\frac{1}{2}U^TJ ^{-1}\\hat J_N J^{-1}U\\\\\n& \\approx - \\frac{1}{N}\\sum _{i=1} ^N \\ln q_{\\theta^*}(Y_i)- \\frac{1}{2}U^TJ ^{-1} U.\n\\end{split}\n\\]\nTaking the expectation:\n\\[\n\\mathbb E (c_{\\hat P _N}(\\hat \\theta _N)) = -\\mathbb E'(\\ln q_{\\theta^*})-\\frac{1}{2N}\\text{Tr}(J^{-1}K)\n\\tag{13}\\]\nComparing Equation 13 and Equation 12 we see that:\n\\[\n\\text{TIC}\\equiv -\\frac{1}{N}\\sum _{i=1}^N\\ln q_{\\hat \\theta}(Y_i)+\\frac{1}{N}\\text{Tr}(J^{-1}K)\n\\tag{14}\\]\nprovides an asymptotically unbiased estimate of \\(\\mathbb E (c_P(\\hat \\theta _N))\\), the expected cross-entropy of a model from family \\(\\mathcal Q\\) estimated on a sample of \\(N\\) observations.\nThe previous derivation assumed the \\(Y_i\\) to be i.i.d. and does not apply, strictly speaking, to the case of regression, for which we need some more machinery. Assume that the pairs \\((X_i,\\,Y_i)\\) are drawn independently from a joint \\(X-Y\\) distribution. Instead of Equation 2, we consider:\nWe define, as in the i.i.d. case:\n\\[\n\\begin{split}\n\\theta ^*(P;\\mathbf X)&=\\arg\\max _{\\theta} \\frac{1}{N}\\sum_{i=1}^N\\intop \\text dP(y\\vert X_i)\\,\\ln \\left(\\frac{1}{q_{\\theta}(y\\vert X_i)}\\right),\\\\\n\\theta ^*(P)&=\\arg\\max _{\\theta} \\intop \\text dP(y,x)\\,\\ln \\left(\\frac{1}{q_{\\theta}(y\\vert X_i)}\\right),\\\\\n\\hat \\theta _N&=\\arg\\max _{\\theta} \\sum _{i=1}^N\\ln \\left(\\frac{1}{q_{\\theta}(Y_i\\vert X_i)}\\right)\n\\end{split}\n\\tag{15}\\]\nNoticing that \\(\\hat \\theta _N\\) is a plugin estimate of \\(\\theta ^*\\), we can repeat mutatis mutandis the steps leading to the CLT Equation 8, which is also valid in this case.\nRather than doing so, let us consider \\(\\hat \\theta _N\\) as the \\(\\mathbf X\\)-conditional plugin estimate of \\(\\theta ^*(P;\\mathbf X)\\), and the latter as a plugin estimate of \\(\\theta ^*(P)\\) interpreted as a functional of the \\(X\\) marginal distribution. Then, a parallel derivation to the one provided above for the i.i.d. case shows the conditional convergence in distribution:\n\\[\n\\sqrt N(\\hat \\theta _N - \\theta ^*(P;\\mathbf X))\\overset{d \\vert \\mathbf X}{\\to} \\mathcal N(0, J_{N}^{-1}(\\mathbf X)K_{N}(\\mathbf X)J_{N}^{-1}(\\mathbf X)).\n\\tag{16}\\]\nas well as the unconditional convergence:\n\\[\n\\sqrt N(\\theta ^*(P;\\mathbf X) - \\theta ^*(P))\\overset{d }{\\to} \\mathcal N(0, J^{-1}\\tilde K J^{-1}).\n\\tag{17}\\]\nwhere the various matrices are defined as:\n\\[\n\\begin{split}\nJ_N(\\mathbf X)&\\equiv \\frac{1}{N}\\sum _{i=1}^N\\mathbb E\\left[I _{\\theta} \\bigg\\vert X=X_i\\right]\\bigg\\vert_{\\theta = \\theta ^*(\\mathbf X)},\\\\\n\\quad K_N(\\mathbf X)&\\equiv\\frac{1}{N}\\sum _{i=1}^N\\mathbb V\\left[u _{\\theta }\\bigg\\vert X=X_i\\right]\\bigg\\vert_{\\theta = \\theta ^*(\\mathbf X)}\n\\end{split}\n\\tag{18}\\]\nand:\n\\[\n\\begin{split}\nJ&\\equiv \\mathbb E\\left[I_{\\theta^*} \\right],\\\\\n\\quad \\tilde K&\\equiv\\mathbb V\\left[\\mathbb E\\left(u_{\\theta ^*} \\vert X\\right)\\right]\n\\end{split}\n\\tag{19}\\]\nHere \\(I_\\theta\\) and \\(u_\\theta\\) are again defined as in Equation 4, but regarded as functions of the random pair \\(\\{(X,\\,Y)\\}\\), rather than \\(Y\\) alone. Although Equation 18 is written for \\(\\theta = \\theta ^*(\\mathbf X)\\), to the order of the present approximation we may as well substitute \\(\\theta ^*(\\mathbf X) \\approx \\theta ^*\\). Doing this, we can easily see that \\(J_N(\\mathbf X) \\to J\\), and \\(K_N(\\mathbf X) \\to \\mathbb E\\left[\\mathbb V\\left(u_{\\theta } \\vert X\\right)\\right]\\bigg\\vert_{\\theta = \\theta ^*}\\). This can be used to find the unconditional variance of \\(\\hat \\theta _N\\):\n\\[\n\\begin{split}\n\\mathbb V(\\hat \\theta _N)\n    &=\\mathbb E (\\mathbb V(\\hat \\theta _N \\vert \\mathbf X))+\\mathbb V (\\mathbb E(\\hat \\theta _N \\vert \\mathbf X))\\\\\n    &=\\mathbb E (\\mathbb V(\\hat \\theta _N \\vert \\mathbf X))+\\mathbb V (\\theta ^*(\\mathbf X))\\\\\n    &=J^{-1}\\left(\\mathbb V\\left[\\mathbb E\\left(u_{\\theta ^*} \\vert X\\right)\\right]+\\mathbb E\\left[\\mathbb V\\left(u_{\\theta ^*} \\vert X\\right)\\right]\\right)J^{-1}\\\\\n    &= J^{-1} KJ^{-1}\n\\end{split}\n\\] with \\(K = \\mathbb V(u_{\\theta^*})\\) as in the i.i.d. case, in agreement with the CLT Equation 8. Our derivation here shows how the variance of \\(\\hat \\theta _N\\) decomposes into a component due to the variability of \\(X\\), and a component due to the residual variability of \\(Y\\) given \\(X\\).\nThe corresponding result for the TIC Equation 14 is slightly less straightforward. Repeating the steps leading to this equation for a fixed sample of regressors \\(\\mathbf X\\), we find that:\n\\[\n\\mathbb E (\\text{TIC}\\vert \\mathbf X)=\\intop \\prod_{i=1}^N\\text dP(y_i\\vert X_i)\\,\\,\\frac{1}{N}\\sum_{j=1}^N\\intop \\text dP(y^\\prime\\vert X_j)\\ln \\left(\\frac{1}{q_{\\hat \\theta_N}(y^\\prime \\vert X_j)}\\right),\n\\tag{20}\\]\nwhere the outer integral is a conditional expectation on the sample responses, while the inner integrals are expectations with respect to a new response associated to a sample regressor \\(X_i\\). If we now average over \\(\\mathbf X\\), we\nfind:\n\\[\n\\mathbb E (\\text{TIC})=\\intop \\prod_{i=1}^N\\text dP(x_i,y_i)\\,\\,\\frac{1}{N}\\sum_{j=1}^N\\intop \\text dP(y^\\prime\\vert x_j)\\ln \\left(\\frac{1}{q_{\\hat \\theta_N}(y^\\prime \\vert x_i)}\\right)=\\mathbb E(\\text{CE}_\\text{in}).\n\\tag{21}\\]\nThe right-hand side is the expected in-sample cross-entropy, which is in general different from the extra-sample cross-entropy:\n\\[\n\\mathbb E(\\text{CE}) =\\intop \\prod_{i=1}^N\\text dP(x_i,y_i)\\intop \\text dP(x^\\prime,y^\\prime)\\ln \\left(\\frac{1}{q_{\\hat \\theta_N}(y^\\prime \\vert x^\\prime)}\\right).\n\\tag{22}\\]"
  },
  {
    "objectID": "notebooks/maximum-likelihood/maximum-likelihood.html#references",
    "href": "notebooks/maximum-likelihood/maximum-likelihood.html#references",
    "title": "Maximum Likelihood",
    "section": "References",
    "text": "References\n\n(Shalizi 2024)\n(Claeskens and Hjort 2008)\n(Freedman 2006)\n(White 1982)"
  },
  {
    "objectID": "notebooks/maximum-likelihood/maximum-likelihood.html#footnotes",
    "href": "notebooks/maximum-likelihood/maximum-likelihood.html#footnotes",
    "title": "Maximum Likelihood",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe definition does not depend on the representations \\(q_\\theta = \\frac{\\text d Q_\\theta}{\\text d \\mu}\\) chosen for the \\(\\mu\\)-density of \\(Q_\\theta\\) if \\(P\\) is also absolutely continuous with respect to \\(\\mu\\), which we tacitly assume. Typically \\(\\mu\\) would be some relative of Lebesgue or counting measures, in continuous and discrete settings respectively.↩︎\nAs a random variable, \\(\\hat \\theta _N\\) is also independent (modulo a measure zero set) of the specific \\(L_1\\) representation \\(q_\\theta\\) if \\(P\\) is absolutely continuous with respect to \\(\\mu\\).↩︎"
  },
  {
    "objectID": "notebooks/thermodynamics/thermodynamics.html",
    "href": "notebooks/thermodynamics/thermodynamics.html",
    "title": "Thermodynamics",
    "section": "",
    "text": "Miscellaneous notes about concepts of Thermodynamics."
  },
  {
    "objectID": "notebooks/thermodynamics/thermodynamics.html#systems",
    "href": "notebooks/thermodynamics/thermodynamics.html#systems",
    "title": "Thermodynamics",
    "section": "Systems",
    "text": "Systems\nThe system is the part of the universe that is the focus of our thermodynamic description. The state of a system is characterized by its macroscopic coordinates, the specification of which forms part of the experimental input to the thermodynamic description.\nThe system’s surroundings is the part of the universe that interacts (that is exchanges energy) with the system. The characterization of the surroundings may also include the specification of some macroscopic coordinates (e.g. external pressure, force fields, temperature of thermal reservoirs…)."
  },
  {
    "objectID": "notebooks/thermodynamics/thermodynamics.html#work",
    "href": "notebooks/thermodynamics/thermodynamics.html#work",
    "title": "Thermodynamics",
    "section": "Work",
    "text": "Work\nThe notion of “work” in Thermodynamics generally refers that fraction of energy exchanged by a system during a thermodynamic process, which could be produced by a change in the potential energy of some macroscopic object interacting with the system. In order to operationalize this intuition, we may assume that for any thermodynamic process there exist equivalent experimental conditions, under which the system passes through the same sequence of intermediate configurations connecting the initial and final states, and under which the performance of work is entirely implemented by the raising or lowering of a weight in a gravitational field.\nFrom the formal point of view, the quantitative expression of work in any given circumstance should be considered as an external input to the general theory. This may come either from direct measurement or from more detailed theories (e.g. mechanics, electromagnetism), always in accordance with the above operative definition.\nIt should be stressed that thermodynamics does not provide by itself any means to determine the “equivalent experimental conditions” referred to in the operative definition above, nor any guidance for calculating work from first principles. The ultimate test of whether a theoretical or empirical assessment of work is correct is the consistency of the resulting thermodynamic description for the system under consideration."
  },
  {
    "objectID": "notebooks/thermodynamics/thermodynamics.html#laws-of-thermodynamics",
    "href": "notebooks/thermodynamics/thermodynamics.html#laws-of-thermodynamics",
    "title": "Thermodynamics",
    "section": "Laws of thermodynamics",
    "text": "Laws of thermodynamics\n\nFirst law\n\nThere exist experimental conditions, called “thermal insulation”, under which the work performed along a certain transformation depends only on the initial and final states of the system.\n\nHere and below, the wording “adiabatic” will always refer to thermal insulation.\nThe operative definitions of internal energy and heat make use, in addition to the First Law, of the following additional postulate, sometimes referred to as the “Comparison Principle” (Lieb and Yngvason 1999):\n\nFor any two states of a thermodynamic system, there exists an adiabatic process that starts in one of the two states and ends in the other.\n\nWe can then define internal energy as the work required to bring a system to a given state from a reference zero-energy state, in adiabatic conditions. Once internal energy is defined, we define the heat absorbed during a process as the difference between the internal energy change and the work performed on the system. These definitions are conventionally summarized by the equation:\n\\[\n\\Delta U = W+Q.\n\\tag{1}\\]\n\n\nTransitivity of thermal equilibrium (“Zero-th” Law)\nTwo systems are said to be in thermal contact if they may exchange energy in the form of heat. When two systems, which are individually in equilibrium, are brought into thermal contact, they will generally undergo a series of changes, until reaching a new equilibrium state. At this point, we may say that the systems are in thermal equilibrium.\nIt is an empirical fact that:\n\nIf two systems are in thermal equilibrium with a third system, they are also in thermal equilibrium with each other.\n\nIf we take, as a probe for thermal equilibrium, a system which is essentially one-dimensional, such as an ideal gas held at a standard pressure, we can then conclude that thermal equilibrium can be characterized by a single number, an empirical temperature. The temperature of a system would be measured by the volume reached by our ideal gas probe once put in thermal contact with such system.\nThis principle is sometimes referred to as the “Zero-th” Law of Thermodynamics, because it is essential to the definition of temperature, whose concept is taken for granted throughout the usual expositions of Thermodynamics. In our formulation, the First Law precedes this principle from a logical point of view."
  },
  {
    "objectID": "posts/2021-07-06-r2r/r2r.html",
    "href": "posts/2021-07-06-r2r/r2r.html",
    "title": "{r2r} now on CRAN",
    "section": "",
    "text": "My package {r2r} (v0.1.1) has been accepted by CRAN, and is now available for download from the public repository.\n\n\n\n  \n\nr2r provides a flexible implementation of hash tables in R, allowing for:\n\narbitrary R objects as keys and values,\narbitrary key comparison and hash functions,\ncustomizable behaviour (throw or return a default value) on missing key exceptions.\n\n\n\n\nYou can install the released version of r2r from CRAN with:\ninstall.packages(\"r2r\")\nand the development version from my R-universe repository, with:\ninstall.packages(\"r2r\", repos = \"https://vgherard.r-universe.dev\")\n\n\n\n\nlibrary(r2r)\nm &lt;- hashmap()\n\n# Insert and query a single key-value pair\nm[[ \"user\" ]] &lt;- \"vgherard\"\nm[[ \"user\" ]]\n\n[1] \"vgherard\"\n\n# Insert and query multiple key-value pairs\nm[ c(1, 2, 3) ] &lt;- c(\"one\", \"two\", \"three\")\nm[ c(1, 3) ]\n\n[[1]]\n[1] \"one\"\n\n[[2]]\n[1] \"three\"\n\n# Keys and values can be arbitrary R objects\nm[[ lm(mpg ~ wt, mtcars) ]] &lt;- c(TRUE, FALSE, TRUE)\nm[[ lm(mpg ~ wt, mtcars) ]]\n\n[1]  TRUE FALSE  TRUE\n\n\n\n\n\nFor further details, including an introductory vignette illustrating the features of r2r hash maps, you can consult the r2r website. If you encounter a bug, want to suggest a feature or need further help, you can open a GitHub issue.\n\n\n\nCRAN package {hash} also offers an implementation of hash tables based on R environments. The two tables below offer a comparison between {r2r} and {hash} (for more details, see the benchmarks Vignette)\n\n\n\nFeatures supported by {r2r} and {hash}.\n\n\n\n\n\n\n\nFeature\nr2r\nhash\n\n\n\n\nBasic data structure\nR environment\nR environment\n\n\nArbitrary type keys\nX\n\n\n\nArbitrary type values\nX\nX\n\n\nArbitrary hash function\nX\n\n\n\nArbitrary key comparison function\nX\n\n\n\nThrow or return default on missing keys\nX\n\n\n\nHash table inversion\n\nX\n\n\n\n\n\n\n\n\nPerformances of {r2r} and {hash} for basic hash table operations.\n\n\nTask\nComparison\n\n\n\n\nKey insertion\n{r2r} ~ {hash}\n\n\nKey query\n{r2r} &lt; {hash}\n\n\nKey deletion\n{r2r} &lt;&lt; {hash}"
  },
  {
    "objectID": "posts/2021-07-06-r2r/r2r.html#r2r",
    "href": "posts/2021-07-06-r2r/r2r.html#r2r",
    "title": "{r2r} now on CRAN",
    "section": "",
    "text": "r2r provides a flexible implementation of hash tables in R, allowing for:\n\narbitrary R objects as keys and values,\narbitrary key comparison and hash functions,\ncustomizable behaviour (throw or return a default value) on missing key exceptions."
  },
  {
    "objectID": "posts/2021-07-06-r2r/r2r.html#installation",
    "href": "posts/2021-07-06-r2r/r2r.html#installation",
    "title": "{r2r} now on CRAN",
    "section": "",
    "text": "You can install the released version of r2r from CRAN with:\ninstall.packages(\"r2r\")\nand the development version from my R-universe repository, with:\ninstall.packages(\"r2r\", repos = \"https://vgherard.r-universe.dev\")"
  },
  {
    "objectID": "posts/2021-07-06-r2r/r2r.html#usage",
    "href": "posts/2021-07-06-r2r/r2r.html#usage",
    "title": "{r2r} now on CRAN",
    "section": "",
    "text": "library(r2r)\nm &lt;- hashmap()\n\n# Insert and query a single key-value pair\nm[[ \"user\" ]] &lt;- \"vgherard\"\nm[[ \"user\" ]]\n\n[1] \"vgherard\"\n\n# Insert and query multiple key-value pairs\nm[ c(1, 2, 3) ] &lt;- c(\"one\", \"two\", \"three\")\nm[ c(1, 3) ]\n\n[[1]]\n[1] \"one\"\n\n[[2]]\n[1] \"three\"\n\n# Keys and values can be arbitrary R objects\nm[[ lm(mpg ~ wt, mtcars) ]] &lt;- c(TRUE, FALSE, TRUE)\nm[[ lm(mpg ~ wt, mtcars) ]]\n\n[1]  TRUE FALSE  TRUE"
  },
  {
    "objectID": "posts/2021-07-06-r2r/r2r.html#getting-help",
    "href": "posts/2021-07-06-r2r/r2r.html#getting-help",
    "title": "{r2r} now on CRAN",
    "section": "",
    "text": "For further details, including an introductory vignette illustrating the features of r2r hash maps, you can consult the r2r website. If you encounter a bug, want to suggest a feature or need further help, you can open a GitHub issue."
  },
  {
    "objectID": "posts/2021-07-06-r2r/r2r.html#comparison-with-hash",
    "href": "posts/2021-07-06-r2r/r2r.html#comparison-with-hash",
    "title": "{r2r} now on CRAN",
    "section": "",
    "text": "CRAN package {hash} also offers an implementation of hash tables based on R environments. The two tables below offer a comparison between {r2r} and {hash} (for more details, see the benchmarks Vignette)\n\n\n\nFeatures supported by {r2r} and {hash}.\n\n\n\n\n\n\n\nFeature\nr2r\nhash\n\n\n\n\nBasic data structure\nR environment\nR environment\n\n\nArbitrary type keys\nX\n\n\n\nArbitrary type values\nX\nX\n\n\nArbitrary hash function\nX\n\n\n\nArbitrary key comparison function\nX\n\n\n\nThrow or return default on missing keys\nX\n\n\n\nHash table inversion\n\nX\n\n\n\n\n\n\n\n\nPerformances of {r2r} and {hash} for basic hash table operations.\n\n\nTask\nComparison\n\n\n\n\nKey insertion\n{r2r} ~ {hash}\n\n\nKey query\n{r2r} &lt; {hash}\n\n\nKey deletion\n{r2r} &lt;&lt; {hash}"
  },
  {
    "objectID": "posts/2022-10-18-posi/posi.html",
    "href": "posts/2022-10-18-posi/posi.html",
    "title": "How to get away with selection. Part I: Introduction",
    "section": "",
    "text": "A few months back, for undocumented circumstances, my browser’s search history was full of terms like “parameter estimation with variable selection”, or “confidence intervals after cross-validation”, or again “linear model uncertainties after staring into the abyss”, …\nSparing you my rock bottom, I eventually stumbled upon the right keywords, and started digging into the mathematical aspects of Selective Inference, or Post-Model Selection Inference. Now, while my hands are still full of dirt, I’ve decided it’s the right moment to write some notes about what I’ve learned - whose main recipient is the future me, which will otherwise inevitably forget what the present me thinks he knows. If you’re not the future me:\n\nWelcome 👋\nIf you have detected some imprecision, or have suggestions for this or the next posts, you are more than welcome to create an issue on the source repository of this blog."
  },
  {
    "objectID": "posts/2022-10-18-posi/posi.html#footnotes",
    "href": "posts/2022-10-18-posi/posi.html#footnotes",
    "title": "How to get away with selection. Part I: Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere, in the “extended family of models”, I’m also implicitly accounting for the multiplicity introduced by continuous model parameters and training parameters (also known as hyper-parameters).↩︎\nThe preferential method according to (Shalizi 2020), from which I borrowed the “a-theoretical” description, and which I recommend as a starting point for literature review.↩︎\nThis is not to say that correctly accounting for Selective Inference is the default in scientific practice. A relevant example from the field I come from (Particle Physics), is documented in this stimulating reference: (Isidori et al. 2021).↩︎\nI’m always amazed by the great deal of theory one can learn by running a dumb simulation, and trying to explain a posteriori what seems to be a too perfect result. Technically, this follows from the fact that the slope estimate \\(\\hat m\\) and residual sum of squares \\(\\text{RSS}\\) of the reduced model, and the \\(F\\)-statistic used to test \\(q = 0\\), are all independent random variables under the same null hypothesis, here true by construction. All these facts are in turn consequences of general theorems from linear model theory, see for example (Vrbik 2020, chap. 4)… and, to be sure, it took me more than a single night without sleep to figure all this out.↩︎\nAnd I’m actually not sure that, after properly taking into account Selective Inference, it would lead to a substantial gain in estimation accuracy, compared to simply fitting the possibly redundant model with intercept.↩︎"
  },
  {
    "objectID": "posts/2023-03-10-correlation-without-causation/correlation-without-causation.html",
    "href": "posts/2023-03-10-correlation-without-causation/correlation-without-causation.html",
    "title": "Correlation Without Causation",
    "section": "",
    "text": "It is part of common knowledge that correlation does not require causation. Absence of causation, say between a condition \\(p\\) and an effect \\(q\\), means that the realization of \\(p\\) has no influence on the presence of \\(q\\). If this is the case, a statistical correlation between \\(p\\) and \\(q\\) can still be present, if the realization of \\(p\\) modifies our state of information about \\(q\\).\nAs an example, let \\(X,Y\\) be two conditionally independent binary random variables, with a common probability \\(\\Theta\\) of evaluating to one. Think, for instance, of a machine that produces pairs of identical biased coins, with a probability of tails \\(\\Theta\\). If \\(\\Theta\\) is equal to a given value \\(\\theta\\), the joint probability distribution of \\(X\\) and \\(Y\\) is:\n\\[\n\\text {Pr}(X=x,Y=y\\vert \\Theta = \\theta) = B(x;\\theta)B(y;\\theta),\n\\tag{1}\\]\nwhere \\(B(z; \\theta) = \\theta ^z (1 - \\theta) ^ {1-z}\\). Whether or not this provides a satisfying probabilistic description of experiments on \\(X\\) and \\(Y\\) depends on context.\nFrom a frequentist point of view, if \\(\\Theta\\) is fixed once and for all, the right hand side of Equation 1 correctly describes the experimental outcomes of \\(X\\) and \\(Y\\) for some value of \\(\\theta\\). On the other hand, if \\(\\Theta\\) can change from experiment to experiment in a random fashion, and we do not observe its values \\(\\theta\\), we clearly cannot use Equation 1 as it stands, as its usage requires knowing \\(\\theta\\). Finally, from a bayesian’s point of view, if \\(\\Theta\\) is fixed but unknown, Equation 1 does not describe our state of knowledge about \\(X\\) and \\(Y\\), because it assumes unavailable information (\\(\\Theta = \\theta\\)).\nIn the last two cases, what we’re actually after is the unconditional probability:\n\\[\n\\text{Pr}(X=x,\\,Y=y)=\\intop\\,\\text{d}P_\\Theta(\\theta) \\,\\text{Pr}(X=x,Y=y\\vert\\Theta = \\theta)\n\\tag{2}\\]\nwhere \\(\\text{d}P_\\Theta(\\theta)\\) can be regarded either as the actual probability distribution of \\(\\Theta\\) (in a frequentist framework) or as a subjective prior distribution (in a bayesian framework).\nPlugging Equation 1 into Equation 2, we find:\n\\[\n\\begin{split}\n\\text{Pr}(X=1,\\,Y=1) & = \\mathbb E(\\Theta)^2+\\text{Var}(\\Theta)\\\\\n\\text{Pr}(X=1,\\, Y=0)&=\\mathbb E(\\Theta)-\\mathbb E(\\Theta)^2-\\text{Var}(\\Theta)\\\\\n\\text{Pr}(X=0,\\, Y=1)&=\\mathbb E(\\Theta)-\\mathbb E(\\Theta)^2-\\text{Var}(\\Theta)\\\\\n\\text{Pr}(X=0,\\,Y=0) & = \\mathbb (1-\\mathbb E(\\Theta))^2+\\text{Var}(\\Theta) \\\\\n\\end{split}\n\\]\nIn particular, we have:\n\\[\n\\dfrac{\\text{Pr}(Y = 1 \\vert\\, X = 1)}{\\text {Pr}(Y=1)} = 1+\\frac{\\text{Var}(\\Theta)}{\\mathbb{E}(\\Theta)^2},\n\\tag{3}\\]\nwhich means that, unconditionally, \\(X\\) and \\(Y\\) are not independent, but in fact positively correlated1.\nObservations of this kind apply, mutatis mutandis, in many practical situations. For instance if we were modeling the time series of new visitors to a website, we could reasonably assume that the number of yesterday’s new visitors does not influence the number of today’s ones (if individual visitors are unlikely to interact with each other). Yet, it would be wrong to assume, and easy to disprove, that these two numbers are by themselves statistically independent, because yesterday’s new visitors carry useful background information on today’s potential new visitors.\nThe bottom line of the post is that lack of causation does not imply lack of correlation, which is logically equivalent to the original motto… but, for some strange reason, I find easier to forget."
  },
  {
    "objectID": "posts/2023-03-10-correlation-without-causation/correlation-without-causation.html#footnotes",
    "href": "posts/2023-03-10-correlation-without-causation/correlation-without-causation.html#footnotes",
    "title": "Correlation Without Causation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere I’m using the word correlation in a loose sense, as in the popular motto.↩︎"
  },
  {
    "objectID": "posts/2023-05-12-consistency-and-bias-of-ols-estimators/consistency-and-bias-of-ols-estimators.html",
    "href": "posts/2023-05-12-consistency-and-bias-of-ols-estimators/consistency-and-bias-of-ols-estimators.html",
    "title": "Consistency and bias of OLS estimators",
    "section": "",
    "text": "Given random variables \\(Y\\colon \\Omega \\to \\mathbb R\\) and \\(X\\colon \\Omega \\to \\mathbb R ^{p}\\) defined on an event space \\(\\Omega\\), denote:\n\\[\n\\beta = \\arg \\min _{\\beta ^\\prime } \\mathbb E[(Y-X \\beta^\\prime )^2]= \\mathbb E(X^TX)^{-1}\\mathbb E(X^TY),\n\\tag{1}\\]\nso that \\(X \\beta\\) is the best linear predictor of \\(Y\\) in terms of \\(X\\) (\\(X\\) is regarded as a row vector).\nLet \\((\\textbf Y, \\textbf X)\\) be independent samples from the joint \\(XY\\) distribution, with independent observations stacked vertically in \\(N \\times 1\\) and \\(N \\times p\\) matrices respectively, as customary. Then the usual Ordinary Least Squares (OLS) estimator of \\(\\beta\\) is given by:\n\\[\n\\hat \\beta = \\arg \\min _{\\beta ^\\prime}(\\textbf Y - \\textbf X \\beta ^\\prime)^2=(\\textbf X^T\\textbf X)^{-1} \\textbf X^T \\textbf Y.\n\\tag{2}\\]\nThis is a consistent, but generally biased estimator of \\(\\beta\\).\nComparing Equation 1 and Equation 2, consistency follows immediately from the law of large numbers and continuity. In order to show that \\(\\mathbb E (\\hat \\beta) \\neq \\beta\\) in general, it is sufficient to provide an example.\nConsider, for instance (example adapted from D.A. Freedman):\n\\[\nX \\sim \\mathcal N (0, 1),\\qquad Y=X(1+aX^2)\n\\] Recalling that \\(\\mathbb E (X^4) = 3\\) for the standard normal, we have:\n\\[\n\\beta = 1+3a,\n\\] where we have ignored a potential intercept term (which would vanish here, since \\(\\mathbb E (Y) = 0\\)). To compute \\(\\mathbb E (\\hat \\beta)\\), we use the identity \\(\\frac{e^{-z}}{z} = \\intop _1 ^\\infty \\text d t\\, e ^{-zt}\\) to rewrite this expected value as:\n\\[\n\\begin{split}\n\\mathbb E (\\hat \\beta) & =  (2 \\pi)^{-N/2}\n    \\intop \\text d\\textbf X \\,e^{-\\sum _j X_i ^2 /2}\n                                    \\dfrac{\\sum _i X_i^2(1+aX_i^2)}{\\sum _i X_i^2} = \\frac{N}{2}\\intop_1 ^\\infty \\text d t\\,I(t) \\\\\nI(t)                                     & \\equiv (2 \\pi)^{-N/2} \\intop \\text d\\textbf X\\,\n                                                        e^{-t \\sum _j X_j ^2 /2}X_1^2(1+aX_1^2)\n\\end{split}\n\\] The inner integral can be computed easily:\n\\[\nI(t) = t^{-\\frac{N}{2}}(\\frac{1}{t}+a\\frac{3}{t^2})\n\\] and we eventually find: \\[\n\\mathbb E (\\hat \\beta) = 1+3 a\\frac{N}{N+2}\n\\]\nThe bias is thus given by:\n\\[\n\\beta - \\mathbb E (\\hat \\beta) = \\frac{6a}{N+2}\n\\] This vanishes linearly, in agreement with the fact that \\(\\sqrt N (\\hat \\beta - \\beta )\\) converges in probability to a gaussian with zero mean and finite variance (which requires the bias to be \\(o(N^{-1/2})\\)).\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2023,\n  author = {Gherardi, Valerio},\n  title = {Consistency and Bias of {OLS} Estimators},\n  date = {2023-05-12},\n  url = {https://vgherard.github.io/posts/2023-05-12-consistency-and-bias-of-ols-estimators/consistency-and-bias-of-ols-estimators.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2023. “Consistency and Bias of OLS\nEstimators.” May 12, 2023. https://vgherard.github.io/posts/2023-05-12-consistency-and-bias-of-ols-estimators/consistency-and-bias-of-ols-estimators.html."
  },
  {
    "objectID": "posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise.html",
    "href": "posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise.html",
    "title": "Linear regression with autocorrelated noise",
    "section": "",
    "text": "Consider two time series \\(Y_t\\) and \\(X_t\\) such that:\n\\[\nY_t =  X_t \\cdot \\beta+\\eta_t\n\\tag{1}\\]\nwhere \\(\\eta_t\\) is \\(\\text{AR}(1)\\) noise:\n\\[\n\\eta_{t+1} = \\alpha \\eta_t + \\epsilon_t, \\qquad \\epsilon _t \\sim \\mathcal N(0,\\sigma^2_0)                                                               \n\\tag{2}\\]\nBy iteration of Equation 2, we see that \\(\\eta_t\\) has gaussian unconditional distribution:\n\\[\n\\eta_t \\sim \\mathcal N (0, \\sigma ^2),\\qquad \\sigma^2 \\equiv \\frac{\\sigma^2_0}{1-\\alpha ^2}                             \n\\tag{3}\\] so that individual observations of \\((X_t,\\,Y_t)\\) are distributed according to a perfectly specified linear model.\nThis does not mean that, given observational data \\(\\{(X_t,\\,Y_t)\\}_{t = 1,\\,2,\\,\\dots,\\,T}\\), we are allowed to make standard linear model assumptions to perform valid inference on the parameters \\(\\beta\\) and \\(\\sigma\\) of Equation 1 and Equation 3. Since the noise terms \\(\\eta _t\\) are not independent draws from a single distribution, but are rather autocorrelated, the usual OLS variance estimate under linear model assumptions will be biased, as we show below 1.\nIt is fairly easy to work out the consequences of autocorrelation. Suppose, more generally, that the error term \\(\\eta _t\\) is a stationary time series with unconditional mean \\(\\mathbb E(\\eta_t)=0\\) and unconditional variance \\(\\text{Var}(\\eta _t)=\\sigma ^2\\). The OLS estimate of \\(\\beta\\) is2:\n\\[\n\\hat \\beta =(\\mathbf X^T\\mathbf X)^{-1}\\mathbf X^T\\mathbf Y=\\beta + (\\mathbf X^T\\mathbf X)^{-1} \\mathbf X^T \\mathbf{η},\n\\tag{4}\\]\nwhich is unbiased since \\(\\mathbb E (\\mathbf{η}) = 0\\). The estimate of the noise variance \\(\\sigma ^2\\), on the other hand:\n\\[\n\\begin{split}\n\\hat \\sigma ^2  & = \\frac{(\\mathbf Y - \\mathbf X\\hat \\beta)^T(\\mathbf Y - \\mathbf X\\hat \\beta)}{N-p}= \\frac{\\mathbf{η}^T(\\mathbf 1-\\mathbf H)\\mathbf{η} }{N-p} \\\\\n\\mathbb E (\\hat \\sigma ^2) & = \\dfrac{\\text {Tr}\\left[(\\mathbf 1- \\mathbb E(\\mathbf H))\\cdot  \\text {Cor}(\\mathbf{η})\\right]}{N-p}\\sigma ^2                     \n\\end{split}\n\\] where \\(\\mathbf H = \\mathbf X(\\mathbf X^T\\mathbf X)^{-1}\\mathbf X^T\\) as usual, and we have used the fact that \\(\\mathbb {V}( \\mathbf{η} ) = \\sigma ^2 \\cdot \\text {Cor}(\\mathbf{η})\\) (since each \\(\\eta_t\\) has the same unconditional variance \\(\\sigma ^2\\)). Hence the \\(\\hat \\sigma ^2\\) OLS estimate is biased if \\(\\text{Cor}(\\mathbf{η})\\neq \\mathbf 1\\).\nSimilarly, the variance-covariance matrix of the OLS \\(\\hat \\beta\\) estimator is:\n\\[\n\\mathbb V (\\hat \\beta) = \\mathbb E\\left[(\\mathbf X^T\\mathbf X)^{-1}\\mathbf X^T\\text {Cor}(\\mathbf{η})\\mathbf X (\\mathbf X^T\\mathbf X)^{-1} \\right]\\sigma^2\n\\] whereas its OLS estimate is:\n\\[\n\\hat {\\mathbb V} (\\hat \\beta) = (\\mathbf X^T\\mathbf X)^{-1} \\hat \\sigma ^2\n\\] which is biased for \\(\\text{Cor}(\\mathbf{η})\\neq \\mathbf 1\\).\nEven though the variance estimators are themselves biased, the biases could still vanish in the asymptotic limit. This is the case for \\(\\hat \\sigma ^2\\), as we can see by rewriting:\n\\[\n\\dfrac{\\mathbb E (\\hat \\sigma ^2)}{\\sigma ^2}-1 = -\\dfrac{1}{{N-p}}\\text {Tr}\\left[\\mathbb E(\\mathbf H)^T\\cdot(\\text {Cor}(\\mathbf{η})-\\mathbf 1)\\cdot \\mathbb E(\\mathbf H)\\right]                      \n\\] where we have used the projector properties of \\(\\mathbf H\\) to recast the trace in terms of a symmetric operator. In principle, nothing prevents the operator above to have \\(O(N)\\) eigenvalues, which would make the \\(\\hat \\sigma ^2\\) estimator asymptotically biased3. In realistic cases, one expects the correlations \\(\\text{Cor}(\\eta_t,\\eta_{t'})\\) to decay exponentially with \\(\\vert t - t'\\vert\\) 4 , in which case the trace is bounded to be of \\(O(p)\\), and \\(\\mathbb E(\\hat \\sigma ^2) \\to \\sigma ^2\\) as \\(N\\to \\infty\\).\nFor \\(\\hat {\\mathbb V} (\\hat \\beta)\\) things are not so favorable. It is enough to consider a special case of a plain intercept term: \\(X=1\\). In this case, we find with some manipulations:\n\\[\n\\begin{split}\n\\mathbb V (\\hat \\beta) &= \\frac{\\sigma ^2}{N}\\left(1+\\frac{1}{N}\\sum _{t\\neq t'} \\text{Cor}(\\eta_t,\\eta_{t'})\\right),\\\\\n\\mathbb E(\\hat {\\mathbb V} (\\hat \\beta)) & = \\frac{\\sigma ^2}{N}\\left(1-\\frac{1}{N(N-1)}\\sum _{t\\neq t'} \\text{Cor}(\\eta_t,\\eta_{t'})\\right)\n\\end{split}\n\\] Since \\(\\sum _{t\\neq t'}\\text{Cor}(\\eta_t,\\eta_{t'})=O(N)\\), we see that:\n\\[\n\\lim _{N\\to \\infty} \\dfrac{\\mathbb E(\\hat {\\mathbb V} (\\hat \\beta))}{\\mathbb V(\\hat \\beta)}\\neq 1\n\\] which amounts to say that \\(\\hat {\\mathbb V} (\\hat \\beta)\\) is asymptotically biased5."
  },
  {
    "objectID": "posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise.html#footnotes",
    "href": "posts/2023-05-20-linear-regression-with-autocorrelated-noise/linear-regression-with-autocorrelated-noise.html#footnotes",
    "title": "Linear regression with autocorrelated noise",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the linear model assumptions to hold, the \\((X_t,\\,Y_t)\\) pairs should come from independent realizations of the same time series, which is of course not the type of data we are usually presented with.↩︎\nAs usual we stack observations vertically in the \\(\\mathbf X\\) and \\(\\mathbf Y\\) matrices.↩︎\nFor an extreme case, suppose that \\(\\mathbf X = \\mathbf e\\) (no covariate except for an intercept term), and let the noise term be \\(\\eta _t = Z_0 + Z_t\\), where \\(Z_0\\) and \\(\\{Z_t\\}_{t=1,2,\\dots,T}\\) are independent \\(Z\\)-scores. One can easily see that, in this setting, \\(\\text {Cor}(\\eta) = \\frac{1}{2}(\\mathbf 1+\\mathbf e \\mathbf e^T )\\) and \\(\\text{Tr}(\\cdots) \\approx \\frac{N}{2}\\).↩︎\nFor instance, for the \\(\\text{AR}(1)\\) noise of Eq. Equation 2, we have \\(\\text{Cor}(\\eta_t, \\eta_{t'})= \\alpha ^{\\vert t - t'\\vert}\\).↩︎\nThe difference \\(\\mathbb E(\\hat {\\mathbb V} (\\hat \\beta))-\\mathbb V(\\hat \\beta)\\) decays as \\(O(N^{-1})\\), which is of the same order of the estimation target \\(\\mathbb V (\\hat \\beta)\\). Not sure I’m using standard terminology here.↩︎\nDisclaimer: I haven’t read any theory about the HAC estimator, so I may be misusing it here, but I would have expected it to work relatively well on such an “easy” example. For illustrations on how to use sandwich estimators for first- and second-order linear model misspecification, you can read this post of mine.↩︎"
  },
  {
    "objectID": "posts/2023-06-07-p-values-and-measure-theory/p-values-and-measure-theory.html",
    "href": "posts/2023-06-07-p-values-and-measure-theory/p-values-and-measure-theory.html",
    "title": "p-values and measure theory",
    "section": "",
    "text": "Let \\((\\Omega, \\mathcal E, \\text{Pr})\\) be a probability space, where \\(\\Omega\\) is the space of random outcomes, \\(\\mathcal E\\) the \\(\\sigma\\)-algebra of measurable events, and \\(P\\) the probability measure.\nGiven a random variable \\(T\\colon \\Omega \\to \\mathbb R\\), define \\(p_T\\colon \\Omega \\to \\left[0,1\\right]\\) as:\n\\[\np_T(\\omega) = \\text{Pr}(\\{\\omega'\\in \\Omega\\,\\vert\\, T(\\omega')\\geq T(\\omega)\\})\n\\]\nTheorem. \\(p_T\\) is measurable and \\(\\text{Pr}(p_T\\leq \\alpha) \\leq \\alpha\\) for all \\(\\alpha \\in \\left[0,1\\right]\\). Equality holds if and only if there exists a sequence \\(\\{\\omega_n\\}_{n\\in \\mathbb N}\\) such that \\(p_T(\\omega_n) \\leq \\alpha\\), and \\(p_T(\\omega _n)\\to \\alpha\\) as \\(n \\to \\infty\\).\nProof. Let \\(\\alpha\\in\\left[0,1\\right]\\), and denote: \\[\nE_T(\\omega) = \\{\\omega'\\in \\Omega\\,\\vert\\, T(\\omega')\\geq T(\\omega)\\},\n\\] so that \\(p_T(\\omega) = \\text{Pr}(E_T(\\omega))\\).\nAssume first that there exists \\(\\omega_\\alpha \\in p_T^{-1}(\\alpha)\\), that is to say \\(\\text{Pr}(E_T(\\omega)) = \\alpha\\). We can show that:\n\\[\nN_T(\\omega_\\alpha) = \\{\\omega \\vert p_T(\\omega) \\leq \\alpha\\} \\backslash E_T(\\omega_\\alpha)\n\\] is a measurable, zero probability set, which proves the thesis for this particular case. As a matter of fact, for any \\(\\omega \\in \\Omega\\), if \\(p_T(\\omega)\\leq \\alpha\\) and \\(T(\\omega) &lt;T(\\omega_\\alpha)\\), then we must have:\n\\[\n\\text{Pr}(\\{\\omega'\\in \\Omega\\,\\vert\\,\n                                                                T(\\omega_\\alpha)&gt;T(\\omega')\\geq T(\\omega)\\}\n                                                                ) = p_T(\\omega) - \\alpha=0.\n\\] If \\(t_* = \\inf_{p_T(\\omega)\\leq \\alpha}T(\\omega)\\) and \\(\\{a _n\\}_{n \\in \\mathbb N}\\) is a sequence in \\(\\Omega\\) such that \\(T(a _n)\\to t_*\\) as \\(n\\to \\infty\\), then:\n\\[\nN_T(\\omega _\\alpha) \\subseteq \\cup _n \\{\\omega'\\in \\Omega\\,\\vert\\,\n                                                                T(\\omega_\\alpha)&gt;T(\\omega')\\geq T(a_n)\\},\n\\] the right hand side being a probability zero set.\nIf \\(p_T^{-1}(\\alpha)\\) is empty, let \\(\\alpha^* = \\sup _{p_T(\\omega)\\leq \\alpha}p(\\omega)\\), and let \\(\\{b _n\\}_{n\\in \\mathbb N}\\) be a sequence in \\(\\Omega\\) such that \\(p_T(b_n)\\to \\alpha^*\\) as \\(n\\to \\infty\\). Then:\n\\[\n\\{\\omega \\vert p_T(\\omega) \\leq \\alpha\\}=\n\\{\\omega \\vert p_T(\\omega) \\leq \\alpha^*\\}=\n\\cup _n \\{\\omega \\vert p_T(\\omega) \\leq p_T(b_n)\\},\n\\] so that, from the particular case proved earlier, we have:\n\\[\n\\text{Pr}(p_T \\leq \\alpha) = \\lim _{n \\to \\infty} \\text{Pr}(p_T \\leq p_T(b_n)) \\leq \\lim _{n \\to \\infty} p_T(b_n) = \\alpha ^* \\leq \\alpha,\n\\] as was to be proved.\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2023,\n  author = {Gherardi, Valerio},\n  title = {P-Values and Measure Theory},\n  date = {2023-06-07},\n  url = {https://vgherard.github.io/posts/2023-06-07-p-values-and-measure-theory/p-values-and-measure-theory.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2023. “P-Values and Measure Theory.”\nJune 7, 2023. https://vgherard.github.io/posts/2023-06-07-p-values-and-measure-theory/p-values-and-measure-theory.html."
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html",
    "title": "Testing functional specification in linear regression",
    "section": "",
    "text": "Another one from the series on “misspecified regression models” (started with Model Misspecification and Linear Sandwiches)."
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#intro",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#intro",
    "title": "Testing functional specification in linear regression",
    "section": "Intro",
    "text": "Intro\nLately I’ve been messing around with the {lmtest} R package, a nice collection of hypothesis tests for classical linear model assumptions: linearity (of course) and heteroskedasticity (\\(X\\)-independence of the conditional variance).\nJust to clarify, here the relevant “linearity” assumption is that the conditional mean \\(\\mathbb E (Y\\vert X)\\) is given by a linear combination of known functions \\(f_i\\) of \\(X\\):\n\\[\n\\mathbb E (Y\\vert X) = \\sum _{i = 1}^p \\alpha_if_i(X),\n\\] Testing “linearity” (or, as the title goes, “functional specification”) refers to testing that the chosen set of functions \\(\\{f_{i}\\}_{i=1,\\dots,p}\\) provide a valid description of the data generating process."
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#first-attempt-residual-autocorrelation",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#first-attempt-residual-autocorrelation",
    "title": "Testing functional specification in linear regression",
    "section": "First attempt: residual autocorrelation",
    "text": "First attempt: residual autocorrelation\nMy initial intuition was that it should be possible to test functional specification through the following procedure:\n\nPerform linear regression with the specified functional form.\nOrder the residuals according to the corresponding values of \\(X\\)1.\nTest for serial correlation (e.g. performing a Durbin-Watson test, lmtest::dwtest) on the series of ordered residuals.\n\nThe idea is quite simple: if residuals exhibit some systematic pattern when plotted against \\(X\\), then for close values of \\(X\\), residuals should also tend to be close, leading to a positive correlation. For example:\n\nset.seed(840)\nx &lt;- rnorm(1e2)\ny &lt;- x^3 + rnorm(length(x))\nplot(x, y)\nabline(lm(y ~ x))\n\n\n\n\n\n\n\n\nThis, I suspect, is the reason why functions such as lmtest::dwtest() have an order.by argument which precisely allows to sort residuals before performing the test.\nUnfortunately, it turns out that such a method is not only sensitive to functional misspecification, but also to heteroskedasticity - as one can quickly verify by running a simulation using lmtest::dwtest().\nThe overall idea is interesting, and works for homoskedastic noise, but the limitation to constant variance may be a bit too stringent. For this reason I turned to a second method, which also allows to take into account the possibility of heteroskedastic noise."
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#second-attempt-reset-heteroskedastic-consistent-variance-estimates",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#second-attempt-reset-heteroskedastic-consistent-variance-estimates",
    "title": "Testing functional specification in linear regression",
    "section": "Second attempt: RESET + Heteroskedastic Consistent variance estimates",
    "text": "Second attempt: RESET + Heteroskedastic Consistent variance estimates\nThe idea of RESET tests (see ?lmtest::resettest()) is also quite simple: if the linear model is correct, there should be relatively little gain in adding additional non-linear functions of the original covariates to the fit’s formula.\nThe statistical significance of these model adjustments can be tested through a standard \\(Z\\)-test (or \\(F\\)-test, for multiple adjustments at once), with an important catch: the covariance matrix of regression coefficients used in these tests can be chosen to be robust to heteroskedasticity (see Model Misspecification and Linear Sandwiches).\nThe code that follows illustrates this procedure with an example dataset. The following section contains a more in-depth simulation study of the property of the RESET test.\n\nfit_cars &lt;- lm(dist ~ speed, data = cars)\nwith(data = cars, plot(speed, dist))\nabline(fit_cars)\n\n\n\n\n\n\n\n\n\nlmtest::resettest(fit_cars, \n                                    type = \"regressor\", \n                                    power = 2,\n                                    vcov = sandwich::vcovHC\n                                    )\n\n\n    RESET test\n\ndata:  fit_cars\nRESET = 2.32, df1 = 1, df2 = 48, p-value = 0.1344\n\n\nUnfortunately, the output of lmtest::resettest does not include the results of the extended fit, which can be useful to understand the impact of the omitted covariates on the overall model picture (independently of the RESET \\(p\\)-value under the null hypothesis). 2\nIn order to get some insight on the effect of misspecification, we need to manually perform the RESET fit and make the relevant comparisons:\n\nfit_cars_sq &lt;- lm(dist ~ speed + I(speed*speed), data = cars)\nwith(data = cars, plot(speed, dist))\nabline(fit_cars)\nlines(x = cars$speed, y = fitted(fit_cars_sq), col = \"blue\")"
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#reset-hc-vcov-a-simulation-study",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#reset-hc-vcov-a-simulation-study",
    "title": "Testing functional specification in linear regression",
    "section": "RESET + HC vcov: a simulation study",
    "text": "RESET + HC vcov: a simulation study\nWe consider a univariate regression problem, with a regressor \\(X \\sim \\mathcal N (0,1)\\), a and a response \\(Y\\). We will consider three ground truth distributions for \\(Y\\) given \\(X\\):\n\\[\n\\begin{split}\n\\text{T1}:& \\qquad Y=\\frac{1}{5}X+Z\\\\\n\\text{T2}:& \\qquad Y=\\frac{1}{5}X + \\vert X \\vert Z\\\\\n\\text{T3}:& \\qquad Y=\\frac{1}{5}X^3 + Z\n\\end{split}\n\\] where \\(Z\\sim \\mathcal N (0,1)\\) is independent from \\(X\\). We will study, through simulation, the \\(p\\)-value distribution of the RESET test for linear regression based on the model \\(Y = q+m X + \\varepsilon\\), where \\(q\\) and \\(m\\) are unknown coefficients, and \\(\\epsilon\\) is a noise term with unknown variance. It follows that the model is correctly specified with respect to \\(\\text{T1}\\), has functional misspecification with respect to \\(\\text{T3}\\), and potentially noise misspecification3 with respect to \\(\\text{T2}\\), if we model variance as being independent of \\(X\\).\nData will consist of independent samples \\((X_i, Y_i)\\) from the joint distribution of \\(X\\) and \\(Y\\). To facilitate simulation, we define some helpers in the code chunk below.\n\n\nCode\n#' Helper to generate data with prescribed: \n#' * Regressor distribution: `x`\n#' * Response conditional mean: `f`\n#' * Response conditional noise: `eps` \ndgp_fun &lt;- function(x, f, eps) {\n    function(n) {\n        .x &lt;- x(n)\n        data.frame(x = .x, y = f(.x) + eps(.x))\n    }\n}\n\n#' Helper to simulate results of linear regression, with prescribed:\n#' * Data generating process: `dgp`\n#' * Sample size of simulated datasets: `n`\n#' * Summary function (e.g. p-value of RESET test): `summarize_fun`\nlm_simulate &lt;- function(dgp, n, summarize_fun, nsim, simplify) {\n    replicate(nsim, {\n        data &lt;- dgp(n)\n        fit &lt;- lm(y ~ x, data)\n        summarize_fun(fit)\n    }, simplify = simplify)\n} \n\n#' Helper to perform RESET test on a `lm` fit object, and plot the p-value\n#' distribution. The estimator for regression coefficients variance-covariance\n#' matrix can be set through the `vcov` argument.\nreset_pvalue &lt;- function(\n        dgp, n,  # Data generating process params\n        power = 2:3, type = \"regressor\", vcov = sandwich::vcovHC,  # RESET params\n        nsim = 1e3  # Simulation params\n        ) \n{\n    summarize_fun &lt;- function(fit)\n        lmtest::resettest(fit, power = power, type = type, vcov = vcov)$p.value\n    \n    p &lt;- lm_simulate(\n        dgp = dgp, \n        n = n, \n        summarize_fun = summarize_fun, \n        nsim = nsim,\n        simplify = TRUE\n        )\n    \n    return(data.frame(\n        p = p,\n        dgp = deparse(substitute(dgp)),\n        n = n,\n        vcov = deparse(substitute(vcov)),\n        nsim = nsim\n    ))\n    \n}\n\n\nFurthermore, we will use:\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\nfor plotting.\n\nData generating processes\nThe data generating processes can be defined as follows:\n\ndgp_t1 &lt;- dgp_fun(\n    x = rnorm,\n    f = \\(x) 0.2 * x,\n    eps = \\(x) rnorm(length(x))\n)\n\ndgp_t2 &lt;- dgp_fun(\n    x = rnorm,\n    f = \\(x) 0.2 * x,\n    eps = \\(x) abs(x) * rnorm(length(x))\n)\n\ndgp_t3 &lt;- dgp_fun(\n    x = rnorm,\n    f = \\(x) 0.2 * x^3,\n    eps = \\(x) rnorm(length(x))\n)\n\nData generated according to these three distributions looks as follows:\n\n\nCode\nbind_rows(\n    tibble(dgp_t1(100), dgp = \"dgp_t1\"),\n    tibble(dgp_t2(100), dgp = \"dgp_t2\"),\n    tibble(dgp_t3(100), dgp = \"dgp_t3\"),\n    ) |&gt;\n    ggplot(aes(x = x, y = y)) +\n        geom_point() +\n        geom_smooth(method = \"lm\", formula = y ~ x, se = F) +\n        facet_grid(~ dgp)\n\n\n\n\n\n\n\n\n\n\n\nRESET \\(p\\)-value distributions\nThe RESET \\(p\\)-value cumulative distributions for the three ground truths \\(\\text{T1}\\), \\(\\text{T2}\\) and \\(\\text{T3}\\) are shown below 4. The \\(y\\) coordinates of these plots can be interpreted as follows:\n\nFor the ground truths \\(\\text{T1}\\) and \\(\\text{T2}\\), \\(y\\) represents the false positive rate (or Type I Error Rate) in rejecting the null hypothesis “no functional misspecification” at a given size of the test \\(x\\). For a valid \\(p\\)-value, these curves should lie on or below the straight line \\(y = x\\).\nFor the ground truth \\(\\text{T3}\\), \\(y\\) represents the Power (or one minus the Type II Error Rate) in detecting functional misspecification at a given size \\(x\\). High values correspond to high sensitivity.\n\n\n\nCode\nsim_data &lt;- dplyr::bind_rows(\n    reset_pvalue(dgp = dgp_t1, n = 10, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t1, n = 100, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t1, n = 1000, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t1, n = 10000, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t1, n = 10, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t1, n = 100, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t1, n = 1000, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t1, n = 10000, vcov = stats::vcov),\n    \n    reset_pvalue(dgp = dgp_t2, n = 10, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t2, n = 100, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t2, n = 1000, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t2, n = 10000, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t2, n = 10, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t2, n = 100, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t2, n = 1000, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t2, n = 10000, vcov = stats::vcov),\n    \n    reset_pvalue(dgp = dgp_t3, n = 10, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t3, n = 100, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t3, n = 1000, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t3, n = 10000, vcov = sandwich::vcovHC),\n    reset_pvalue(dgp = dgp_t3, n = 10, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t3, n = 100, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t3, n = 1000, vcov = stats::vcov),\n    reset_pvalue(dgp = dgp_t3, n = 10000, vcov = stats::vcov)\n)\n\nsim_data |&gt;\n    mutate(n_label = paste(\"n\", n, sep = \" = \")) |&gt;\n    ggplot(aes(p, color = vcov)) + \n        stat_ecdf() +\n        scale_color_discrete(\"vcov\") + \n        scale_x_continuous(\"p-value\", labels = scales::percent) + \n        scale_y_continuous(\"Empirical CDF\", labels = scales::percent) +\n        geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n        facet_grid(n_label ~ dgp, ) +\n        ggtitle(\n            \"p-value distribution of RESET test\",\n            paste(\"nsim\", max(sim_data$nsim), sep = \" = \")\n            )\n\n\n\n\n\n\n\n\n\nThe plots illustrate qualitatively the behavior of the RESET test with and without the vcov correction for noise heteroskedasticity. Various remarks:\n\nThe test with the standard stats::vcov estimator is sensitive not only to pure functional misspecification (\\(\\text{T3}\\)), but also to pure heteroskedastic noise (\\(\\text{T2}\\)).\nThe sandwich::vcovHC estimator leads to an asymptotically correct Type I Error Rate in the \\(\\text{T2}\\) case, but to a somewhat lower sensitivity (with respect to stats::vcov) in the \\(\\text{T3}\\) case.\nWe need to keep in mind that sandwich::vcovHC only provides asymptotically correct variance-covariance estimates. Thus, for small \\(n\\), the \\(p\\)-value distribution of the RESET test using the sandwich::vcovHC can also be distorted (even in the perfectly specified case \\(\\text{T1}\\))."
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#conclusions",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#conclusions",
    "title": "Testing functional specification in linear regression",
    "section": "Conclusions",
    "text": "Conclusions\nThis post explained how to perform model validation checks that are sensitive to functional misspecification, but relatively robust to heteroskedasticity.\nThe general idea is to extend the original model, allowing for more general functional forms in the conditional mean of the response, and test whether such extension significantly improves the fit. The catch is that, when performing the latter test, we need to somehow keep into account the possibility of heteroskedastic noise.\nThis idea is readily implemented with RESET tests for linear models: one can simply use a variance-covariance estimator for regression coefficients that is robust to heteroskedasticity. In R, this can be achieved with a single line of code, using lmtest::resettest(vcov = sandwich::vcovHC).\nWith some effort, one may be able to generalize such a procedure to any parametric model fitted by Maximum Likelihood Estimation, since a sandwich estimator is available also in this more general case (see e.g. the presentation of sandwich estimators in this paper by D.A. Freedman)."
  },
  {
    "objectID": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#footnotes",
    "href": "posts/2023-07-11-testing-functional-specification-in-linear-regression/testing-functional-misspecification-in-linear-regression.html#footnotes",
    "title": "Testing functional specification in linear regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere I’m implicitly assuming that we have a single \\(X\\), but a similar logic should also apply to multivariate regression.↩︎\nWith enough data, the RESET test would likely test positive for a variety of misspecifications, but that doesn’t mean that such misspecification are necessarily relevant from a modeling perspective. Here, for instance, a large coefficient for \\(\\text{(speed)}^2\\) with a \\(Z\\)-score of two \\(\\sigma\\)s could be more worrying than a minuscule coefficient with a \\(Z\\)-score of five \\(\\sigma\\)s.↩︎\nSometimes also referred to as “second order misspecification”.↩︎\nThe code is a bit unelegant 😬 but it works.↩︎"
  },
  {
    "objectID": "posts/2023-10-31-prefix-free-codes/prefix-free-codes.html",
    "href": "posts/2023-10-31-prefix-free-codes/prefix-free-codes.html",
    "title": "Prefix-free codes",
    "section": "",
    "text": "Let \\(\\mathbb X\\) be a finite alphabet and denote by \\(\\mathbb X ^* = \\coprod _{k = 0} ^{\\infty} \\mathbb X ^k\\) the set of strings of symbols from \\(\\mathbb X\\). A binary code on \\(\\mathbb X\\) is a function \\(f \\colon \\mathbb X \\to \\{0,\\,1\\}^*\\). This is usually extended to a function \\(f^* \\colon \\mathbb X ^* \\to \\{0,\\,1\\}^*\\) as follows:\n\\[\nf^* (x_1 \\,x_2\\,\\cdots x_n) = f(x_1) f(x_2)\\cdots f(x_n)\n\\] A code is said to be:\nFor example: \\[\na \\mapsto 0,\\quad b\\mapsto 00\n\\] is a non-singular but not uniquely decodable code for the alphabet \\(\\mathbb X = \\{a,\\,b\\}\\), while the code:\n\\[\na \\mapsto 0,\\quad b\\mapsto 01\n\\]\nis uniquely decodable, but not prefix-free. Finally, the assignments:\n\\[\na \\mapsto 0, \\quad b \\mapsto 10, \\quad c \\mapsto 110, \\quad d\\mapsto1110,\\quad\\cdots\n\\] show that there exist prefix-free codes for any finite or countable alphabet.\nThe importance of prefix-free codes lies in the fact that they allow for real-time decoding, as soon as the string corresponding to a symbol is received (which is why they are also called “instantaneous codes”) 1. Binary prefix-free codes can also be interpreted as representing sequences of “Yes-No” questions that univocally identify the elements of \\(\\mathbb X\\).\nAn important property satisfied by all uniquely decodable binary codes, and in particular by prefix-free codes, is the Kraft-McMillan inequality:\n\\[\n\\sum _{x\\in \\mathbb X} 2 ^{-L(x)} \\leq 1\n\\] where \\(L (x)\\) is the length of the code for \\(x\\). A converse is also true: for any set of positive integers \\((\\ell _{i})_{1\\leq i\\leq N}\\) satisfying the Kraft-McMillan inequality, there exists a prefix-free code over \\(\\mathbb X = \\{1,\\,2,\\,\\dots,\\,N\\}\\) such that \\(\\ell _i = L(i)\\).\nThis allows to immediately prove the entropy bound for the expected length of uniquely decodable codes. Given a probability distribution \\(p\\) over \\(\\mathbb X\\), we have:\n\\[\n\\begin{split}\n\\mathbb E(L(X))&=\\sum _{x\\in \\mathbb X} p(x) L(x) \\\\\n                             &=-\\sum _{x\\in \\mathbb X} p(x) \\log _2(2^{-L(x)}) \\\\\n                             &=-\\sum _{x\\in \\mathbb X} p(x) \\log _2(p(x))-\\sum _{x\\in \\mathbb X} p(x) \\log _2(\\frac{2^{-L(x)}}{p(x)})\n\\end{split}\n\\] The first term is recognized as the entropy (in bits) of \\(X\\), \\(H_2(X)\\), whereas the second term can be bounded using the Jensen and Kraft-McMillan inequalities:\n\\[\n-\\sum _{x\\in \\mathbb X} p(x) \\log _2(\\frac{2^{-L(x)}}{p(x)}) \\geq -\\log _2\\left(\\sum _{x\\in \\mathbb X} 2^{-L(x)} \\right) \\geq 0.\n\\] We obtain:\n\\[\n\\mathbb E (L(X)) \\geq H_2(X)\n\\]\nFurthermore, noticing that the positive integers \\(\\ell _i = \\lceil \\log _2\\frac{1}{p(x_i)} \\rceil\\) satisfy the Kraft-McMillan inequality, we can immediately construct a prefix-free code (the Shannon-Fano code) for which \\(L(x_i) = \\ell _i\\). For this code:\n\\[\n\\mathbb E (L(X)) \\leq H_2(X) + 1.\n\\]"
  },
  {
    "objectID": "posts/2023-10-31-prefix-free-codes/prefix-free-codes.html#footnotes",
    "href": "posts/2023-10-31-prefix-free-codes/prefix-free-codes.html#footnotes",
    "title": "Prefix-free codes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe decoding algorithm works as follows: given a binary string \\(y_1y_2\\cdots y_M = f^*(x_1 x_2 \\cdots x_N)\\) we start reading the substrings \\(y_1y_2 \\cdots y_k\\) until we find a match with some code \\(s \\in \\text{Im}(f)\\), which is the code of the first symbol \\(x_1\\) of the original sequence. We remove this substring and start reading again, to find the code of the second symbol \\(x_2\\),and so on and so forth. This procedure can obviously be implemented in an online setting.↩︎"
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "",
    "text": "During the last few months, I’ve been working on a machine learning algorithm with applications in Forensic Science, a.k.a. Criminalistics. In this field, one common task for the data analyst is to present the trier-of-fact (the person or people who determine the facts in a legal proceeding) with a numerical assessment of the strength of the evidence provided by available data towards different hypotheses. In more familiar terms, the forensic expert is responsible of computing the likelihoods (or likelihood ratios) of data under competing hypotheses, which are then used by the trier-of-fact to produce Bayesian posterior probabilities for the hypotheses in question1.\nIn relation to this, forensic scientists have developed a bunch of techniques to evaluate the performance of a likelihood ratio model in discriminating between two alternative hypothesis. In particular, I have come across the so called Likelihood Ratio Cost, usually defined as:\n\\[\nC_{\\text{LLR}} = \\frac{1}{2N_1} \\sum _{Y_i=1} \\log(1+r(X_i) ^{-1})+\\frac{1}{2N_0} \\sum _{Y_i=0} \\log(1+r(X_i)),\n\\tag{1}\\] where we assume we have data consisting of \\(N_1+N_0\\) independent identically distributed observations \\((X_i,\\,Y_i)\\), with binary \\(Y\\); \\(N_1\\) and \\(N_0\\) stand for the number of positive (\\(Y=1\\)) and negative (\\(Y=0\\)) cases; and \\(r(X)\\) is a model for the likelihood ratio \\(\\Lambda(X) \\equiv \\frac{\\text{Pr}(X\\vert Y = 1)}{\\text{Pr}(X\\vert Y = 0)}\\).\nThe main reason for writing this note was to understand a bit better what it means to optimize Equation 1, which does not look immediately obvious to me from its definition2. In particular: is the population minimizer of Equation 1 the actual likelihood ratio? And in what sense is a model with lower \\(C_\\text{LLR}\\) better than one with a correspondingly higher value?\nThe short answers to these questions are: yes; and: \\(C_\\text{LLR}\\) optimization seeks for the model with the best predictive performance in a Bayesian inference setting with uninformative prior on \\(Y\\), assuming that this prior actually reflects reality (i.e. \\(\\text{Pr}(Y=1) = \\text{Pr}(Y=0) = \\frac{1}{2}\\)). The mathematical details are given in the rest of the post."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#intro",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#intro",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "",
    "text": "During the last few months, I’ve been working on a machine learning algorithm with applications in Forensic Science, a.k.a. Criminalistics. In this field, one common task for the data analyst is to present the trier-of-fact (the person or people who determine the facts in a legal proceeding) with a numerical assessment of the strength of the evidence provided by available data towards different hypotheses. In more familiar terms, the forensic expert is responsible of computing the likelihoods (or likelihood ratios) of data under competing hypotheses, which are then used by the trier-of-fact to produce Bayesian posterior probabilities for the hypotheses in question1.\nIn relation to this, forensic scientists have developed a bunch of techniques to evaluate the performance of a likelihood ratio model in discriminating between two alternative hypothesis. In particular, I have come across the so called Likelihood Ratio Cost, usually defined as:\n\\[\nC_{\\text{LLR}} = \\frac{1}{2N_1} \\sum _{Y_i=1} \\log(1+r(X_i) ^{-1})+\\frac{1}{2N_0} \\sum _{Y_i=0} \\log(1+r(X_i)),\n\\tag{1}\\] where we assume we have data consisting of \\(N_1+N_0\\) independent identically distributed observations \\((X_i,\\,Y_i)\\), with binary \\(Y\\); \\(N_1\\) and \\(N_0\\) stand for the number of positive (\\(Y=1\\)) and negative (\\(Y=0\\)) cases; and \\(r(X)\\) is a model for the likelihood ratio \\(\\Lambda(X) \\equiv \\frac{\\text{Pr}(X\\vert Y = 1)}{\\text{Pr}(X\\vert Y = 0)}\\).\nThe main reason for writing this note was to understand a bit better what it means to optimize Equation 1, which does not look immediately obvious to me from its definition2. In particular: is the population minimizer of Equation 1 the actual likelihood ratio? And in what sense is a model with lower \\(C_\\text{LLR}\\) better than one with a correspondingly higher value?\nThe short answers to these questions are: yes; and: \\(C_\\text{LLR}\\) optimization seeks for the model with the best predictive performance in a Bayesian inference setting with uninformative prior on \\(Y\\), assuming that this prior actually reflects reality (i.e. \\(\\text{Pr}(Y=1) = \\text{Pr}(Y=0) = \\frac{1}{2}\\)). The mathematical details are given in the rest of the post."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#cross-entropy-with-random-weights",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#cross-entropy-with-random-weights",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "Cross-entropy with random weights",
    "text": "Cross-entropy with random weights\nWe start with a mathematical digression, which will turn out useful for further developments. Let \\(\\{(X_i,\\,Y_i)\\}_{i=1,\\,2,\\,\\dots,N}\\) be independent draws from a joint distribution, with binary \\(Y_i \\in \\{0,\\,1\\}\\). Given a function \\(w=w(\\boldsymbol Y)\\) that is symmetric in its arguments3, we define the random functional:\n\\[\n\\mathcal L_N^w[f] = -\\frac{1}{N}\\sum_{i=1} ^N \\left[w(\\boldsymbol Y)Y_i \\log(f(X_i))+ w({\\boldsymbol Y}^c)( Y_i^c) \\log(f(X_i)^c)\\right],\n\\tag{2}\\]\nwhere \\(f=f(X)\\) is any function satisfying \\(f(X)\\in [0,\\,1]\\) for all \\(X\\), and we let \\(q^c = 1-q\\) for any number \\(q \\in [0,\\,1]\\). Notice that for \\(w(\\boldsymbol{Y}) \\equiv 1\\), this is just the usual cross-entropy loss.\nWe now look for the population minimizer of Equation 2, i.e. the function \\(f_*\\) that minimizes the functional \\(f \\mapsto \\mathbb E(\\mathcal L _N ^w [f])\\)4. Writing the expectation as:\n\\[\n\\mathbb E(\\mathcal L _N ^w [f]) = -\\frac{1}{N}\\sum _{i=1} ^N \\mathbb E\\left[ \\mathbb E(Y_i\\cdot w(\\boldsymbol Y)\\vert X_i)\\cdot \\log(f(X_i))+E(Y_i^c\\cdot w(\\boldsymbol Y ^c)\\vert X_i)\\cdot \\log(f^c(X_i))\\right],\n\\] we can easily see that \\(\\mathbb E(\\mathcal L _N ^w [f])\\) is a convex functional with a unique minimum given by:\n\\[\nf_*(X_i) = \\frac{1}{1+r(X_i)^{-1}},\\quad r_*(X_i) = \\dfrac{E(Y_i\\cdot w(\\boldsymbol Y)\\vert X_i)}{E(Y_i^c\\cdot w(\\boldsymbol Y^c)\\vert X_i)}.\n\\tag{3}\\]\nThe corresponding expected loss is:\n\\[\n\\mathbb E(\\mathcal L _N ^w [f_*]) = \\mathbb E\\left[ \\mathbb E(Y_i\\cdot w(\\boldsymbol Y) + Y_i^c\\cdot w(\\boldsymbol Y^c)\\vert X_i)\\cdot \\mathcal H(f_*(X_i))\\right],\n\\] where \\(\\mathcal H(p) = -p \\log (p) -(1-p) \\log(1-p)\\) is the entropy of a binary random variable \\(Z\\) with probability \\(p = \\text{Pr}(Z=1)\\) (the index \\(i\\) in the previous expression can be any index, since data points are assumed to be identically distributed).\nBefore looking at values of \\(f\\) other than \\(f_*\\), we observe that the previous expectation can be succintly expressed as:\n\\[\n\\mathbb E(\\mathcal L _N ^w [f_*]) = k \\cdot H^\\prime(Y\\vert X),\n\\]\nwhere\n\\[\nk = \\mathbb E(Y_i\\cdot w(\\boldsymbol Y) + Y_i^c\\cdot w(\\boldsymbol Y^c))\n\\tag{4}\\]\nand \\(H'(Y\\vert X)\\) is the conditional entropy of \\(Y\\vert X\\) with respect to a different probability measure \\(\\text{Pr}^\\prime\\), defined by:\n\\[\n\\text{Pr}^\\prime(E) = t \\cdot \\text {Pr}(E \\vert Y = 1) + (1-t)\\cdot \\text {Pr}(E \\vert Y = 0),\n\\tag{5}\\]\nwhere \\(t=\\text{Pr}^\\prime(Y=1)\\in [0,\\,1]\\) is fixed by the requirement5:\n\\[\n\\dfrac{\\text {Pr}^\\prime (Y=1)}{\\text{Pr}^\\prime (Y=0)}=\\dfrac{\\text {Pr} (Y=1)}{\\text{Pr} (Y=0)}\\cdot\\dfrac{\\mathbb E(w(\\boldsymbol Y)\\vert \\sum _i Y_i &gt;0)}{\\mathbb E(w(\\boldsymbol Y^c)\\vert \\sum _i Y_i^c &gt;0)}.\n\\tag{6}\\]\nIn terms of \\(\\text{Pr}^\\prime\\), the population minimizers \\(f_*\\) and \\(r_*\\) in Equation 3 can be simply expressed as:\n\\[\nr_*(X)=\\dfrac{\\text {Pr}^\\prime(Y=1\\vert X)}{\\text {Pr}^\\prime(Y=0\\vert X)},\\qquad f_*(X)=\\text {Pr}^\\prime(Y=1\\vert X).\n\\tag{7}\\]\nIf now \\(f\\) is an arbitrary function, we have:\n\\[\n\\begin{split}\n\\mathbb E(\\mathcal L _N ^w [f]) - \\mathbb E(\\mathcal L _N ^w [f_*]) &= \\mathbb E\\left[ \\mathbb E(Y_i\\cdot w(\\boldsymbol Y) + Y_i^c\\cdot w(\\boldsymbol Y^c)\\vert X_i)\\cdot \\mathcal D(f_*(X_i)\\vert \\vert f(X_i))\\right]\n&= k\\cdot D(\\text{Pr}^\\prime\\vert \\vert \\text{Pr}^\\prime _f)\n\\end{split}\n\\] where \\(\\mathcal D(p\\vert \\vert q) = p \\log (\\frac{p}{q}) + (1-p) \\log (\\frac{1-p}{1-q})\\), and \\(D(\\text{Pr}^\\prime\\vert \\vert \\text{Pr}^\\prime _f)\\) is the Kullback-Liebler divergence between the measure \\(\\text{Pr}^\\prime\\) and the measure \\(\\text{Pr}^\\prime _f\\) defined by:\n\\[\n\\text{Pr}^\\prime _f(Y = 1\\vert X)=f(X),\\qquad \\text{Pr}^\\prime _f(X)=\\text{Pr}^\\prime(X)\n\\] (notice that \\(\\text {Pr} ^{\\prime} _{f_*} \\equiv \\text{Pr} ^{\\prime}\\) by definition). Finally, suppose that \\(X = g(\\widetilde X)\\) for some random variable \\(\\widetilde X\\), and define the corresponding functional:\n\\[\n\\widetilde{\\mathcal L} _N^w[\\widetilde f]  = -\\frac{1}{N}\\sum_{i=1} ^N \\left[w(\\boldsymbol Y)Y_i \\log(\\widetilde f(\\widetilde X))+ w({\\boldsymbol Y}^c)( Y_i^c) \\log(\\widetilde f(\\widetilde X)^c)\\right].\n\\] Then \\(\\mathcal L _N ^w [f] = \\widetilde{\\mathcal L} _N^w[f \\circ g]\\). If \\(\\widetilde f  _* =\\) is the population minimizer of \\(\\widetilde{\\mathcal L} _N^w\\), it follows that \\(\\mathbb E (\\widetilde{\\mathcal L} _N^w[\\widetilde f _*]) \\leq \\mathbb E(\\mathcal L _N ^w [f_*])\\).\nPutting everything together, we can decompose the expected loss for a function \\(f=f(X)\\), where \\(X= g(\\widetilde X)\\), in the following suggestive way:\n\\[\n\\begin{split}\n\\mathbb E(\\mathcal L _N ^w [f]) &= (L_N ^w)_\\text{min}+(L_N ^w)_\\text{proc} +(L_N ^w)_\\text{missp},\\\\\n(L_N ^w)_\\text{min}&\\equiv\\mathbb E(\\widetilde{\\mathcal L} _N^w[{\\widetilde f} _*])  \\\\ &=\n\\mathbb E\\left[ \\mathbb E(Y_i\\cdot w(\\boldsymbol Y) + Y_i^c\\cdot w(\\boldsymbol Y^c)\\vert \\widetilde X _i)\\cdot \\mathcal H({\\widetilde f} _*(\\widetilde X _i))\\right]\\\\\n&=k\\cdot H^\\prime(Y\\vert \\widetilde X),\\\\\n(L_N ^w)_\\text{proc}&\\equiv\\mathbb E(\\mathcal L _N ^w [f_*]-\\widetilde{\\mathcal L} _N^w[\\phi_*])  \\\\& =\n\\mathbb E\\left[ \\mathbb E(Y_i\\cdot w(\\boldsymbol Y) + Y_i^c\\cdot w(\\boldsymbol Y^c)\\vert X_i)\\cdot  \\mathcal H(f_*(X_i))\n\\right]- (L_N ^w)_\\text{min}\\\\\n& = k\\cdot I^\\prime(Y; \\widetilde X\\vert X),\\\\\n(L_N ^w)_\\text{missp} & \\equiv \\mathbb E(\\mathcal L _N ^w [f]) - \\mathbb E(\\mathcal L _N ^w [f_*]) \\\\&= \\mathbb E\\left[ \\mathbb E(Y_i\\cdot w(\\boldsymbol Y) + Y_i^c\\cdot w(\\boldsymbol Y^c)\\vert X_i)\\cdot  \\mathcal  D(f_*(X_i)\\vert \\vert f(X_i))\\right]\\\\ &=k\\cdot D(\\text {Pr}^\\prime\\vert \\vert \\text {Pr}^\\prime _f),\n\\end{split}\n\\tag{8}\\]\nwhere \\(k\\) is defined in Equation 4. In the equation for \\((L^w _N)_\\text{proc}\\) we introduced the conditional mutual information (with respect to the measure \\(\\text{Pr}^\\prime\\)), that satisfies [Cover and Thomas (2006)]:\n\\[\nI(\\widetilde X;Y\\vert X) = I(\\widetilde X,Y)-I(X,Y) = H(Y\\vert X)-H(Y\\vert \\widetilde X).\n\\]\nThe three components in Equation 8 can be interpreted as follows: \\((L_N ^w)_\\text{min}\\) represents the minimum expected loss achievable, given the data available \\(\\widetilde X\\); \\((L_N ^w)_\\text{proc}\\) accounts for the information lost in the processing transformation \\(X=g(\\widetilde X)\\); finally \\((L_N ^w)_\\text{missp}\\) is due to misspecification, i.e. the fact that the model \\(f(X)\\) for the true posterior probability \\(f_*(X)\\) is an approximation.\nAll the information-theoretic quantities (and their corresponding operative interpretations hinted in the previous paragraph) make reference to the measure \\(\\text{Pr}^\\prime\\) defined by Equation 5 and Equation 6. This is merely the result of altering the proportion of positive (\\(Y=1\\)) and negative (\\(Y=0\\)) examples in the \\(X\\)-\\(Y\\) joint distribution by a factor dictated by the weight function \\(w\\) - while keeping conditional distributions such as \\(X\\vert Y\\) unchanged."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#a-familiar-case-cross-entropy-loss",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#a-familiar-case-cross-entropy-loss",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "A familiar case: cross-entropy loss",
    "text": "A familiar case: cross-entropy loss\nFor \\(w(\\boldsymbol {Y}) = 1\\), the functional \\(\\mathcal {L} _{N} ^{w}[f]\\) coincides with the usual cross-entropy loss6:\n\\[\n\\text{CE}[f] = -\\frac{1}{N}\\sum_{i=1} ^N \\left[Y_i \\log(f(X_i))+ (1-Y_i) \\log(1-f(X_i))\\right].\n\\tag{9}\\]\nFrom Equation 6 we see that the measure \\(\\text{Pr}^{\\prime}\\) coincides with the original \\(\\text{Pr}\\), so that by Equation 3 the population minimizer of Equation 9 is \\(f_{*}(X) = \\text{Pr}(Y=1\\vert X)\\) (independently of sample size). Since \\(k = 1\\) (cf. Equation 4), the decomposition Equation 8 reads:\n\\[\n\\begin{split}\n\\mathbb E(\\text{CE} [f]) &= (\\text{CE})_\\text{min}+(\\text{CE})_\\text{proc} +(\\text{CE})_\\text{missp},\\\\\n(\\text{CE})_\\text{min}&=H(Y\\vert \\widetilde X),\\\\\n(\\text{CE})_\\text{proc}&= I(Y; \\widetilde X\\vert X),\\\\\n(\\text{CE})_\\text{missp} &=D(\\text {Pr}\\vert \\vert \\text {Pr} _{f}),\n\\end{split}\n\\tag{10}\\]\nwhere conditional entropy \\(H\\), mutual information \\(I\\) and relative entropy \\(D\\) now simply refer to the original measure \\(\\text{Pr}\\)."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#the-likelihood-ratio-cost",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#the-likelihood-ratio-cost",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "The Likelihood Ratio Cost",
    "text": "The Likelihood Ratio Cost\nThe quantity \\(C_{\\text{LLR}}\\) defined in Equation 1 can be put in the general form Equation 2, if we let \\(f(X) = (1+r(X)^{-1})^{-1}\\) and7:\n\\[\nw(\\boldsymbol Y) = \\left(\\dfrac{2}{N}\\sum _{i = 1}^{N}Y_j \\right)^{-1}\n\\] In what follows, I will consider a slight modification of the usual \\(C_\\text{LLR}\\), defined by the weight function:\n\\[\nw(\\boldsymbol Y) = \\dfrac{1}{2(N-1)}\\sum _{i = 1}^{N}(1-Y_j).\n\\] This yields Equation 1 multiplied by \\(\\dfrac{N_1N_0}{N(N-1)}\\), which I will keep denoting as \\(C_\\text{LLR}\\), with a slight abuse of notation.\nWe can easily compute8:\n\\[\n\\dfrac{\\text {Pr}^\\prime (Y=1)}{\\text{Pr}^\\prime (Y=0)}=1,\n\\tag{11}\\]\nso that, by Equation 3, the population minimizer of \\(C_\\text{LLR}\\) is:\n\\[\nr_*(X) = \\Lambda (X),\\quad f_*(X)=\\dfrac{1}{1+\\Lambda(X)^{-1}},\n\\]\nwhere \\(\\Lambda(X)\\) denotes the likelihood-ratio of \\(X\\), schematically:\n\\[\n\\Lambda(X)\\equiv \\dfrac{\\text{Pr}(X\\vert Y = 1)}{\\text{Pr}(X\\vert Y = 0)}.\n\\]\nThe constant \\(k\\) in Equation 4 is:\n\\[\nk = \\text{Pr}(Y = 1)\\text{Pr}(Y = 0)=\\text{Var}(Y)\n\\]\nThe general decomposition Equation 8 becomes: \\[\n\\begin{split}\n\\mathbb E(C_\\text{LLR} [f]) &= (C_\\text{LLR})_\\text{min}+(C_\\text{LLR})_\\text{proc} +(C_\\text{LLR})_\\text{missp},\\\\\n(C_\\text{LLR})_\\text{min}&=\\text{Var}(Y)\\cdot H^{\\prime}(Y\\vert \\widetilde X),\\\\\n(C_\\text{LLR})_\\text{proc}&= \\text{Var}(Y)\\cdot I^{\\prime}(Y; \\widetilde X\\vert X),\\\\\n(C_\\text{LLR})_\\text{missp} &=\\text{Var}(Y)\\cdot D^{\\prime}(\\text {Pr}\\vert \\vert \\text {Pr} _{f}),\n\\end{split}\n\\tag{12}\\]\nwhere \\(\\text{Pr}^\\prime\\) is now given by Equation 11."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#discussion",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#discussion",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "Discussion",
    "text": "Discussion\nThe table below provides a comparison between cross-entropy and likelihood-ratio cost, summarizing the results from previous sections.\n\n\n\n\n\n\n\n\n\nCross-entropy\nLikelihood Ratio Cost\n\n\n\n\n\\(f_*(X)\\)\n\\(\\text{Pr}(Y = 1\\vert X)\\)\n\\((1+\\Lambda(X)^{-1})^{-1}\\)\n\n\n\\(r_*(X)\\)`\nPosterior odds ratio\nLikelihood ratio\n\n\nMinimum Loss\n\\(H(Y\\vert \\widetilde X)\\)\n\\(\\text{Var}(Y) \\cdot H^\\prime(Y\\vert \\widetilde X)\\)\n\n\nProcessing Loss\n\\(I(Y; \\widetilde X\\vert X)\\)\n\\(\\text{Var}(Y) \\cdot I^\\prime(Y; \\widetilde X\\vert X)\\)\n\n\nMisspecification Loss\n\\(D(f_*\\vert\\vert f)\\)\n\\(\\text{Var}(Y) \\cdot D^\\prime(f_*\\vert\\vert f)\\)\n\n\nReference measure\n\\(\\text{Pr}\\)\n\\(\\text{Pr}^{\\prime} = \\frac{\\text{Pr}(\\cdot \\vert Y = 1)+\\text{Pr}(\\cdot \\vert Y = 0)}{2}\\)\n\n\n\nThe objective of \\(C_\\text{LLR}\\) is found to be the likelihood ratio, as terminology suggests. The interpretation of model selection according to \\(C_\\text{LLR}\\) minimization turns out to be slightly more involved, compared to cross-entropy, which we first review.\nSuppose we are given a set of predictive models \\(\\{\\mathcal M_i\\}_{i\\in I}\\), each of which consists of a processing transformation, \\(\\widetilde X \\mapsto X\\), and an estimate of the posterior probability \\(\\text{Pr}(Y = 1\\vert X)\\). When the sample size \\(N \\to \\infty\\), cross-entropy minimization will almost certainly select the model that minimizes \\(I(Y; \\widetilde X\\vert X) + D(f_*\\vert \\vert f)\\). Following standard Information Theory arguments, we can interpret this model as the statistically optimal compression algorithm for \\(Y\\), assuming \\(X\\) to be available at both the encoding and decoding ends.\nThe previous argument carries over mutatis mutandi to \\(C_\\text{LLR}\\) minimization, with an important qualification: optimal average compression is now achieved for data distributed according to a different probability measure \\(\\text{Pr}'(\\cdot) = \\frac{1}{2}\\text {Pr}(\\cdot\\vert Y = 1) + \\frac{1}{2}\\text {Pr}(\\cdot\\vert Y = 0)\\). In particular, according to \\(\\text{Pr}'\\), the likelihood ratio coincides with the posterior odds ratio, and \\((1+\\Lambda(X)^{-1})^{-1}\\) coincides with posterior probability, which clarifies why we can measure differences from the true likelihood-ratio through the Kullback-Liebler divergence.\nThe measure \\(\\text{Pr}'\\) is not just an abstruse mathematical construct: it is the result of balanced sampling from the original distribution, i.e. taking an equal number of positive and negative cases9. If the \\((X,\\,Y)\\) distribution is already balanced, either by design or because of some underlying symmetry in the data generating process, our analysis implies that likelihood-ratio cost and cross-entropy minimization are essentially equivalent for \\(N\\to \\infty\\). In general, with \\(\\text{Pr} (Y=1) \\neq \\text{Pr} (Y=0)\\), this is not the case10.\nThe fact that \\(C_\\text{LLR}\\) seeks for optimal predictors according to the balanced measure \\(\\text{Pr}'\\) is, one could argue, not completely crazy from the point of view of forensic science, where “\\(Y\\in\\{0,1\\}\\)” often stands for a sort verdict (guilty vs. not guilty, say). Indeed, optimizing with respect to \\(\\text{Pr}^\\prime\\) means that our predictions are designed to be optimal in a world in which the verdict could be a priori \\(Y=0\\) or \\(Y=1\\) with equal probability - which is what an unbiased trier-of-fact should ideally assume. Minimizing \\(C_\\text{LLR}\\), we guard ourselves against any bias that may be implicit in the training dataset, extraneous to the \\(X\\)-\\(Y\\) relation and not explicitly modeled, a feature that may be regarded as desirable from a legal standpoint."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#simulated-example",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#simulated-example",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "Simulated example",
    "text": "Simulated example\nIn general, the posterior odd ratio and likelihood ratio differ only by a constant, so it is reasonable to try to fit the same functional form to both of them. Let us illustrate with a simulated example of this type the differences between cross-entropy and \\(C_{\\text{LLR}}\\) optimization mentioned in the previous Section.\nSuppose that \\(X \\in \\mathbb R\\) has conditional density: \\[\n\\phi(X\\vert Y) = (2\\pi\\sigma _Y^2)^{-\\frac{1}{2}} \\exp(-\\frac{(X-\\mu_Y)^2}{2\\sigma _Y^2})\n\\] and \\(Y\\) has marginal probability \\(\\text{Pr}(Y = 1) = \\pi\\). The true likelihood-ratio and posterior odds ratio are respectively given by:\n\\[\n\\begin{split}\n\\Lambda (X) &\n    \\equiv \\frac{\\phi(X\\vert Y=1)}{\\phi(X\\vert Y=0)}\n    = e ^ {a X^2 + bX +c},\\\\\n\\rho (X) &\n    \\equiv \\frac{\\text{Pr}(Y = 1\\vert X)}{\\text{Pr}(Y = 0\\vert X)}\n    = e ^ {a X ^ 2 + bX +c+d},\n\\end{split}\n\\] where we have defined:\n\\[\na  \\equiv \\dfrac{\\sigma _1 ^2 -\\sigma_0 ^2}{2\\sigma _0 ^2\\sigma_1 ^2},\\quad\nb  \\equiv \\mu _1 - \\mu _0, \\quad\nc  \\equiv \\dfrac{\\mu_0^2}{2\\sigma_0^2} -\\dfrac{\\mu_1 ^2}{2\\sigma _1^2}+\\ln(\\frac{\\sigma _0 }{\\sigma _1 }),\\quad\nd  \\equiv \\ln (\\frac {\\pi}{1-\\pi}) .\n\\]\nSuppose that we fit an exponential function \\(r(X)=e^{mX +q}\\) to \\(\\Lambda(X)\\) by likelihood-ratio cost minimization, and similarly \\(r'(X)=e^{m'X+q'}\\) to \\(\\rho(X)\\) by cross-entropy minimization11. Due to the previous discussion, one could reasonably expect the results of the two procedure to differ in some way, which is demonstrated below by simulation.\nThe chunk of R code below defines the function and data used for the simulation. In particular, I’m considering a heavily unbalanced case (\\(\\text{Pr}(Y = 1) = 0.1\\%\\)) in which negative cases give rise to a sharply localized \\(X\\) peak around \\(X=0\\) (\\(\\mu _0 = 0\\), \\(\\sigma_0 = .25\\)), while the few positive cases give rise to a broader signal centered at \\(X=1\\) (\\(\\mu _1 = 1\\), \\(\\sigma _1 = 1\\)).\n\n# Tidyverse facilities for plotting\nlibrary(dplyr)\nlibrary(ggplot2) \n\n# Loss functions\nweighted_loss &lt;- function(par, data, w) {\n    m &lt;- par[[1]]\n    q &lt;- par[[2]]\n    x &lt;- data$x\n    y &lt;- data$y\n    \n    z &lt;- m * x + q\n    p &lt;- 1 / (1 + exp(-z))\n    \n    -mean(y * w(y) * log(p) + (1-y) * w(1-y) * log(1-p))\n}\n\ncross_entropy &lt;- function(par, data) \n    weighted_loss(par, data, w = \\(y) 1)\n\ncllr &lt;- function(par, data) \n    weighted_loss(par, data, w = \\(y) mean(1-y))\n\n\n# Data generating process\nrxy &lt;- function(n, pi = .001, mu1 = 1, mu0 = 0, sd1 = 1, sd0 = 0.25) { \n    y &lt;- runif(n) &lt; pi\n    x &lt;- rnorm(n, mean = y * mu1 + (1-y) * mu0, sd = y * sd1 + (1-y) * sd0)\n    data.frame(x = x, y = y)\n}\npi &lt;- formals(rxy)$pi\n\n\n# Simulation\nset.seed(840)\ndata &lt;- rxy(n = 1e6)\npar_cllr &lt;- optim(c(1,0), cllr, data = data)$par\npar_cross_entropy &lt;- optim(c(1,0), cross_entropy, data = data)$par\npar_cross_entropy[2] &lt;- par_cross_entropy[2] - log(pi / (1-pi))\n\n\n# Helpers to extract LLRs from models\nllr &lt;- function(x, par)\n    par[1] * x + par[2] \n\nllr_true &lt;- function(x) {\n    mu1 &lt;- formals(rxy)$mu1 \n    mu0 &lt;- formals(rxy)$mu0 \n    sd1 &lt;- formals(rxy)$sd1\n    sd0 &lt;- formals(rxy)$sd0\n        \n    a &lt;- 0.5 * (sd1 ^2 - sd0 ^2) / (sd1 ^2 * sd0 ^2)\n    b &lt;- mu1 / (sd1^2) - mu0 / (sd0^2)\n    c &lt;- 0.5 * (mu0^2 / (sd0^2) - mu1^2 / (sd1^2)) + log(sd0 / sd1)\n    a * x * x + b * x + c\n}\n\nSo, what do our best estimates look like? The plot below shows the best fit lines for the log-likelihood ratio from \\(C_{\\text{LLR}}\\) minimization (in solid red) and cross-entropy minimization (in solid blue). The true log-likelihood ratio parabola is the black line. Also shown are the \\(\\text{LLR}=0\\) line (in dashed red) and the \\(\\text{LLR}=\\ln(\\frac{1-\\pi}{\\pi})\\) (in dashed blue), which are the appropriate Bayes thresholds for classifying a data point as positive (\\(Y=1\\)), assuming data comes from a balanced and unbalanced distribution, respectively.\n\nggplot() + \n    geom_function(fun = \\(x) llr(x, par_cllr), color = \"red\") + \n    geom_function(fun = \\(x) llr(x, par_cross_entropy), color = \"blue\") +\n    geom_function(fun = \\(x) llr_true(x), color = \"black\") +\n    geom_hline(aes(yintercept = 0), linetype = \"dashed\", color = \"red\") +\n        geom_hline(aes(yintercept = -log(pi / (1-pi))), \n                             linetype = \"dashed\", color = \"blue\") +\n        ylim(c(-10,10)) + xlim(c(-1, 2)) +\n    xlab(\"X\") + ylab(\"Log-Likelihood Ratio\")\n\n\n\n\n\n\n\n\nThe reason why the lines differ is that they are designed to solve a different predictive problem: as we’ve argued above, minimizing \\(C_\\text{LLR}\\) looks for the best \\(Y\\vert X\\) conditional probability estimate according to the balanced measure \\(\\text{Pr}'\\), whereas cross-entropy minimization does the same for the original measure \\(\\text{Pr}\\). This is how data looks like under the two measures (the histograms are stacked - in the unbalanced case, positive examples are invisible on the linear scale of the plot):\n\ntest_data &lt;- bind_rows(\n    rxy(n = 1e6, pi = 0.5) |&gt; mutate(type = \"Balanced\", llr_thresh = 0),\n    rxy(n = 1e6) |&gt; mutate(type = \"Unbalanced\", llr_thresh = -log(pi / (1-pi)))\n    )\n\ntest_data |&gt; \n    ggplot(aes(x = x, fill = y)) + \n    geom_histogram(bins = 100) +\n    facet_grid(type ~ ., scales = \"free_y\") +\n    xlim(c(-2, 4))\n\n\n\n\n\n\n\n\nThese differences are reflected in the misclassification rates of the resulting classifiers defined by \\(\\hat Y(X)=I(\\text{LLR}(X)&gt;\\text{threshold})\\), where the appropriate threshold is zero in the balanced case, and \\(\\ln(\\frac{1-\\pi}{\\pi})\\) in the unbalanced case. According to intuition, we see that the \\(C_\\text{LLR}\\) optimizer beats the cross-entropy optimizer on the balanced sample, while performing significantly worse on the unbalanced one.\n\ntest_data |&gt;\n    mutate(\n        llr_cllr = llr(x, par_cllr),\n        llr_cross_entropy = llr(x, par_cross_entropy),\n        llr_true = llr_true(x)\n        ) |&gt;\n    group_by(type) |&gt;\n    summarise(\n        cllr = 1 - mean((llr_cllr &gt; llr_thresh) == y),\n        cross_entropy = 1 - mean((llr_cross_entropy &gt; llr_thresh) == y),\n        true_llr = 1 - mean((llr_true &gt; llr_thresh) == y)\n        )\n\n# A tibble: 2 × 4\n  type           cllr cross_entropy true_llr\n  &lt;chr&gt;         &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n1 Balanced   0.166         0.185    0.140   \n2 Unbalanced 0.000994      0.000637 0.000518"
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#final-remarks",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#final-remarks",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "Final remarks",
    "text": "Final remarks\nOur main conclusion in a nutshell is that \\(C_\\text{LLR}\\) minimization is equivalent, in the infinite sample limit, to cross-entropy minimization on a balanced version of the original distribution. We haven’t discussed what happens for finite samples where variance starts to play a role, affecting the efficiency of loss functions as model optimization and selection criteria. For instance, for a well specified model of likelihood ratio, how do the convergence properties of \\(C_{\\text{LLR}}\\) and cross-entropy estimators compare to each other? I expect that answering questions like this would require a much more in-depth study than the one performed here (likely, with simulation playing a central role)."
  },
  {
    "objectID": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#footnotes",
    "href": "posts/2023-11-15-interpreting-the-likelihood-ratio-cost/interpreting-the-likelihood-ratio-cost.html#footnotes",
    "title": "Interpreting the Likelihood Ratio cost",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is how I understood things should theoretically work, from discussions with friends who are actually working on this field. I have no idea on how much day-to-day practice comes close to this mathematical ideal, and whether there exist alternative frameworks to the one I have just described.↩︎\nThe Likelihood Ratio Cost was introduced in (Brümmer and du Preez 2006). The reference looks very complete, but I find its notation and terminology so unfamiliar that I decided to do my own investigation and leave this reading for a second moment.↩︎\nThat is to say, \\(w(Y_{\\sigma(1)},\\,Y_{\\sigma(2)},\\dots,\\,Y_{\\sigma(N)})=w(Y_1,\\,Y_2,\\dots,\\,Y_N)\\) for any permutation \\(\\sigma\\) of the set \\(\\{1,\\,2,\\,\\dots,\\,N\\}\\).↩︎\nNota bene: the function \\(f\\) is here assumed to be fixed, whereas the randomness in the quantity \\(L _N ^w [f]\\) only comes from the paired observations \\(\\{(X_i,\\,Y_i)\\}_{i=1,\\,2,\\,\\dots,N}\\).↩︎\nNotice that, due to symmetry \\(\\mathbb E(w(\\boldsymbol Y)\\vert \\sum _i Y_i &gt;0) = \\mathbb E(w(\\boldsymbol Y)\\vert Y_1 = 1)\\), which might be easier to compute.↩︎\nHere and below I relax a bit the notation, as most details should be clear from context.↩︎\nThe quantity \\(w(\\boldsymbol Y)\\) is not defined when all \\(Y_i\\)’s are zero, as the right-hand side of Equation 1 itself. In this case, we make the convention \\(w(\\boldsymbol Y) = 0\\).↩︎\nFor the original loss in Equation 1, without the modification discussed above, the result would have been \\(\\dfrac{\\text {Pr}^\\prime (Y=1)}{\\text{Pr}^\\prime (Y=0)}=\\dfrac{1-\\text {Pr}(Y=0)^N}{1-\\text {Pr}(Y=1)^N}.\\)↩︎\nFormally, given an i.i.d. stochastic process \\(Z_i = (X_i,\\,Y_i)\\), we can define a new stochastic process \\(Z_i ^\\prime = (X_i^\\prime,\\,Y_i^\\prime)\\) such that \\(Z_i ^\\prime = Z_{2i - 1}\\) if \\(Y_{2i-1}\\neq Y_{2i}\\), and \\(Z_i ^\\prime = \\perp\\) (not defined) otherwise. Discarding \\(\\perp\\) values, we obtain an i.i.d. stochastic process whose individual observations are distributed according to \\(\\text{Pr}^\\prime\\).↩︎\nThere is another case in which \\(C_{\\text{LLR}}\\) and cross-entropy minimization converge to the same answer as \\(N\\to \\infty\\): when used for model selection among a class of models for the likelihood or posterior odds ratio that contains their correct functional form.↩︎\nThis is just logistic regression. It could be a reasonable approximation if \\(\\sigma_0 ^2\\approx \\sigma_1 ^2\\), which however I will assume below to be badly violated.↩︎"
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html",
    "title": "Gravity waves in an ideal fluid",
    "section": "",
    "text": "We compare two derivations of the stability conditions for hydrostatic equilibrium of an ideal fluid:\n\nA “parcel” argument, that follows the motion of a small particle of fluid, ignoring the dynamics of the surroundings.\nStandard linearization of the ideal fluid equations.\n\nThe two derivations turn out to give the same answer, but the intermediate steps in the parcel argument contain some hidden assumptions, which are clarified in the second approach."
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#intro",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#intro",
    "title": "Gravity waves in an ideal fluid",
    "section": "",
    "text": "We compare two derivations of the stability conditions for hydrostatic equilibrium of an ideal fluid:\n\nA “parcel” argument, that follows the motion of a small particle of fluid, ignoring the dynamics of the surroundings.\nStandard linearization of the ideal fluid equations.\n\nThe two derivations turn out to give the same answer, but the intermediate steps in the parcel argument contain some hidden assumptions, which are clarified in the second approach."
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#the-parcel-method",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#the-parcel-method",
    "title": "Gravity waves in an ideal fluid",
    "section": "The parcel method",
    "text": "The parcel method\nWe start with a fluid at rest in a constant gravitational field \\(\\mathbf g = -g\\hat {\\mathbf z}\\), and consider a small portion of fluid initially located at height \\(z_0\\). We imagine that this parcel is now vertically displaced to height \\(z_1 = z_0 + \\delta z\\), and that no heat is transferred between the parcel and the surroundings during this process. We further assume that the pressure inside the parcel rapidly equalizes with the pressure outside of it (on a time scale much shorter than the one involved in the displacement). Finally, we assume that the whole process does not appreciably alter the pressure field \\(p\\) with respect to its equilibrium configuration, satisfying \\(\\frac{\\text d p}{\\text d z}= -\\rho g\\), where \\(\\rho\\) is the fluid’s density at rest. To anticipate, in the second derivation below, we will see that the last assumption may actually fail, giving rise to different dynamics than the one discussed in these Section.\nThe derivation below follows (Landau and Lifshitz 2013). The parcel’s acceleration in the vertical direction is given by Newton’s second law:\n\\[\n\\rho _\\text{p}\\ddot {\\delta z}=-\\rho _\\text{p}g-\\frac{\\text{d}p}{\\text{d}z}=-(\\rho _\\text{p}-\\rho)g,\n\\tag{1}\\]\nwhere the equilibrium assumption was used in the second equality, where \\(\\rho _\\text{p}\\) is the parcel’s density, while \\(\\rho\\) is the density of the surroundings evaluated at the parcel’s height \\(z_1=z_0 + \\delta z\\).\nUsing the thermodynamic state equation of the fluid, we can express densities in terms of pressure \\(p\\) and specific entropy \\(s\\). For the fluid density, this means:\n\\[\n\\rho = \\rho(p(z_1),\\,s(z_1)),\n\\] while for the parcel we have:\n\\[\n\\rho _\\text{p} = \\rho (p(z_1), s(z_0)),\n\\] due to the fact that the process is adiabatic. Hence, expanding the right hand side of Equation 1 to first order in \\(\\delta z\\), we obtain:\n\\[\n\\ddot {\\delta z} = -\\Omega  ^2 \\delta z,\n\\tag{2}\\]\nwhere:\n\\[\n\\Omega  ^2 \\equiv -\\dfrac{g}{\\rho}\\left(\\frac{\\partial \\rho }{\\partial s}\\right)_p\\frac{\\text d s}{\\text d z}=-\\dfrac{g}{\\rho}\\left(\\frac{\\partial \\rho }{\\partial s}\\right)_p\\frac{\\text d s}{\\text d z},\n\\tag{3}\\]\nis called the Brunt–Väisälä frequency, or buoyancy frequency (all quantities in this equation can be evaluated at \\(z = z_0\\) in the linear approximation we are considering). Equations Equation 2 imply that, in order for hydrostatic equilibrium to be stable, we must have \\(\\Omega ^2 &gt; 0\\), that is:\n\\[\n-\\left(\\frac{\\partial \\rho }{\\partial s}\\right)_p\\frac{\\text d s}{\\text d z} &gt; 0\n\\tag{4}\\]\nThere are a few alternative ways to express Equation 4. First of all, using the Maxwell relation \\(\\left(\\frac{\\partial \\rho }{\\partial s}\\right)_p=\\frac{T}{c_p}\\left(\\frac{\\partial \\rho }{\\partial T}\\right)_p\\), we see that equilibrium requires:\n\\[\n-\\left(\\frac{\\partial \\rho }{\\partial T}\\right)_p\\frac{\\text d s}{\\text d z}&gt;0.\n\\tag{5}\\]\nMoreover, assuming \\(\\left(\\frac{\\partial \\rho }{\\partial T}\\right)_p&lt;0\\), this simplifies to:\n\\[\n\\frac{\\text d s}{\\text d z} &gt;0\n\\tag{6}\\]\nConsidering \\(s\\) as a function of \\(p\\) and \\(T\\), we have:\n\\[\n\\frac{\\text d s}{\\text d z} = \\left(\\frac{\\partial s}{\\partial T}\\right)_p \\frac{\\text d T}{\\text d z}+\\left(\\frac{\\partial s}{\\partial p}\\right)_T \\frac{\\text d p}{\\text d z}=c_p \\frac{\\text d T}{\\text d z}+\\left(\\frac{\\partial V}{\\partial T}\\right)_p\\frac{\\text d p}{\\text d z}&gt;0,\n\\tag{7}\\]\nwhere the Maxwell relation \\(\\left(\\frac{\\partial s}{\\partial p}\\right)_T=\\left(\\frac{\\partial V}{\\partial T}\\right)_p\\) and the definition of the specific heat at constant pressure \\(c_p \\equiv \\left(\\frac{\\partial s}{\\partial p}\\right)_T\\) were used. Finally, using again the equilibrium condition \\(\\frac{\\text d p}{\\text d z} = -g /V\\), we obtain\n\\[\n-\\frac{\\text d T}{\\text d z} &lt; -\\frac{\\beta Tg}{\\rho c_p},\n\\tag{8}\\]\nwhere \\(\\beta \\equiv -\\frac{1}{\\rho}\\left(\\frac{\\partial \\rho}{\\partial T}\\right)_p\\) is the thermal expansion coefficient. For an ideal gas, the right hand side is just \\(\\frac{g}{c_p}\\).\nThe Brunt–Väisälä oscillation frequency (Equation 3) is actually correct only in a certain limit, which is best clarified in the more careful approach, that proceeds from the ideal fluid equations. Nonetheless, the equilibrium condition \\(\\Omega ^2 &gt;0\\) turns out to be correct."
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#linearization-of-the-ideal-fluid-equations",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#linearization-of-the-ideal-fluid-equations",
    "title": "Gravity waves in an ideal fluid",
    "section": "Linearization of the ideal fluid equations",
    "text": "Linearization of the ideal fluid equations\nIn fluid dynamics, our system would be described by the ideal fluid equations:\n\\[\n\\begin{split}\n\\frac {\\text D \\mathbf v}{\\text D t}&=-\\frac{\\nabla p}{\\rho }+\\mathbf g,\n\\\\\n\\frac{\\text D \\rho }{\\text D t} &=-\\rho (\\nabla \\cdot \\mathbf v),\n\\\\\n\\frac{\\text D s}{\\text D t}&=0,\n\\end{split}\n\\tag{9}\\]\nwhere \\(\\frac{\\text D}{\\text D t} = \\frac{\\partial}{\\partial t}+\\mathbf v \\cdot \\nabla\\) denotes the material derivative. The last equation can be exchanged for1:\n\\[\n\\frac{\\text{D}p}{\\text Dt}=c_s^2\\frac{\\text D \\rho}{\\text D t}\n\\tag{10}\\]\nwhere \\(c_s^2 \\equiv (\\frac{\\partial p}{\\partial \\rho})_s\\) is the speed of sound. Denoting by \\(p_0\\) and \\(\\rho_0\\) the pressure and density field of the hydrostatic solution, satisfying \\(\\nabla p _0 = \\mathbf g \\rho _0\\), we consider a perturbation of the form:\n\\[\n\\mathbf v = \\delta \\mathbf v,\\quad p=p_0+\\delta p,\\quad \\rho=\\rho_0+\\delta \\rho.\n\\tag{11}\\]\nTo linear order in the small quantities \\(\\delta \\mathbf v\\), \\(\\delta p\\) and \\(\\delta \\rho\\), the equations of motion read:\n\\[\n\\begin{split}\n0 &=-\\frac {\\partial  \\delta \\mathbf v}{\\partial t}-\\frac{\\nabla (\\delta p)}{\\rho _0}+\\mathbf g\\frac{\\delta \\rho }{\\rho _0},\n\\\\\n0 &=\\frac{\\partial (\\delta \\rho) }{\\partial t}+\\delta\\mathbf v \\cdot \\nabla \\rho _0+\\rho_0 (\\nabla \\cdot \\delta \\mathbf v) ,\n\\\\\n0&=\\frac{\\partial (\\delta p )}{\\partial t}+\\delta \\mathbf v \\cdot \\nabla p_0-c_s^2\\frac{\\partial (\\delta \\rho )}{\\partial t}-c_s^2\\mathbf \\delta \\mathbf v \\cdot \\nabla \\rho_0.\n\\end{split}\n\\tag{12}\\]\nThese equations take a rather simple form if we re-express them in terms of the mass flux density \\(\\mathbf j = \\rho \\mathbf v\\), that is \\(\\delta \\mathbf j = \\rho _0 \\delta \\mathbf v\\) to linear order. Before doing so, we notice that:\n\\[\n\\nabla \\rho_0=(\\frac {\\partial \\rho}{\\partial p})_s\\nabla p_0+(\\frac {\\partial \\rho}{\\partial s})_p\\nabla s=-(\\frac{g}{c_s^2} +\\frac{\\Omega ^2}{g}) \\rho_0 \\hat {\\mathbf z},\n\\tag{13}\\]\nwhere \\(\\Omega ^2\\) is the buoyancy frequency defined above (cf. Equation 3) and we assume, consistent with cylindrical symmetry, \\(\\nabla s\\) to lie in the \\(\\hat {\\mathbf z}\\)2. Putting everything together, we obtain:\n\\[\n\\begin{split}\n0 &=-\\frac {\\partial (\\delta \\mathbf j)}{\\partial t}-\\nabla (\\delta p)+\\mathbf g\\delta \\rho,\n\\\\\n0 &=\\frac{\\partial (\\delta \\rho) }{\\partial t}+\\nabla \\cdot (\\delta\\mathbf j) ,\n\\\\\n0&=\\frac{\\partial (\\delta p )}{\\partial t}+c_s^2\\nabla \\cdot  (\\delta \\mathbf j)+\\frac{c_s^2\\Omega ^2}{g}(\\delta \\mathbf j) \\cdot  \\hat {\\mathbf z}.\n\\end{split}\n\\tag{14}\\]\nStrictly speaking, the quantities \\(c_s^2\\) and \\(\\Omega ^2\\) appearing in this equation are scalar fields with a non-trivial spatial variation. However, assuming that the spatial scale of the perturbation is much smaller than the typical scale of variation of \\(\\Omega ^2\\) and \\(c_s^2\\), we can treat these two numbers as constants. For simplicity, we will work with units such that \\(c_s = g = 1\\) (this is the same as using \\(L=c_s^2g^{-1}\\) and \\(T = c_sg^{-1}\\) as units of time and length, respectively; the dependence from \\(c_s\\) and \\(g\\) can be reintroduced in the final formulas through dimensional analysis).\nThe system becomes then a linear system with constant coefficients, which suggests to search for simple solutions of the form:\n\\[\n\\mathbf j = \\mathbf u e^{i(\\omega t-\\mathbf q  \\cdot \\mathbf r)},\\quad \\mathbf \\delta \\rho = \\alpha e^{i(\\omega t-\\mathbf q  \\cdot \\mathbf r)},\\quad\\delta p = \\beta e^{i(\\omega t-\\mathbf q  \\cdot \\mathbf r)}.\n\\]\nPlugging these into the linearized system, we obtain:\n\\[\n\\begin{split}\n0 &=-i\\omega \\mathbf u+i\\mathbf q \\beta -\\hat {\\mathbf z}\\alpha,\n\\\\\n0 &=i\\omega \\alpha-i\\mathbf q \\cdot \\mathbf u ,\n\\\\\n0&=i\\omega \\beta +\\Omega ^2\\mathbf u \\cdot \\hat{\\mathbf z}-i\\mathbf q \\cdot \\mathbf u,\n\\end{split}\n\\tag{15}\\]\nIn order to solve these equations, we write:\n\\[\n\\mathbf q = q_z \\hat {\\mathbf z}+q_\\perp \\hat {\\mathbf x}.\n\\] From the first equation we obtain:\n\\[\n\\mathbf u \\cdot \\hat {\\mathbf x} = \\frac{\\beta q_\\perp}{\\omega},\\quad \\mathbf u \\cdot \\hat{\\mathbf y} = 0, \\quad\n\\mathbf u \\cdot \\hat {\\mathbf z} = \\frac{\\beta q_z+i\\alpha }{\\omega}.\n\\]\nThe second equation then yields:\n\\[\n\\dfrac{\\alpha}{\\beta}=\\dfrac {\\mathbf q^2}{\\omega ^2 -i q_z}\n\\]\nFinally, from the third equation we obtain:\n\\[\n0 =\\omega ^4 -\\omega ^2 [i(1+\\Omega ^2) q_z+\\mathbf q^2]+q_\\perp ^2\\Omega ^2\n\\]\nWe now require \\(\\mathbf q\\) to have an imaginary part \\(\\text {Im}(\\mathbf q) = -\\frac{1+\\Omega ^2}{2}\\hat {\\mathbf z}\\), as we rigorously justify below. Under this assumption, the equation for \\(\\omega ^2\\) has two real roots:\n\\[\n\\omega ^2_\\pm = \\frac {c_s^2 (\\mathbf k ^2+\\lambda^{-2})}{2}\\left(1\\pm \\sqrt {1-\\dfrac{4\\Omega ^2k_\\perp^2}{c_s^2 (\\mathbf k ^2+\\lambda^{-2})^2}}\\right),\n\\tag{16}\\]\nwith:\n\\[\n\\mathbf k = \\text{Re}(\\mathbf q),\\qquad  \\lambda^{-1}\\equiv \\frac{1}{2}( \\frac{g}{c_s^2} +\\frac{\\Omega ^2}{g})\n\\tag{17}\\]\n(\\(g\\) and \\(c_s\\) have been reintroduced in these formulas as explained above).\nBefore proceeding further, we notice that the frequencies \\(\\omega _-\\) (those from the minus sign branch in Equation 16) are real if and only if \\(\\Omega ^2 &gt; 0\\), which is the same as the equilibrium condition derived from the parcel argument. The actual frequencies of oscillation are not given by \\(\\Omega\\), in general."
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#physical-interpretation",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#physical-interpretation",
    "title": "Gravity waves in an ideal fluid",
    "section": "Physical interpretation",
    "text": "Physical interpretation\nIn order to understand the two branches of Equation 16, we start by noticing that, for the whole linearization approach to be valid, we must have (in natural units \\(g=c_s=1\\)):\n\\[\n\\dfrac{4\\Omega ^2k_\\perp^2}{(\\mathbf k ^2+\\lambda^{-2})^2} \\ll 1,\n\\tag{18}\\]\nThis must be the case for the perturbation to be localized in the \\(\\hat {\\mathbf z}\\) direction, which requires \\(k_z \\gg 1\\) (notice that \\(\\Omega, \\lambda \\sim \\mathcal O(1)\\) in natural units).\nAssuming Equation 18, we can approximate the two roots in Eq. Equation 16 as follows:\n\\[\n\\omega ^2_+ \\approx\\mathbf k ^2,\\qquad\\omega ^2_- \\approx \\frac{ k_\\perp ^2}{k_z^2+k_\\perp ^2}\\Omega ^2.\n\\tag{19}\\]\nWe also notice that the fluid velocity field satisfies (without any approximation):\n\\[\n\\frac{v_z}{v_\\perp} = \\frac{k_z}{k_\\perp}\\left(\\dfrac{1+i\\frac{k_\\perp^2}{k_z\\omega^2}-i\\frac{1+\\Omega ^2}{2k_z}}{1-i\\frac{k_z}{\\omega^2}-\\frac{1+\\Omega ^2}{2\\omega^2}}\\right)\n\\] Let us first consider waves associated with \\(\\omega _+\\), which are essentially sound waves and for which gravity plays very little role. These have both phase and group velocity aligned with \\(\\mathbf k\\) and close to \\(1\\) (the speed of sound), and the fluid velocity is also in the direction of \\(\\mathbf k\\) (the waves are longitudinal):\n\\[\n\\frac{v_z}{v_\\perp}\\approx \\frac{k_z}{k_\\perp },\n\\]\nIn contrast, waves associated with \\(\\omega _{-}\\), called gravity waves, have vanishing phase and group velocity in the limit \\(k_z \\to \\infty\\), in general. The material velocity is perpendicular to \\(\\mathbf k\\):\n\\[\n\\frac{v_z}{v_\\perp}\\approx -\\frac{k_\\perp}{k_z },\n\\] The wave frequency depends on the angle \\(\\theta\\) between \\(k\\) and \\(\\mathbf g\\), since \\(\\omega _{-}^2 = \\sin^2 \\theta \\cdot \\Omega ^2\\). In particular, in the limit of plane waves in the \\(\\hat {\\mathbf z}\\) direction, i.e. \\(\\theta \\to 0\\), we have \\(\\omega _{-}^2 \\to 0\\), while plane waves orthogonal to gravity \\(\\theta \\to \\frac{\\pi}{2}\\) have frequency \\(\\omega _{-}^2 \\approx \\Omega ^2\\). From the physical point of view, these two limits correspond to the cases in which the horizontal spatial scale of the perturbation is much larger/smaller than the vertical scale, respectively.\nWe realize that the kind of perturbation analysed in the parcel argument implicitly refers to gravity waves of the second type (with small horizontal scales). From Equation 19, we see that the oscillation frequency coincides with the buoyancy frequency Equation 3 only if \\(k _\\perp \\gg k_z\\), that is, if the vertical spatial scale of the perturbation is much larger than its horizontal scale.\n\nMathematical details on the wave solution\nIn order to justify the procedure used in the derivation of the plane waves solutions, consider a localized perturbation (say with compact support) at \\(t = 0\\) and let \\(\\Psi(t=0)\\) denote the vector of quantities \\(\\delta \\rho(t=0)\\), \\(\\delta p (t=0)\\) and \\(\\delta \\mathbf j (t=0)\\). Since \\(\\Psi(t=0)\\) is localized, we can define:\n\\[\n\\widetilde \\Psi(\\mathbf k,t=0)=\\intop \\text d ^3 \\mathbf r \\,e^{i\\mathbf k \\cdot \\mathbf r} e^{z/\\lambda} \\Psi(\\mathbf r, t=0)\n\\tag{20}\\] and the inverse of the Fourier transform gives:\n\\[\n\\Psi(\\mathbf r, t=0) = e^{-z/\\lambda}\\intop  \\frac{\\text d ^3\\mathbf k}{(2\\pi)^3} e^{-i\\mathbf k \\cdot \\mathbf r}\\widetilde \\Psi(\\mathbf k,t=0).\n\\tag{21}\\]\nThe Fourier components \\(\\widetilde \\Psi (\\mathbf k, t)\\) for a fixed \\(\\mathbf k\\) satisfy a linear system of ordinary differential equations, for which we already found four independent solutions (two for each frequency) in the previous Section. The fifth solution can be easily verified to correspond to a static, divergence-less velocity perturbation, with the velocity field orthogonal to the \\(\\hat {\\mathbf z}\\) axis:\n\\[\n\\widetilde {\\delta \\mathbf j}(\\mathbf k ,t) = f(\\mathbf k) \\,{\\mathbf k} \\times \\mathbf g,\\qquad \\widetilde {\\delta p}=0\\qquad\\widetilde {\\delta \\rho} = 0\n\\tag{22}\\]\nIn momentum space, in the basis provided by the four eigenvectors with eigenvalues given by Equation 16, plus this last (static) solution, time evolution is trivial.\nAs a parenthetical remark, we notice that if we drop the requirement of a localized perturbation, we can have additional solutions that are not covered by the previous remarks. A trivial example is that of an hydrostatic equations - \\(\\nabla p = \\mathbf g \\rho\\), with \\(\\delta \\mathbf j = \\mathbf 0\\), all fields being independent of time. These solutions are clearly not localized, since the pressure field changes only in the \\(\\hat {\\mathbf z }\\) direction. Another example is provided by Lamb waves, that satisfy the constraint:\n\\[\n\\delta \\mathbf j \\cdot \\hat {\\mathbf z} = 0\n\\]\nand take the general form:\n\\[\n\\Psi(\\mathbf r,t) = e^{-(\\frac{\\Omega ^2}{g}-\\frac{g}{c_s^2})z}\\intop \\frac{\\text d ^2 \\mathbf k _\\perp}{(2\\pi)^2} e^{-i\\mathbf k _\\perp \\cdot \\mathbf r}  \\left[a(\\mathbf k _\\perp)e^{i kc_st}+b(\\mathbf k _\\perp)e^{-i kc_st}\\right].\n\\tag{23}\\]\nThese waves are clearly not localized in the \\(\\hat {\\mathbf z}\\) direction."
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#further-problems",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#further-problems",
    "title": "Gravity waves in an ideal fluid",
    "section": "Further problems",
    "text": "Further problems\nThis is the point where I felt the algebra was getting a bit too involved and I left the problem. There are still a few things that it may be interesting to investigate. In particular, it would be nice to derive the explicit evolution of a wave packet, say:\n\\[\n\\delta \\mathbf v (\\mathbf r, 0) = \\mathbf V \\exp\\left[{-\\frac{x^2+y^2}{2\\sigma _\\perp^2}-\\frac{z^2}{2\\sigma _z^2}}\\right].\n\\] with vanishing density and pressure perturbation (to simplify the algebra a little bit). One should compute the “modified” Fourier transform Equation 20 and express the coefficients in terms of the five eigenvectors derived above. Perturbations like this will in general give rise to a combination of acoustic and longitudinal waves, depending on the direction of \\(\\mathbf V\\) and on the ratio of vertical and horizontal scales, \\(\\sigma _z\\) and \\(\\sigma _\\perp\\)."
  },
  {
    "objectID": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#footnotes",
    "href": "posts/2024-02-22-gravity-waves-in-an-ideal-fluid/gravity-waves-in-an-ideal-fluid.html#footnotes",
    "title": "Gravity waves in an ideal fluid",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn order to see this, we simply write \\(p = p(\\rho, s)\\) as a function of \\(\\rho\\) and \\(s\\) and take the material derivative.↩︎\nFrom the pure mathematical point of view, this is not a strict consequence of Equation 9, which are in fact consistent with any static density configuration, as long as \\(\\nabla p = \\mathbf g \\rho\\) is satisfied. The physical reason is, of course, that we’re neglecting thermal conductivity, which allows for an arbitrary temperature gradient to persist forever in the absence of motion.↩︎"
  },
  {
    "objectID": "posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level/no-overdispersion-from-individual-variation.html",
    "href": "posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level/no-overdispersion-from-individual-variation.html",
    "title": "No binomial overdispersion from variations at the individual level",
    "section": "",
    "text": "I came across some confusing statements regarding how overdispersion can arise in binary or count data, such as the typical capture-recapture data encountered in Biology and Ecology. The term generally refers to a variance inflation with respect to the prediction of a specific statistical model (or family of models) for the data generating process under study. Such extra variability is sometimes ascribed to “inhomogeneities in the population”, a phrase that is not very precise from a mathematical point of view, and can be misleading without further qualification.\nLet’s get to the point. Consider a binomial model:\n\\[\nB_{N,\\,p}(k) = \\binom{N}{k}p^k(1-p)^{N-k}.\n\\tag{1}\\]\nFor concreteness, imagine that we are studying survival in a population of animals, and Equation 1 is proposed to model the survival probability of an initial cohort of \\(N\\) individuals (from one year to the next, say).\nClearly, we should not expect \\(p\\) to represent the survival probability for each single animal. In fact are a lot of factors that are only determined at the level of the individual and that could realistically affect survival: age, sex, weight, etc.. If we are not including any individual variable in our analysis (because they were not measured, for example) we may model the survival probability \\(q\\) of any individual by a probability distribution \\(\\text d \\pi(q)\\) with mean \\(\\bar q = \\int q\\,\\text d \\pi (q)\\). If we further assume that survival probabilities of several individuals are independent and identically distributed (i.i.d.), we can derive explicitly the probability of \\(k\\) survivals out of \\(N\\) initial individuals:\n\\[\n\\begin{split}\n\\text{Pr}(k) &= \\intop \\text d\\pi(q_1)\\text d\\pi (q_2)\\cdots \\text d\\pi(q_N)\\sum _{y\\in E_{N,k}}\\prod_{i=1}^Nq_i^{y_i}(1-q_i)^{(1-y_i)}\\\\\n& = \\sum _{y\\in E_{N,k}}\\prod_{i=1}^N \\left(\\intop \\text d \\pi(q_i)q_i^{y_i}(1-q_i)^{(1-y_i)}\\right) \\\\\n& = \\sum _{y\\in E_{N,k}}\\prod_{i=1}^N \\bar q^{y_i}(1-\\bar q)^{1-y_i} \\\\\n& = B_{N,\\bar q}(k)\n\\end{split}\n\\tag{2}\\]\nwhere we have denoted by \\(E_{N,k}\\) the set of \\(Y\\in \\{0,\\,1\\}^N\\) such that \\(\\sum _{i=1}^{N}Y_i=k\\). Notice that the integrand in the first line of Equation 2 is the conditional probability of \\(k\\) successes out of \\(N\\) trials with probabilities for the individual trials given by \\(q_1,\\,q_2,\\,\\dots,\\,q_N\\).\nIn other words, assuming that the survival probabilities of individuals are i.i.d. according to \\(\\text d \\pi (q)\\), we see that the binomial distribution Equation 1 holds exactly with \\(p = \\intop \\text d \\pi (q) q\\) for the unconditional (on individual level covariates) distribution of survivals. A fortiori, no overdispersion with respect to the binomial variance, i.e. \\(Np(1-p)\\), is possible under these assumptions.\nLet us examine a bit more in detail the i.i.d. assumption. First of all, we observe that “identically distributed” is not the same as “identical”, which would be the case if \\(\\text d \\pi (q) = \\delta (q - \\bar q)\\text dq\\). Quite the contrary, the purpose of \\(\\text d \\pi (q)\\) is exactly to reflect the variability of \\(q\\) in the overall population. On the other hand, assuming all individuals are sampled from the same population, the distribution \\(\\text d \\pi\\) is simply the result of such a sampling scheme, and it doesn’t really make sense to consider different distributions for different individuals. The only case in which we should use different \\(\\text d \\pi _i(q_i)\\) distributions is if our experimental design involved systematically sampling individuals from distinct populations and putting them together into a single cohort (e.g. we always start with \\(\\frac{N}{2}\\) individuals from population \\(A\\) and \\(\\frac{N}{2}\\) from population \\(B\\)). Finally, if the analysis included some individual covariate, such as sex or age, all the discussion would remain valid, with unconditional survival probabilities replaced by conditional (on sex and age) probabilities.\nThe rather strong assumption is, instead, independence. How could independence be violated? Suppose there is some set of variables \\(X\\) not included in the analysis, which globally affect survival for all individuals - in our example \\(X\\) may include for instance things like food availability and metereological conditions. Suppose, further, that survival probabilities are actually i.i.d. conditional on \\(X\\), with joint distribution:\n\\[\n\\text d \\Pi(q_1,q_2,\\dots, q_N\\vert X)=\\text d\\pi(q_1\\vert X)\\text d\\pi(q_2\\vert X)\\cdots\\text d\\pi (q_N\\vert X)\n\\tag{3}\\]\nThen, unconditionally:\n\\[\n\\text d \\Pi(q_1,q_2,\\dots, q_N)=\\intop \\text dF(X)\\,\\text d\\pi(q_1\\vert X)\\text d\\pi(q_2\\vert X)\\cdots\\text d\\pi (q_N\\vert X),\n\\tag{4}\\]\nwhere \\(\\text d F(X)\\) is the marginal distribution of \\(X\\). Crucially, this is in general not a product measure, and (looking back at our derivation, Equation 2) we see that this dependence can indeed change the form of the resulting distribution - and lead to overdispersion with respect to the binomial expectation, in particular.\nI think the discussion above clearly shows that binomial overdispersion is not caused by inhomogeneities in the population, if these are understood as random (patternless) variations at the individual level. Quite the contrary, what can easily make data look non-binomial is the presence of unobserved global factors that can change randomly between experimental repetitions, and influence (or simply correlate with) survival probability at the population level.\nA few concluding remarks:\n\nFrom a pure mathematical point of view, in the limit in which initial cohorts are sampled from a single, infinite population, the validity of the i.i.d. assumption is guaranteed by De Finetti’s theorem on infinite exchangeable sequences (in the finite case there are also guarantees of approximate validity). Clearly, if the experimental design involves sampling individuals from several populations in a systematic way, the resulting sequence of Bernoulli variables (alive/dead) is not exchangeable.\nIf the De Finetti measure in the previous point can change between different cohort releases, depending on some random and unmeasured parameter \\(X\\), this will effectively lead to the same kind of dependence between individual probability parameters illustrated above.\nAnother form in which dependence may arise is when survival of one individual may influence, or simply correlate with, survival of other individuals. Imagine, for instance, that we may only observe individuals in pairs. Mathematically, this will again manifest in the form of non-exchangeability.\n\nFurther references:\n\n(Cox and Snell 1989)\n\n\n\n\n\nReferences\n\nCox, D. R., and E. J. Snell. 1989. Analysis of Binary Data, Second Edition. Chapman & Hall/CRC Monographs on Statistics & Applied Probability. Taylor & Francis.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {No Binomial Overdispersion from Variations at the Individual\n    Level},\n  date = {2024-03-06},\n  url = {https://vgherard.github.io/posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level/no-overdispersion-from-individual-variation.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “No Binomial Overdispersion from\nVariations at the Individual Level.” March 6, 2024. https://vgherard.github.io/posts/2024-03-06-no-binomial-overdispersion-from-variations-at-the-individual-level/no-overdispersion-from-individual-variation.html."
  },
  {
    "objectID": "posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance/akaike-criterion-for-the-gaussian-linear-model-known-vs-unknown-variance.html",
    "href": "posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance/akaike-criterion-for-the-gaussian-linear-model-known-vs-unknown-variance.html",
    "title": "AIC for the linear model: known vs. unknown variance",
    "section": "",
    "text": "The Akaike Information Criterion (AIC) for the linear model \\(Y = X \\beta + \\varepsilon\\), with takes the form:\n\\[\n\\text{AIC}^{\\text{(k)}} = \\frac{(\\mathbf Y-\\mathbf X\\hat \\beta )^2}{\\sigma ^2} + 2p\n\\]\nif the noise variance \\(\\sigma ^2 = \\mathbb V(\\varepsilon\\vert X)\\) is known, and:\n\\[\n\\text{AIC}^{\\text{(u)}} = N\\ln(\\hat \\sigma ^2) + 2(p + 1)\n\\]\nif \\(\\sigma^2\\) is unknown. Here \\(\\hat \\beta\\) denotes the maximum-likelihood estimate of \\(\\beta\\), and \\(\\hat \\sigma ^2 = \\frac{1}{N}(\\mathbf Y -\\mathbf X \\hat \\beta)^2\\) the corresponding estimate of \\(\\sigma ^2\\) if the latter is unknown; \\(p\\) is the dimension of the covariate vector \\(X\\).\nOne would expect knowledge on variance to have little effect on model selection for the mean, at least in a limit in which variance can be considered to be reasonably well estimated. In order to check that this is actually the case, we expand \\(\\text{AIC}^{\\text{(u)}}\\) differences to first order \\(\\hat \\sigma _1 ^2 - \\hat \\sigma _2 ^2\\):\n\\[\n\\begin{split}\n\\text{AIC}^{\\text{(u)}}_1-\\text{AIC}^{\\text{(u)}}_2 &= N\\ln(\\frac{\\hat \\sigma ^2_1}{\\hat \\sigma ^2_2}) + 2(p_1-p_2)\\\\\n&\\approx N\\frac{\\hat \\sigma _{1}^2-\\hat \\sigma _2 ^2}{\\hat \\sigma _2 ^2} + 2(p_1-p_2)\\\\\n& = \\text{AIC}^{\\text{(k)}}_1-\\text{AIC}^{\\text{(k)}}_2+N\\frac{(\\hat \\sigma _{1}^2-\\hat \\sigma _2 ^2)(\\sigma ^2-\\hat \\sigma _2 ^2)}{\\hat \\sigma _2 ^2\\sigma^2}\n\\end{split}\n\\]\nThe approximation in the second line requires \\(\\vert \\hat \\sigma _1 ^2 - \\hat \\sigma _2 ^2\\vert \\ll\\hat \\sigma _2 ^2\\). Furthermore, the last term in the final expression is a small fraction of \\(\\text{AIC}^{\\text{(u)}}_1-\\text{AIC}^{\\text{(u)}}_2\\) if \\(|\\sigma ^2 -\\hat \\sigma _2 ^2| \\ll \\sigma ^2\\).\nPutting these two conditions together, we obtain:\n\\[\n|\\hat \\sigma _1 ^2 -\\hat \\sigma _2 ^2|,|\\sigma ^2 -\\hat \\sigma _2 ^2| \\ll \\sigma ^2,\\qquad\n\\]\nwhich means that \\(\\text{AIC}^{\\text{(u)}}\\) and \\(\\text{AIC}^{\\text{(k)}}\\) lead to the same model selection provided that the models involved in the AIC comparison estimate reasonably well the true variance.\nConcluding remarks:\n\nAlthough the maximum-likelihood estimates plugged in the AIC are derived from normal theory, the theorem about the equivalence of AIC selection in the known and unknown variance cases continues to hold irrespective of this assumption.\nWhat happens in misspecified cases, in which \\(\\hat \\sigma ^2\\) does not consistently estimate \\(\\mathbb V(\\varepsilon \\vert X)\\), either because of non-linearity or heteroskedasticity?\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {AIC for the Linear Model: Known Vs. Unknown Variance},\n  date = {2024-03-13},\n  url = {https://vgherard.github.io/posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance/akaike-criterion-for-the-gaussian-linear-model-known-vs-unknown-variance.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “AIC for the Linear Model: Known Vs.\nUnknown Variance.” March 13, 2024. https://vgherard.github.io/posts/2024-03-13-aic-for-the-linear-model-known-vs-unknown-variance/akaike-criterion-for-the-gaussian-linear-model-known-vs-unknown-variance.html."
  },
  {
    "objectID": "posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman/induction-and-deduction-in-bayesian-data-analysis-by-a-gelman.html",
    "href": "posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman/induction-and-deduction-in-bayesian-data-analysis-by-a-gelman.html",
    "title": "“Induction and Deduction in Bayesian Data Analysis” by A. Gelman",
    "section": "",
    "text": "(Gelman 2011). From the paper’s abstract:\n\nThe classical or frequentist approach to statistics (in which inference is centered on significance testing), is associated with a philosophy in which science is deductive and follows Popper’s doctrine of falsification. In contrast, Bayesian inference is commonly associated with inductive reasoning and the idea that a model can be dethroned by a competing model but can never be directly falsified by a significance test. The purpose of this article is to break these associations, which I think are incorrect and have been detrimental to statistical practice, in that they have steered falsificationists away from the very useful tools of Bayesian inference and have discouraged Bayesians from checking the fit of their models. From my experience using and developing Bayesian methods in social and environmental science, I have found model checking and falsification to be central in the modeling process.\n\nComments:\n\nI don’t know nothing about applied Bayesian analysis, but I’m a bit surprised by the fact that the recommendation to check model’s fit requires a whole paper in the 21st century. What is the supposed argument why Bayesians should not worry about model fit?\nI’m a bit confused about how one would actually interpret the model posterior checks discussed in the paper. If I understand correctly, the \\(p\\)-value is the posterior probability of observing a statistic as extreme as in the original data. Should I interpret this as a strength of evidence against the model - similar to Fisherian significance testing? What is the philosophical basis for rejecting models with small \\(p\\)-values? I guess these questions are answered in the technical references by the same author.\n\n\n\n\n\nReferences\n\nGelman, Andrew. 2011. “Induction and Deduction in Bayesian Data Analysis.”\n\nReuseCC BY 4.0CitationBibTeX citation:@online{gherardi2024,\n  author = {Gherardi, Valerio},\n  title = {“{Induction} and {Deduction} in {Bayesian} {Data} {Analysis}”\n    by {A.} {Gelman}},\n  date = {2024-04-25},\n  url = {https://vgherard.github.io/posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman/induction-and-deduction-in-bayesian-data-analysis-by-a-gelman.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nGherardi, Valerio. 2024. “‘Induction and Deduction in\nBayesian Data Analysis’ by A. Gelman.” April 25, 2024. https://vgherard.github.io/posts/2024-04-25-induction-and-deduction-in-bayesian-data-analysis-by-a-gelman/induction-and-deduction-in-bayesian-data-analysis-by-a-gelman.html."
  },
  {
    "objectID": "posts/2024-05-22-frequentist-bounds-for-bayesian-sequential-hypothesis-testing/frequentist-bounds-for-bayesian-sequential-hypothesis-testing.html",
    "href": "posts/2024-05-22-frequentist-bounds-for-bayesian-sequential-hypothesis-testing/frequentist-bounds-for-bayesian-sequential-hypothesis-testing.html",
    "title": "Frequentist bounds for Bayesian sequential hypothesis testing",
    "section": "",
    "text": "I just came across (Kerridge 1963), an old result which falls under the umbrella of “frequentist properties of Bayesian inference”. Specifically, the theorem proved in this reference applies to sequential testing, a context in which the mechanics of Bayesian inference, with its typical sequential updates, may be regarded as natural.\nSuppose we wish to compare two hypotheses \\(H_0\\) and \\(H_1\\), where \\(H_0\\) is simple1. We start collecting data until our sample meets some specific requirement, according to some given stopping rule \\(S\\). If this ever occurs, we compute the Bayes factor:\n\\[\nB = \\frac{\\text{Pr}(\\text {data} \\vert H_0)}{\\text{Pr}(\\text {data} \\vert H_1)}.\n\\tag{1}\\]\nand reject \\(H_0\\) if \\(B \\leq b\\), for some \\(b &gt; 0\\). The theorem is that if \\(H_0\\) is the true data generating process, the above procedure has a false rejection rate lower than \\(b\\), independently of the stopping rule employed to end sampling.\nNotice that the rejection event is composed by two parts:\nWe also note that the stopping rule needs not be deterministic, although this appears to be implicitly assumed in the original reference. In general, the data collected up to a certain point will only determine the probability that sampling stops at that time (and, to reinforce the previous point, the sum of these probabilities will not, in general, add up to \\(1\\)).\nIn order to prove this theorem, let us set up some notation. Let \\((X_n)_{n\\in \\mathbb N}\\) be some stochastic process representing “data”, where each \\(X_n \\in \\mathcal  X\\) is a data point. We denote by \\(P^{(0)}\\) the probability distribution of \\(X\\) under \\(H_0\\), which is completely defined since \\(H_0\\) is simple. We further denote by \\(P_n ^{(0)}\\) the corresponding probability measure on \\(\\mathcal X ^n\\) for the set of the first \\(n\\) observations \\(X_1,\\,X_2,\\,\\dots, \\,X_n\\).\nWe first consider the case in which \\(H_1\\) is also simple, and denote by \\(P^{(1)}\\) and \\(P^{(1)}_n\\) the corresponding measures. The Bayes factor is defined as the Radon-Nikodym derivative:\n\\[\nB_n \\equiv \\frac{\\text d P^{(0)}_n}{\\text d P_n^{(1)}}\n\\tag{2}\\]\n(we assume regularity conditions so that such a derivative exists).\nAlso, we assume for the moment that the stopping rule is deterministic, embodied by binary functions \\(S_n=S(X_1,\\,X_2,\\,\\dots,X_n)\\) of the first \\(n\\) observations, with \\(S_n = 1\\) if sampling can stop at step \\(n\\).\nNow fix \\(b&gt;0\\). A rejection of \\(H_0\\) at sampling step \\(n\\) is represented by the event:\n\\[\n\\mathcal R _{n}(b)\\equiv \\{B_n\\leq b,\\,S_n=1,\\,S_i=0\\,\\text{ for }i&lt;n\\},\n\\tag{3}\\]\nwhich, with abuse of notation, we may identify with a subset of \\(\\mathcal X ^n\\). The overall rejection event (at any sampling step) is given by:\n\\[\n\\mathcal R (b)\\equiv \\bigcup _{n=1} ^\\infty \\mathcal R_n(b),\n\\tag{4}\\]\nso that our theorem amounts to the bound:\n\\[\n\\text{Pr}_{H_0}(\\mathcal R(b))\\leq b.\n\\tag{5}\\]\nIn order to prove this, we first note that:\n\\[\n\\text{Pr}_{H_0}(\\mathcal R _n(b))=\n        \\intop _{\\mathcal R _n(b)} \\text d P_n=\n        \\intop _{\\mathcal R _n(b)}B_n \\text d Q_n \\leq\n        b\\intop _{\\mathcal R _n(b)} \\text d Q_n=b\\cdot\\text{Pr}_{H_1}(\\mathcal R _n(b)).\n\\tag{6}\\]\nHence, since the events \\(\\mathcal R _n(b)\\) and \\(\\mathcal R _m(b)\\) are clearly disjoint for \\(n\\neq m\\), we have:\n\\[\n\\text{Pr}_{H_0}(\\mathcal R(b))\\leq b\\cdot\\text{Pr}_{H_1}(\\mathcal R (b)),\n\\tag{7}\\]\nwhich, since \\(\\text{Pr}_Q(\\cdot)\\leq1\\), implies Equation 5.\nWe may relax the assumption that the alternative hypothesis is simple, by considering a parametric family of measures \\((P^{(1)}_\\theta)_{\\theta \\in \\Theta}\\), where the parameter \\(\\theta\\) has some prior probability \\(\\text d\\Phi(\\theta)\\). The argument given above still applies to this case, if \\(P^{(1)}\\) is replaced by the mixture \\(P^{(1)} = \\intop \\text d \\Phi(\\theta) P^{(1)}_\\theta\\) (under appropriate regularity assumptions). In the notation of Equation 1, the denominator \\(\\text {Pr}(\\text {data} \\vert H_1)\\equiv \\intop \\text d \\Phi(\\theta)\\,\\text{Pr}(\\text{data} \\vert H_{1,\\theta})\\).\nFinally, in order to lift the assumption that our stopping rule is deterministic, let us first consider the following special (deterministic) stopping rule:\n\\[\nS^*_n =1\\iff B_n \\leq b.\n\\tag{8}\\]\nIn other words, we stop sampling whenever the sample would reject \\(H_0\\) according to \\(B_n \\leq b\\). The rejection event \\(\\mathcal R(b)\\) for this special stopping rule is simply:\n\\[\n\\mathcal R^*(b) \\equiv \\{B_n \\leq b\\text{ for some }n\\in \\mathbb N\\}.\n\\tag{9}\\]\nSince we already proved the theorem for any deterministic stopping rule, Equation 5 implies:\n\\[\n\\text {Pr}_{H_0}(\\mathcal R^*(b)) \\leq b.\n\\tag{10}\\]\nBut Equation 10 clearly implies the theorem for any stopping rule, deterministic or not, since in general:\n\\[\n\\mathcal R(b) \\subseteq \\mathcal R^*(b)\n\\tag{11}\\]\n(we need \\(B_n\\leq b\\) to hold for some \\(n\\in \\mathbb N\\) in order to reject \\(H_0\\)).\nInterestingly, the argument just given leads to a more accurate statement of our main result Equation 5:\n\\[\n\\text{Pr}_{H_0}(\\mathcal R(b))\\leq \\text {Pr}_{H_0}(B_n \\leq b\\text{ for some }n\\in \\mathbb N) \\leq b,\n\\tag{12}\\]\nwhere the leftmost quantity is the false rejection rate of a selective testing procedure, such as the one we have been considering so far, wheareas the central quantity is the false rejection rate of a simultaneous testing procedure (that checks whether \\(B_n \\leq b\\) at each step of sampling). What’s happening here is analogous to a phenomenon observed in the context of parameter estimation following model selection (Berk et al. 2013), where one can show that, in order to guarantee marginal coverage for the selected parameters, if the selection rule is allowed to be completely arbitrary one must actually require simultaneous coverage for all possible parameters.\nTo conclude the post, let us remark that Equation 5 was originally formulated in terms of the posterior probability \\(Q_n(\\pi)\\) of \\(H_0\\):\n\\[\nQ_n(\\pi) = \\frac{\\pi }{\\pi +(1-\\pi)B^{-1}_n},\n\\tag{13}\\]\nwhere \\(\\pi\\) and \\(1-\\pi\\) are the prior probabilities of the two competing models \\(H_0\\) and \\(H_1\\), respectively. We may use \\(Q_n(\\pi) \\leq q\\), rather than \\(B_n \\leq b\\), as the relevant criterion for rejecting \\(H_0\\). From the pure frequentist point of view, this doesn’t add anything to our formulation in terms of the Bayes ratio, as \\(Q_n(\\pi)\\leq q\\) is equivalent to \\(B_n \\leq b\\) as long as \\(b = \\frac{q}{1-q}\\frac{1-\\pi}{\\pi}\\). In particular, the bound analogous to Equation 5 reads:\n\\[\n\\text{Pr}_{H_0}(\\mathcal R(q))\\leq \\text {Pr}_{H_0}(Q_n(\\pi) \\leq q\\text{ for some }n\\in \\mathbb N) \\leq \\frac{q}{1-q}\\frac{1-\\pi}{\\pi}.\n\\tag{14}\\]"
  },
  {
    "objectID": "posts/2024-05-22-frequentist-bounds-for-bayesian-sequential-hypothesis-testing/frequentist-bounds-for-bayesian-sequential-hypothesis-testing.html#footnotes",
    "href": "posts/2024-05-22-frequentist-bounds-for-bayesian-sequential-hypothesis-testing/frequentist-bounds-for-bayesian-sequential-hypothesis-testing.html#footnotes",
    "title": "Frequentist bounds for Bayesian sequential hypothesis testing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a technical term, meaning that \\(H_0\\) completely characterizes the probability distribution of data. An example of a non-simple hypothesis would be a parametric model depending on some unknown parameter \\(\\theta\\).↩︎"
  },
  {
    "objectID": "posts/2024-06-01-statements-of-the-second-law-of-thermodynamics/statements-of-the-second-law-of-thermodynamics.html",
    "href": "posts/2024-06-01-statements-of-the-second-law-of-thermodynamics/statements-of-the-second-law-of-thermodynamics.html",
    "title": "Statements of the Second Law of Thermodynamics",
    "section": "",
    "text": "The Second Law of Thermodynamics is commonly stated in the forms of Kelvin’s and Clausius’ postulates. These can be enunciated in the following way (Dittman and Zemansky 2021) 1:\nEither formulation is equivalent to the other and leads to the fundamental Clausius’ theorem. This asserts the existence of a universal state function \\(T\\), the absolute temperature, defined for any thermodynamic system, that satisfies the Clausius inequality. Concretely, if a system undergoes a cyclic process, during which it absorbs quantities \\(\\Delta Q _i\\) of energy in the form of heat from reservoirs at absolute temperatures \\(T_i\\), the inequality:\n\\[\n\\sum _i\\frac{\\Delta Q_i}{T_i} \\leq 0\n\\tag{1}\\] always holds.\nThe derivation of Equation 1 from Kelvin’s and Clausius’ postulates, a clever argument that employs ideal Carnot engines, is standard textbook material; see for example (Fermi 1956). On the other hand, I’ve never seen the converse being stressed, that is, that Clausius theorem allows one to recover versions of Kelvin’s and Clausius’ postulates. Here are two (fairly obvious) arguments in this direction.\nConsider a cyclic process of a thermodynamic system during which a quantity \\(\\Delta Q\\) of heat is absorbed from a reservoir at constant temperature \\(T_0\\). Equation 1 applied to this special process implies:\n\\[\n\\Delta Q\\leq 0.\n\\tag{2}\\]\nThe fact that \\(\\Delta Q\\leq 0\\) means that the heat reservoir can only absorb energy during a cycle, which must be supplied by performing a positive work on the system. This is the content of Kelvin’s postulate.\nSimilarly, if the system performs a cycle exchanging amounts of heat \\(\\Delta Q_1\\) and \\(\\Delta Q_2\\) with two heat sources at temperatures \\(T_1\\) and \\(T_2\\) respectively, Equation 1 implies:\n\\[\n\\frac{\\Delta Q_1}{T_1}+\\frac{\\Delta Q_2}{T_2}\\leq 0\n\\tag{3}\\]\nBut \\(\\Delta Q_1 + \\Delta Q_2 = \\Delta Q =-\\Delta W\\), the external work performed on the system during a cycle. Hence:\n\\[\n(\\frac{1}{T_1}-\\frac{1}{T_2})\\Delta Q_1\\leq \\frac{\\Delta W}{T_2}.\n\\tag{4}\\]\nTherefore, \\(\\Delta Q_1 \\geq 0\\) with \\(T_1 &lt; T_2\\) requires \\(\\Delta W \\geq 0\\). In other words, in order to perform a cycle in which a positive amount of heat is transferred from a low-temperature reservoir to a high-temperature one, we must necessarily perform some positive work2. This is the content of Clausius’ postulate.\nA subtle point that may require some elucidation is that, in the usual logical exposition of Thermodynamics, the temperature to which Kelvin’s and Clausius’ postulates make reference is the empirical temperature, call it \\(\\theta\\). This is the “quantity measured by a thermometer” (Fermi 1956), and is logically distinct from the absolute temperature \\(T\\), whose existence is a consequence of the second law. What we actually proved here are versions of Kelvin’s and Clausius’ postulates formulated in terms of the absolute temperature, \\(T\\).\nNow, if we take Kelvin’s or Clausius’ postulate (formulated in terms of \\(\\theta\\)) as our logical starting point, we can actually prove that \\(T\\) is an increasing function of \\(\\theta\\), in which case there is no point in specifying which temperature the postulates refer to. However, if our starting point is\nClausius’ Theorem, there is no a priori logical reason for a relation between \\(T\\) and \\(\\theta\\), which should be considered as an additional assumption.\nEven though this goes a bit beyond the original scope of the post, I’d like to show here how Equation 1 leads the existence of another state function, the entropy \\(S\\), which satisfies a generalized version of Equation 1, namely:\n\\[\n\\sum _i\\frac{\\Delta Q_i}{T_i} \\leq \\Delta S\n\\tag{5}\\]\nwhere quantities have the same meaning as in Equation 1, but the process is not necessarily cyclic. One can additionally show that the differential of \\(S\\) is given by:\n\\[\n\\text dS = \\frac{\\delta Q _R}{T},\n\\tag{6}\\]\nwhere \\(\\delta Q_R = \\text d U + \\delta W_R\\) is the differential heat absorbed by the system in a reversible process, and \\(T\\) is the system’s temperature.\nWe start by observing that, for a reversible process, equality must hold in Equation 1. This is so because, for a reversible cycle, the inverse cycle, in which the system absorbs amounts \\(-\\Delta Q_i\\) of heat at temperatures \\(T_i\\), must also be possible. Altogether, the Clausius inequalities for the direct and inverse cycles thus imply:\n\\[\n\\sum _i\\frac{\\Delta Q_i}{T_i} = 0\\quad \\text{(reversible process)}.\n\\tag{7}\\]\nImagining an ideal cyclic process, in which the system exchanges infinitesimal amounts of heat \\(\\delta Q(T')\\) with a continuous distribution of sources at temperatures \\(T'\\), we should replace the sum in Equation 7 with an integral:\n\\[\n\\intop \\frac{\\delta Q(T')}{T'} = 0 \\quad\\text{(reversible process)}\n\\tag{8}\\] We now fix a reference state \\(\\sigma _0\\) of our system, and define for any other state \\(\\sigma\\):\n\\[\nS(\\sigma;\\sigma _0) = \\intop _{\\sigma_0}^\\sigma \\frac{\\delta Q(T')}{T'}\n\\tag{9}\\]\nwhere the integral is taken along any reversible path that connects \\(\\sigma _0\\) and \\(\\sigma\\), and \\(\\delta Q(T')\\) is the amount of heat exchanged at temperature \\(T'\\) along this representative process. The fact that the integral in Equation 9 depends only upon the final states \\(\\sigma _0\\) and \\(\\sigma\\) is guaranteed by Equation 8.\nBy construction, we see that Equation 6 must hold with \\(T\\) being the temperature of a source that, if placed in thermal contact with the system, can produce a reversible exchange of heat. It remains to be shown that this temperature is nothing but the temperature of the system itself. Consider a reversible process in which two systems at temperatures \\(T_1\\) and \\(T_2\\) exchange an (infinitesimal) amount of heat. From what we have just said:\n\\[\n\\text d S_1 = \\frac{\\delta Q_1}{T_2},\\quad \\text d S_2 = \\frac{\\delta Q _2}{T_1},\n\\tag{10}\\] where \\(\\delta Q_i\\) is the heat absorbed by system \\(i\\), and \\(\\text d S_i\\) is its corresponding entropy change. However, since the composite system is thermally insulated, we must have \\(\\delta Q_1 + \\delta Q_2=0\\) and \\(\\text d S_1 + \\text d S_2 = 0\\)3. Equation 10 then implies that, if the process is reversible, we must necessarily have \\(T_1 = T_2\\). This completes the proof of Equation 6."
  },
  {
    "objectID": "posts/2024-06-01-statements-of-the-second-law-of-thermodynamics/statements-of-the-second-law-of-thermodynamics.html#footnotes",
    "href": "posts/2024-06-01-statements-of-the-second-law-of-thermodynamics/statements-of-the-second-law-of-thermodynamics.html#footnotes",
    "title": "Statements of the Second Law of Thermodynamics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe may compare these with the corresponding formulations given in Enrico Fermi’s famous book (Fermi 1956). For instance, Kelvin’s postulate reads: “A transformation whose only final result is to transform into work heat extracted from a source which is at the same temperature throughout is impossible.”. Even though I’m a big fan of Fermi’s book, I find the more modern formulations given in (Dittman and Zemansky 2021) clearer.↩︎\nIn fact, Equation 4 tells us a bit more than Clausius postulate, since it gives the maximum theoretical efficiency of a refrigerator operating between temperatures \\(T_1 &lt; T_2\\): \\[\n\\frac{\\Delta Q_1}{\\Delta W} \\leq \\frac{T_1}{T_2-T_1}\n\\]↩︎\nThe additivity of entropy is a consequence of the additivity of heat, which in turn would require a dedicate discussion. Such a requirement boils down to the additivity of external work, which holds generally if the interaction energies of the systems being composed are negligible. This is always assumed (more or less explicitly) whenever discussing the interaction of a system with a heat reservoir.↩︎"
  },
  {
    "objectID": "posts/2024-06-25-the-physics-and-mathematics-of-the-second-law-of-thermodynamics-by-eh-lieb-and-j-yngvason/lieb-yngvason-second-law.html",
    "href": "posts/2024-06-25-the-physics-and-mathematics-of-the-second-law-of-thermodynamics-by-eh-lieb-and-j-yngvason/lieb-yngvason-second-law.html",
    "title": "“The Physics and Mathematics of the Second Law of Thermodynamics” by E.H. Lieb and J. Yngvason",
    "section": "",
    "text": "(Lieb and Yngvason 1999).\nThe paper can be subdivided into two parts. In the first part, the authors deduce the existence of a universal entropy state function from a primitive notion of adiabatic accessibility. A key assumption in this derivation is the so-called Comparison Hypothesis, that postulates that for any two equilibrium states \\(X\\) and \\(Y\\) of a given thermodynamic system, either \\(X\\) is adiabatically accessible from \\(Y\\) or \\(Y\\) is adiabatically accessible from \\(X\\).\nThe second part is devoted to the derivation of the Comparison Hypothesis (which becomes thus a Comparison Principle) for an important class of thermodynamic systems. The main ingredients for this derivation are: - The First Law of Thermodynamics and, in particular the concept of internal energy. - The notion of thermal equilibrium and its transitivity (sometimes called the “Zero-th Law”). - An assumed convex structure in the state space of thermodynamic systems.\nSo, how does such a formal endeavor improve our understanding of Nature? On one side, entropy is clarified to represent nothing more than a numerical encoding of adiabatic accessibility. Its existence is independent of the concepts of energy, heat or temperature that appear in the usual formulations of Thermodynamics. On the other side, the classical statements of the Second Law of Kelvin-Planck and Clausius, which are explicitly formulated in terms of heat and temperature, are seen to be theorems on the adiabatic (in)accessibility of certain states, that follow from how the concepts of internal energy and thermal equilibrium interact with the primitive notion of adiabatic accessibility. Both of these are major advancements, because they clarify the physical content and universality of the Second Law of Thermodynamics.\nThe last Section of (Lieb and Yngvason 1999) provides a useful summary of the formalism and of the logical paths followed by the mathematical derivations. The rest of this post are some personal notes on the original reference."
  },
  {
    "objectID": "posts/2024-06-25-the-physics-and-mathematics-of-the-second-law-of-thermodynamics-by-eh-lieb-and-j-yngvason/lieb-yngvason-second-law.html#footnotes",
    "href": "posts/2024-06-25-the-physics-and-mathematics-of-the-second-law-of-thermodynamics-by-eh-lieb-and-j-yngvason/lieb-yngvason-second-law.html#footnotes",
    "title": "“The Physics and Mathematics of the Second Law of Thermodynamics” by E.H. Lieb and J. Yngvason",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn particular, the states \\(X\\) and \\(Y\\) are always comparable if \\(\\sum _{i=1}^{n} \\lambda _i = \\sum _{j=1}^m \\gamma _j\\). This does not need to be the case if the two sums differ.↩︎\nIf \\(t&lt;0\\), we can interpret \\(X + tY \\prec Z\\) as \\(X\\prec Z -tY\\).↩︎"
  },
  {
    "objectID": "posts/2024-08-12-dutch-book-arguments/dutch-book-arguments.html",
    "href": "posts/2024-08-12-dutch-book-arguments/dutch-book-arguments.html",
    "title": "Dutch book arguments",
    "section": "",
    "text": "The subjective interpretation of probability is based on the premise that degrees of belief must satisfy the axioms of probability calculus. The so-called “Dutch book” arguments provide a philosophical basis for this assumption.\nThe arguments start by operationalizing1 the (otherwise quantitatively vague) concept of “degree of belief”. The degree of belief of a subject into a given uncertain event2 \\(E\\) is supposed to be a number \\(p(E)\\) that can be quantified as follows:\n(the concrete unit of payment in these imaginary bets is irrelevant to the arguments, but is assumed to be a continuous quantity). The idea is that, for the subject not to incur into a sure loss, the rule \\(E\\mapsto p(E)\\) must define a single valued function that follows the laws of probability.\nLet us start by showing that the function \\(E\\mapsto p(E)\\) must be single valued (i.e. the degree of belief is operatively well-defined). Suppose that someone assigns two different degrees of belief \\(p\\) and \\(q\\) to the same event \\(E\\), and suppose that \\(p&gt;q\\), for instance. This means that this person must be willing to place a bet of \\(p\\) on \\(E\\) and, at the same time, accept a bet of \\(q\\) on \\(E\\). But this doesn’t make sense, because the net result of these combined bets is a sure loss (of an amount \\(p-q\\)). We can conclude that the degree of belief assigned by any individual into a given event must be a single number.\nWith a similar approach we can prove the three basic axioms of probability:\nPositivity. Degrees of belief must be positive numbers, because no rational agent would be willing to pay a positive amount \\(q = -p\\) (which is the only reasonable way to interpret accepting a negative amount \\(p = -q\\)), for later having to pay an additional amount \\(1\\) if event \\(E\\) obtains.\nNormalization. Suppose that the event \\(E\\) is certain, and let \\(p\\) be your degree of belief into it. If \\(p &lt; 1\\), one can force you to accept an amount \\(p\\), and to give \\(1\\) in return, with certainty since \\(E\\) is always true. If \\(p &gt; 1\\), one can force you to pay an amount \\(p\\) to get \\(1\\) in return. In both cases, you face a sure loss of an amount \\(\\vert 1 - p\\vert\\), unless \\(p = 1\\).\nAdditivity. Suppose that events \\(A\\) and \\(B\\) are mutually exclusive, and let \\(p\\), \\(q\\) and \\(r\\) be your degrees of belief into \\(A\\), \\(B\\) and \\(A\\cup B\\) ( denoting \\(A\\) or \\(B\\)). If \\(r &lt; p + q\\), one can force you to accept the following bets:\nThe fact that \\(A\\) and \\(B\\) are mutually exclusive, implies that the cash flow from the returns of these three bets is always zero, and the net flow is entirely set by the initial payments. For you, this is \\(r - p - q &lt; 0\\), which is a sure loss. If \\(r &gt; p + q\\), your opponent could also force you into a sure loss by reversing the bet directions in the previous argument.\nThere are also Dutch book arguments showing that when some rational agent has to update its degrees of belief based on new information, it must do so according to the standard conditioning rule:\n\\[\np(A\\vert B)p(B)=p(A\\cap B),\n\\tag{1}\\] where \\(p(A\\vert B)\\) denotes the degree of belief on \\(A\\) after finding out that \\(B\\) is true, while \\(A\\cap B\\) denotes the event that both \\(A\\) and \\(B\\) are true. It is worth to notice that the argument given below relies on the fact that the agent’s assessment of \\(p(A\\vert B)\\) is fixed and declared a priori, and does not change according to whether \\(B\\) actually obtains or not.\nThe argument goes as follows: suppose that Equation 1 does not hold and, for instance \\(p(B)\\cdot p(A\\vert B) &lt; p(A\\cap B)\\). We can then force the agent to participate in the following bets:\nIt is easy to see that, irrespective of the outcomes of the \\(A\\) and \\(B\\) events, the agent always ends up loosing an amount \\(p(A\\cap B) - p(B) \\cdot P(A\\vert B)\\). If \\(p(B)\\cdot p(A\\vert B) &gt; p(A\\cap B)\\), reversing the direction of these bets also leads to a sure loss for the agent. Clearly, the only way out is to set conditional probabilities according to Eq. Equation 1."
  },
  {
    "objectID": "posts/2024-08-12-dutch-book-arguments/dutch-book-arguments.html#footnotes",
    "href": "posts/2024-08-12-dutch-book-arguments/dutch-book-arguments.html#footnotes",
    "title": "Dutch book arguments",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhich means “giving a practical way to measure”.↩︎\nI use the word “events” in a conventional way. Strictly speaking, to reflect the wider generality of the subjectivist point of view, I should rather talk about “uncertain propositions” or “hypothetical facts”.↩︎\nThis is a slight generalization of the type of bet used in the operative definition of “degree of belief”, that assumes a unitary return amount. The reason why this is equivalent to the original definition is that, given bets \\(B_1,\\,B_2,\\,\\cdots,\\,B_N\\) with unitary return amounts, and positive numbers \\(x_1, \\,x_2,\\,\\dots,\\,x_N\\), we can always find positive integers \\(n_1,\\,n_2,\\dots,\\,n_N\\), such that the total gain from repeating \\(n_i\\) times bet \\(B_i\\) for all \\(i=1,2,\\dots,N\\) always has the same sign of the total gain from “generalized bets” that result by changing the return amount of bet \\(B_i\\) to \\(x_i\\).↩︎"
  },
  {
    "objectID": "scientific_publications.html",
    "href": "scientific_publications.html",
    "title": "Scientific Publications",
    "section": "",
    "text": "My research activity in Particle Physics spans between years 2017 and 2022, largely overlapping with my PhD studies. The main research topics are Non-perturbative methods in Quantum Field Theory and Beyond Standard Model phenomenology. A full list of publications is available on my iNSPIRE HEP author page. My PhD thesis can be accessed on arXiv.\nSelected articles:\n\nMatching scalar leptoquarks to the SMEFT at one loop\nModular invariant dynamics and fermion mass hierarchies around \\(\\tau = i\\)\nSolving the Bethe-Salpeter Equation in Minkowski Space for a Fermion-Scalar system"
  },
  {
    "objectID": "scientific_publications.html#particle-physics",
    "href": "scientific_publications.html#particle-physics",
    "title": "Scientific Publications",
    "section": "",
    "text": "My research activity in Particle Physics spans between years 2017 and 2022, largely overlapping with my PhD studies. The main research topics are Non-perturbative methods in Quantum Field Theory and Beyond Standard Model phenomenology. A full list of publications is available on my iNSPIRE HEP author page. My PhD thesis can be accessed on arXiv.\nSelected articles:\n\nMatching scalar leptoquarks to the SMEFT at one loop\nModular invariant dynamics and fermion mass hierarchies around \\(\\tau = i\\)\nSolving the Bethe-Salpeter Equation in Minkowski Space for a Fermion-Scalar system"
  }
]
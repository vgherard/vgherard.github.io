<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
  <title>CLLR loss function</title>

  <meta property="description" itemprop="description" content="A short description of the post."/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2023-11-15"/>
  <meta property="article:created" itemprop="dateCreated" content="2023-11-15"/>
  <meta name="article:author" content="vgherard"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="CLLR loss function"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="A short description of the post."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="CLLR loss function"/>
  <meta property="twitter:description" content="A short description of the post."/>

  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Application-independent evaluation of speaker detection;citation_volume=20;citation_doi=https://doi.org/10.1016/j.csl.2005.08.001;citation_issn=0885-2308;citation_author=Niko Brümmer;citation_author=Johan Preez"/>
  <meta name="citation_reference" content="citation_title=Elements of information theory 2nd edition (wiley series in telecommunications and signal processing);citation_publisher=Hardcover; Wiley-Interscience;citation_author=Thomas M. Cover;citation_author=Joy A. Thomas"/>
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","bibliography","categories","draft"]}},"value":[{"type":"character","attributes":{},"value":["CLLR loss function"]},{"type":"character","attributes":{},"value":["A short description of the post.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["vgherard"]},{"type":"character","attributes":{},"value":["https://vgherard.github.io"]}]}]},{"type":"character","attributes":{},"value":["2023-11-15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["biblio.bib"]},{"type":"character","attributes":{},"value":["Probability Theory","Measure Theory"]},{"type":"logical","attributes":{},"value":[true]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["biblio.bib","cllr-loss-function_files/anchor-4.2.2/anchor.min.js","cllr-loss-function_files/bowser-1.9.3/bowser.min.js","cllr-loss-function_files/distill-2.2.21/template.v2.js","cllr-loss-function_files/figure-html5/unnamed-chunk-6-1.png","cllr-loss-function_files/figure-html5/unnamed-chunk-7-1.png","cllr-loss-function_files/header-attrs-2.24/header-attrs.js","cllr-loss-function_files/jquery-3.6.0/jquery-3.6.0.js","cllr-loss-function_files/jquery-3.6.0/jquery-3.6.0.min.js","cllr-loss-function_files/jquery-3.6.0/jquery-3.6.0.min.map","cllr-loss-function_files/popper-2.6.0/popper.min.js","cllr-loss-function_files/tippy-6.2.7/tippy-bundle.umd.min.js","cllr-loss-function_files/tippy-6.2.7/tippy-light-border.css","cllr-loss-function_files/tippy-6.2.7/tippy.css","cllr-loss-function_files/tippy-6.2.7/tippy.umd.min.js","cllr-loss-function_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="cllr-loss-function_files/header-attrs-2.24/header-attrs.js"></script>
  <script src="cllr-loss-function_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="cllr-loss-function_files/popper-2.6.0/popper.min.js"></script>
  <link href="cllr-loss-function_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="cllr-loss-function_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="cllr-loss-function_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="cllr-loss-function_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="cllr-loss-function_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="cllr-loss-function_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="cllr-loss-function_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"CLLR loss function","description":"A short description of the post.","authors":[{"author":"vgherard","authorURL":"https://vgherard.github.io","affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2023-11-15T00:00:00.000+01:00","citationText":"vgherard, 2023"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>CLLR loss function</h1>
<!--radix_placeholder_categories-->
<div class="dt-tags">
<div class="dt-tag">Probability Theory</div>
<div class="dt-tag">Measure Theory</div>
</div>
<!--/radix_placeholder_categories-->
<p><p>A short description of the post.</p></p>
</div>

<div class="d-byline">
  vgherard <a href="https://vgherard.github.io" class="uri">https://vgherard.github.io</a> 
  
<br/>2023-11-15
</div>

<div class="d-article">
<h1 id="intro">Intro</h1>
<p>During the last few months, I’ve been working on some machine learning applications to <a href="https://en.wikipedia.org/wiki/Forensic_science">Forensic Science</a>, a.k.a. Criminalistics.
In this field, one common task for the data analyst is to present the <em>trier-of-fact</em> (the person or people who determine the facts in a legal proceeding) with a numerical assessment of the strength of the evidence provided by available data towards different hypotheses. In more familiar terms, forensic experts are responsible of computing the likelihoods (or likelihood ratios) of data under competing hypotheses, which are then used by the trier-of-fact to produce (Bayesian) posterior probabilities for the hypotheses in question<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>In relation to this, forensic scientists have developed a bunch techniques to assess the performance of a likelihood ratio model in discriminating between two alternative hypothesis. In particular, I have come across the so called <em>Likelihood Ratio Cost</em>, usually defined as:</p>
<p><span class="math display" id="eq:CLLR">\[
C_{\text{LLR}} = \frac{1}{2N_1} \sum _{Y_i=1} \log(1+r(X_i) ^{-1})+\frac{1}{2N_0} \sum _{Y_i=0} \log(1+r(X_i)), \tag{1}
\]</span>
where we assume we have data consisting of <span class="math inline">\(N_1+N_0\)</span> independent identically distributed observations <span class="math inline">\((X_i,\,Y_i)\)</span> and <span class="math inline">\(r(X)\)</span> is our model for <span class="math inline">\(\frac{\text{Pr}(X\vert Y = 1)}{\text{Pr}(X\vert Y = 0)}\)</span>. The main reason for writing this note was to understand some properties of Eq. <a href="#eq:CLLR">(1)</a>, which I found (and still find, in some respects - see below) somewhat obscure<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>Strictly speaking, there are several aspects to what I have referred to as the “performance of a likelihood ratio model”. First of all, there is the
left-over uncertainty on <span class="math inline">\(Y\)</span> after measuring <span class="math inline">\(X\)</span>, which is an intrinsic property of the data and is independent of modeling. Second, <span class="math inline">\(X\)</span> may not correspond to raw data, but rather be the result of some data-processing/summary, which will in general reduce the amount of available information on <span class="math inline">\(Y\)</span>. Finally, in the general case, the likelihood ratio <span class="math inline">\(r(X)\)</span> will not be an exact model, but only an approximation estimated from data. All this aspects get captured and mixed by Eq. <a href="#eq:CLLR">(1)</a>, luckily in a way that can be actually decomposed (see below).</p>
<p>I begin with a mathematical generalization of Eq. <a href="#eq:CLLR">(1)</a>.</p>
<h1 id="weighted-cross-entropy-loss">Weighted cross-entropy loss</h1>
<p>Let <span class="math inline">\(\{(X_i,\,Y_i)\}_{i=1,\,2,\,\dots,N}\)</span> be independent draws from a joint distribution, with binary <span class="math inline">\(Y_i \in \{0,\,1\}\)</span>. Given a function <span class="math inline">\(w=w(\boldsymbol Y)\)</span>, symmetric in its arguments, we define the functional:</p>
<p><span class="math display" id="eq:WeightedLoss">\[
\mathcal L_N^w[f] = -\frac{1}{N}\sum_{i=1} ^N \left[w(\boldsymbol Y)Y_i \log(f(X_i))+ w({\boldsymbol Y}^c)( Y_i^c) \log(f^c(X_i))\right],\tag{2}
\]</span>
where <span class="math inline">\(f=f(X)\)</span> is any function satisfying <span class="math inline">\(f(X)\in [0,\,1]\)</span> for all <span class="math inline">\(X\)</span>, and we let <span class="math inline">\(q^c = 1-q\)</span> for any number <span class="math inline">\(q \in [0,\,1]\)</span>.</p>
<p>We now look for the population minimizer of <a href="#eq:WeightedLoss">(2)</a>, <em>i.e.</em> the function <span class="math inline">\(f_*\)</span> that minimizes the functional <span class="math inline">\(f \mapsto \mathbb E(\mathcal L _N ^w [f])\)</span><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. We have:</p>
<p><span class="math display">\[
\mathbb E(\mathcal L _N ^w [f]) = -\frac{1}{N}\sum _{i=1} ^N \mathbb E\left[ \mathbb E(Y_i\cdot w(\boldsymbol Y)\vert X_i)\cdot \log(f(X_i))+E(Y_i^c\cdot w(\boldsymbol Y ^c)\vert X_i)\cdot \log(f^c(X_i))\right],
\]</span>
which is minimized by:</p>
<p><span class="math display">\[
\begin{split}
f_*(X_i) &amp;= \frac{1}{1+r(X_i)^{-1}},\\
r_*(X_i) &amp;= \dfrac{E(Y_i\cdot w(\boldsymbol Y)\vert X_i)}{E(Y_i^c\cdot w(\boldsymbol Y^c)\vert X_i)},
\end{split}
\]</span>
with:</p>
<p><span class="math display">\[
\mathbb E(\mathcal L _N ^w [f_*]) = \mathbb E\left[ \mathbb E(Y_i\cdot w(\boldsymbol Y) + Y_i^c\cdot w(\boldsymbol Y^c)\vert X_i)\cdot \mathcal H(f_*(X_i))\right].
\]</span>
Here <span class="math inline">\(\mathcal H(p) = -p \log (p) -(1-p) \log(1-p)\)</span>, and the index <span class="math inline">\(i\)</span> in the previous expression can be any index, since data points are assumed to be identically distributed. For any other function <span class="math inline">\(f\)</span>, we have:</p>
<p><span class="math display">\[
\mathbb E(\mathcal L _N ^w [f]) - \mathbb E(\mathcal L _N ^w [f_*]) = \mathbb E\left[ \mathbb E(Y_i\cdot w(\boldsymbol Y) + Y_i^c\cdot w(\boldsymbol Y^c)\vert X_i)\cdot \mathcal D(f_*(X_i)\vert \vert f(X_i))\right],
\]</span>
being <span class="math inline">\(\mathcal D(p\vert \vert q) = p \log (\frac{p}{q}) + (1-p) \log (\frac{1-p}{1-q})\)</span>.</p>
<p>Finally, if <span class="math inline">\(X = g(\widetilde X)\)</span> for some random variable <span class="math inline">\(\widetilde X\)</span>, and we define:</p>
<p><span class="math display">\[
\widetilde{\mathcal L} _N^w[\widetilde f]  = -\frac{1}{N}\sum_{i=1} ^N \left[w(\boldsymbol Y)Y_i \log(\widetilde f(\widetilde X))+ w({\boldsymbol Y}^c)( Y_i^c) \log(\widetilde f(\widetilde X)^c)\right],
\]</span>
then <span class="math inline">\(\mathcal L _N ^w [f] = \widetilde{\mathcal L} _N^w[f \circ g]\)</span>. If <span class="math inline">\(\widetilde f _* =\)</span> is the population minimizer of <span class="math inline">\(\widetilde{\mathcal L} _N^w\)</span>, it follows that <span class="math inline">\(\mathbb E (\widetilde{\mathcal L} _N^w[\widetilde f _*]) \leq \mathbb E(\mathcal L _N ^w [f_*])\)</span>.</p>
<p>In conclusion, we can decompose the expected loss for a function <span class="math inline">\(f=f(X)\)</span>, where <span class="math inline">\(X= g(\widetilde X)\)</span>, in the following suggestive way:</p>
<p><span class="math display">\[
\mathbb E(\mathcal L _N ^w [f]) = (L_N ^w)_\text{min}+(L_N ^w)_\text{proc} +(L_N ^w)_\text{missp}
\]</span>
where:</p>
<p><span class="math display" id="eq:DecompositionWeightedLoss">\[
\begin{split}
(L_N ^w)_\text{min}&amp;\equiv\mathbb E(\widetilde{\mathcal L} _N^w[{\widetilde f} _*])  \\ &amp;=
\mathbb E\left[ \mathbb E(Y_i\cdot w(\boldsymbol Y) + Y_i^c\cdot w(\boldsymbol Y^c)\vert \widetilde X _i)\cdot \mathcal H({\widetilde f} _*(\widetilde X _i))\right],\\
(L_N ^w)_\text{proc}&amp;\equiv\mathbb E(\mathcal L _N ^w [f_*]-\widetilde{\mathcal L} _N^w[\phi_*])  \\&amp; =
\mathbb E\left[ \mathbb E(Y_i\cdot w(\boldsymbol Y) + Y_i^c\cdot w(\boldsymbol Y^c)\vert X_i)\cdot  \mathcal H(f_*(X_i))
\right]- (L_N ^w)_\text{min},\\
(L_N ^w)_\text{missp} &amp; \equiv \mathbb E(\mathcal L _N ^w [f]) - \mathbb E(\mathcal L _N ^w [f_*]) \\&amp;= \mathbb E\left[ \mathbb E(Y_i\cdot w(\boldsymbol Y) + Y_i^c\cdot w(\boldsymbol Y^c)\vert X_i)\cdot  \mathcal D(f_*(X_i)\vert \vert f(X_i))\right].
\end{split} \tag{3}
\]</span>
The three components can be interpreted in the light of the arguments in the
introduction: <span class="math inline">\((L_N ^w)_\text{min}\)</span> represents the minimum expected loss
achievable, given the data available <span class="math inline">\(\widetilde X\)</span>; <span class="math inline">\((L_N ^w)_\text{proc}\)</span> accounts
for the information lost in the processing transformation <span class="math inline">\(X=g(\widetilde X)\)</span>; finally
<span class="math inline">\((L_N ^w)_\text{missp}\)</span> is due to misspecification, <em>i.e.</em> the fact that the
model <span class="math inline">\(f(X)\)</span> for the true conditional probability
<span class="math inline">\(f_*(X) = \text{Pr}(Y=1\vert X)\)</span> is an approximation.</p>
<h1 id="a-familiar-example">A familiar example</h1>
<p>For <span class="math inline">\(w(\boldsymbol) = 1\)</span>, <span class="math inline">\(\mathcal L _N ^{w}\)</span> coincides with the usual
cross-entropy loss:</p>
<p><span class="math display" id="eq:CrossEntropyLoss">\[
\mathcal L_N^{w=1}[f] = -\frac{1}{N}\sum_{i=1} ^N \left[Y_i \log(f(X_i))+ (1-Y_i) \log(1-f(X_i))\right].\tag{4}
\]</span>
The population minimizer of <a href="#eq:CrossEntropyLoss">(4)</a> is
<span class="math inline">\(f_*(X) = \text{Pr}(Y=1\vert X)\)</span> (independently of sample size) and the
corresponding expected loss is:</p>
<p><span class="math display">\[
\mathbb E(\mathcal L _N ^{w=1} [f_*]) = H(Y\vert X),
\]</span>
the conditional entropy of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>. The expected loss for a generic
function <span class="math inline">\(f\)</span> is:</p>
<p><span class="math display">\[
\mathbb E(\mathcal L _N ^{w=1} [f]) = H(Y\vert X) + D(f_* \vert \vert f)
\]</span>
where <span class="math inline">\(D(f_* \vert \vert f)\)</span> is a short for the Kullback-Liebler divergence
between the true and postulated probability measures, with the
<span class="math inline">\(Y\vert X\)</span> conditional probability given by <span class="math inline">\(f_*(X)\)</span> and <span class="math inline">\(f(X)\)</span>, respectively<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Finally, if <span class="math inline">\(X = g(\widetilde X)\)</span> as before, we can
decompose the expected loss of <span class="math inline">\(f\)</span> as in the previous section:</p>
$$
<span class="math display" id="eq:DecompositionCrossEntropy">\[\begin{split}
\mathbb E(\mathcal L _N ^{w=1} [f]) &amp;= (L_N ^{w=1})_\text{min}+(L_N ^{w=1})_\text{proc} +(L_N ^{w=1})_\text{missp},\\

(L_N ^{w=1})_\text{min} &amp; = H(Y\vert \widetilde X),\\
(L_N ^{w=1})_\text{proc} &amp; = I(\widetilde X;Y\vert X),\\
(L_N ^{w=1})_\text{missp} &amp; = D(f_*\vert \vert f).
\end{split}\]</span>
<p>\tag{5}
<span class="math display">\[
where $I$ denotes mutual information, and we employed identities [@Cover2006]:
\]</span>
I(X;YX) = I(X,Y)-I(X,Y) = H(YX)-H(YX).
$$</p>
<p>All these quantities have straightforward information-theoretic interpretations. In particular, <span class="math inline">\((L_N ^{w=1})_\text{proc}\)</span> can be interpreted as the amount of information on <span class="math inline">\(Y\)</span> lost due to processing, whereas <span class="math inline">\((L_N ^{w=1})_\text{missp}\)</span> is the average extra space needed to encode <span class="math inline">\(Y\)</span> in a scheme optimized for <span class="math inline">\(f\)</span>, rather than for the true <span class="math inline">\(f_*\)</span>.</p>
<h1 id="the-likelihood-ratio-cost">The Likelihood Ratio Cost</h1>
<p>The quantity <span class="math inline">\(C_{\text{LLR}}\)</span> defined in Eq. <a href="#eq:CLLR">(1)</a> can be put in the general form <a href="#eq:WeightedLoss">(2)</a>, if we let <span class="math inline">\(f(X) = (1+r(X)^{-1})^{-1}\)</span> and<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>:</p>
<p><span class="math display">\[
w(\boldsymbol Y) = \left(\dfrac{2}{N}\sum _{i = 1}^{N}Y_j \right)^{-1}
\]</span>
The calculations leading to <span class="math inline">\(f_*\)</span> and <span class="math inline">\(r_*\)</span> are a bit more involved but can still be carried out analytically. The result for <span class="math inline">\(r_*\)</span> is:</p>
<p><span class="math display">\[
r_*(X) = \dfrac{\text{Pr}(Y=1\vert X)}{\text{Pr}(Y=0\vert X)}\cdot \frac{\text {Pr}(Y=0)}{\text {Pr}(Y=1)}\cdot \frac{1-\text {Pr}(Y=1)^N}{1-\text {Pr}(Y=0)^N}.
\]</span></p>
<p>Apart from the last term, which tends to unity as <span class="math inline">\(N\to \infty\)</span>, we see that <span class="math inline">\(r_*(X)\)</span> is essentially the likelihood ratio of <span class="math inline">\(X\)</span>, which we denote <span class="math inline">\(\Lambda (X)\)</span>. Schematically:</p>
<p><span class="math display">\[
r_*(X) \approx \Lambda (X) \sim \dfrac{\text {Pr}(X\vert Y = 1)}{\text {Pr}(X\vert Y = 0)}.
\]</span></p>
<p>In order to avoid annoying <span class="math inline">\(\approx\)</span> symbols, I will consider a slight modification of the usual <span class="math inline">\(C_\text{LLR}\)</span>, that is Eq. <a href="#eq:CLLR">(1)</a> multiplied by <span class="math inline">\(\dfrac{N_1N_2}{N^2}\)</span> in the same notation. As this is essentially equivalent to the original definition, I will keep denoting this quantity by <span class="math inline">\(C_\text{LLR}\)</span>, in order to avoid cumbersome notations. This can again be obtained from Eq. <a href="#eq:WeightedLoss">(2)</a> with:</p>
<p><span class="math display">\[
w(\boldsymbol Y) = \dfrac{1}{2N}\sum _{i = 1}^{N}(1-Y_j),
\]</span></p>
<p>and, in this case, we can easily compute:</p>
<p><span class="math display">\[
r_*(X) = \Lambda (X),\quad f_*(X)=\dfrac{1}{1+\Lambda(X)^{-1}},
\]</span></p>
<p>where the equal signs are exact. The decomposition of <span class="math inline">\(\mathbb E(C_\text{LLR})\)</span> reads:</p>
$$
<span class="math display">\[\begin{split}
\mathbb E(C_\text{LLR}) &amp;= \mathbb E(C_\text{LLR}^\text{min})+\mathbb E(C_\text{LLR}^\text{proc}) +\mathbb E(C_\text{LLR}^\text{missp}),\\

\mathbb E(C_\text{LLR}^\text{min}) &amp;=
\text{Var}(Y) \cdot\mathbb E\left[ \frac{1}{2}\left( \dfrac{\text{Pr}(Y = 1\vert \widetilde X)}{\text{Pr}(Y=1)}+\dfrac{\text{Pr}(Y = 0\vert \widetilde X)}{\text{Pr}(Y=0)}\right)\cdot \mathcal H({\widetilde f} _*(\widetilde X))\right],\\

\mathbb E(C_\text{LLR}^\text{proc}) &amp; =
\text{Var}(Y) \cdot\mathbb E\left[ \frac{1}{2}\left( \dfrac{\text{Pr}(Y = 1\vert  X)}{\text{Pr}(Y=1)}+\dfrac{\text{Pr}(Y = 0\vert X)}{\text{Pr}(Y=0)}\right)\cdot \mathcal H({f} _*( X))\right]-\mathbb E(C_\text{LLR}^\text{min}),\\

\mathbb E(C_\text{LLR}^\text{missp}) &amp;=
\text{Var}(Y) \cdot\mathbb E\left[ \frac{1}{2}\left( \dfrac{\text{Pr}(Y = 1\vert  X)}{\text{Pr}(Y=1)}+\dfrac{\text{Pr}(Y = 0\vert X)}{\text{Pr}(Y=0)}\right)\cdot \mathcal D({f} _*( X) \vert \vert f(X))\right],\\
\end{split}\]</span>
<p>$$</p>
<p>with <span class="math inline">\(\text{Var}(Y) = \text{Pr}(Y=1)\text{Pr}(Y=0)\)</span>.</p>
<p>We can recast the above expressions into a more interpretable form as follows. First of all, we observe that<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>:</p>
<p><span class="math display">\[
\frac{1}{2}\left( \dfrac{\text{Pr}(Y = 1\vert  X)}{\text{Pr}(Y=1)}+\dfrac{\text{Pr}(Y = 0\vert X)}{\text{Pr}(Y=0)}\right)=\dfrac{\text{Pr}(X\vert Y = 1)\cdot \frac{1}{2}+\text{Pr}(X\vert Y = 0)\cdot\frac{1}{2}}{\text{Pr}(X)}\equiv\dfrac{\text{Pr}&#39;(X)}{\text{Pr}(X)},
\]</span>
where the last equality is nothing but a definition of <span class="math inline">\(\text{Pr}^\prime(X)\)</span>.
We now notice that <span class="math inline">\(\text{Pr}^\prime(X)\)</span> is indeed the <span class="math inline">\(X\)</span> marginal distribution from the joint distribution:</p>
<p><span class="math display">\[
\text{Pr}^\prime(X,Y) = \frac{1}{2} \text{Pr}(X \vert Y),
\]</span>
which gives rise to the same <span class="math inline">\(X\vert Y\)</span> conditional distribution, but to <span class="math inline">\(\text{Pr}^\prime(Y=1) = \frac{1}{2}\)</span>. Using this fact, we can rewrite:</p>
<p><span class="math display">\[
\mathbb E\left[ \left( \dfrac{\text{Pr}(Y = 1\vert  X)}{\text{Pr}(Y=1)}+\dfrac{\text{Pr}(Y = 0\vert X)}{\text{Pr}(Y=0)}\right)\cdot \mathcal u(X)\right] = \mathbb E^\prime (u(X)),
\]</span></p>
<p>for a generic function <span class="math inline">\(u(X)\)</span>, where the expectation on the right-hand side is taken with respect to the <span class="math inline">\(\text{Pr}^\prime\)</span> probability measure. Finally, observing that <span class="math inline">\(f_*(X) = \text{Pr}^\prime(Y=1\vert X)\)</span>, in analogy with <a href="#eq:DecompositionCrossEntropy">(5)</a> we obtain:</p>
<p><span class="math display" id="eq:DecompositionCLLR">\[
\begin{split}
\mathbb E(C_\text{LLR}^\text{min}) &amp; = H^\prime(Y\vert \widetilde X),\\
\mathbb E(C_\text{LLR}^\text{proc}) &amp; = I^\prime(Y; \widetilde X\vert X),\\
\mathbb E(C_\text{LLR}^\text{missp}) &amp; = D^\prime(f_*\vert \vert f),
\end{split} \tag{6}
\]</span></p>
<p>where entropies are also computed with respect to the <span class="math inline">\(\text{Pr}^\prime\)</span>
probability measure.</p>
<h1 id="discussion">Discussion</h1>
<p>The table below provides a comparison between cross entropy and <span class="math inline">\(C_\text{LLR}\)</span>,
summarizing the results from previous sections.</p>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 38%" />
<col style="width: 46%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Cross-entropy</th>
<th>Likelihood Ratio Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(f_*(X)\)</span></td>
<td><span class="math inline">\(\text{Pr}(Y = 1\vert X)\)</span></td>
<td><span class="math inline">\((1+\Lambda(X)^{-1})^{-1}\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(r_*(X)\)</span>`</td>
<td>Posterior odds ratio</td>
<td>Likelihood ratio</td>
</tr>
<tr class="odd">
<td>Minimum</td>
<td><span class="math inline">\(H(Y\vert \widetilde X)\)</span></td>
<td><span class="math inline">\(H^\prime(Y\vert \widetilde X)\)</span></td>
</tr>
<tr class="even">
<td>Processing</td>
<td><span class="math inline">\(I(Y; \widetilde X\vert X)\)</span></td>
<td><span class="math inline">\(I^\prime(Y; \widetilde X\vert X)\)</span></td>
</tr>
<tr class="odd">
<td>Misspecification</td>
<td><span class="math inline">\(D(f_*\vert\vert f)\)</span></td>
<td><span class="math inline">\(D^\prime(f_*\vert\vert f)\)</span></td>
</tr>
</tbody>
</table>
<p>The objective of <span class="math inline">\(C_\text{LLR}\)</span> is found to be the likelihood ratio, as
terminology suggests. The interpretation of model selection according to
<span class="math inline">\(C_\text{LLR}\)</span> minimization turns out to be slightly more involved, compared to
cross-entropy, which we first review.</p>
<p>Suppose we are given a set of predictive models <span class="math inline">\(\{\mathcal M_i\}_{i\in I}\)</span>,
each of which consists of a processing transformation, <span class="math inline">\(\widetilde X \mapsto X\)</span>,
and an estimate of the posterior probability <span class="math inline">\(\text{Pr}(Y = 1\vert X)\)</span>.
When the sample size <span class="math inline">\(N \to \infty\)</span>, cross-entropy minimization will almost
certainly select the model that minimizes
<span class="math inline">\(I(Y; \widetilde X\vert X) + D(f_*\vert \vert f)\)</span>. Following standard
Information Theory arguments, we can interpret this model as the optimal
(on average) compression algorithm for <span class="math inline">\(Y\)</span>, assuming <span class="math inline">\(X\)</span> to be available at both
the encoding and decoding ends.</p>
<p>The previous argument carries over <em>mutatis mutandi</em> to <span class="math inline">\(C_\text{LLR}\)</span>
minimization, with an important qualification: optimal average compression is
now achieved with respect to a different probability measure
<span class="math inline">\(\text{Pr}&#39;(X,Y) = \frac{1}{2}\text {Pr}(X\vert Y)\)</span>, that satisfies
<span class="math inline">\(\text{Pr}&#39;(X\vert Y) = \text{Pr}(X\vert Y)\)</span> and
<span class="math inline">\(\text{Pr}&#39;(Y = 1) = \frac{1}{2}\)</span>. In particular, according to <span class="math inline">\(\text{Pr}&#39;\)</span>,
the likelihood ratio coincides with the posterior odds ratio, and
<span class="math inline">\((1+\Lambda(X)^{-1})^{-1}\)</span> coincides with posterior probability, which clarifies
why we can measure differences from the true likelihood ratio through the
Kullback-Liebler divergence.</p>
<p>The measure <span class="math inline">\(\text{Pr}&#39;\)</span> is not just an abstruse mathematical construct:
it is the result of balanced sampling from the original distribution, <em>i.e.</em>
taking an equal number of positive and negative cases<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>. If the <span class="math inline">\((X,\,Y)\)</span> distribution is already balanced,
either by design or because of some underlying symmetry in the data generating
process, <span class="math inline">\(C_{\text{LLR}}\)</span> is essentially equivalent to cross-entropy loss, as we
have shown. On the other hand, for very unbalanced distributions
(with <span class="math inline">\(\text{Pr}(Y=1)\)</span> very close to one or zero) balanced sampling can be
costly in terms of data, leading to rejection of many data points. In this case,
if the goal is to estimate the likelihood ratio, employing a <span class="math inline">\(C_{\text{LLR}}\)</span>
loss can be advantageous.</p>
<h1 id="example">Example</h1>
<p>In general, the posterior odd ratio and likelihood ratio differ only by a
constant, the prior ratio <span class="math inline">\(\frac{\text {Pr}(Y=1)}{\text {Pr}(Y=0)}\)</span>, so it is
reasonable to try to fit the same functional form to both of them. Let us illustrate with a simulated example of this type the differences between cross-entropy and <span class="math inline">\(C_{\text{LLR}}\)</span> optimization.</p>
<p>Suppose that <span class="math inline">\(X \in \mathbb R\)</span> and $Y{0,,1} have joint probability
density:</p>
<p><span class="math display">\[
\Phi(X,Y)=Y\frac{\pi}{\sqrt{2\pi\sigma _1^2}}\exp(-\frac{(X-\mu_1)^2}{2\sigma _1^2})+(1-Y)\frac{1-\pi}{\sqrt{2\pi\sigma _0^2}}\exp(-\frac{(X-\mu_0)^2}{2\sigma _0^2}),
\]</span></p>
<p>so that <span class="math inline">\(X\)</span> has marginal density:</p>
<p><span class="math display">\[
\phi(X\vert Y) = \frac{1}{\sqrt{2\pi\sigma _Y^2}}\exp(-\frac{(X-\mu_Y)^2}{2\sigma _Y^2}),
\]</span>
and <span class="math inline">\(Y\)</span> has marginal probability:</p>
<p><span class="math display">\[
\pi = \text{Pr}(Y = 1)
\]</span>
The true likelihood ratio and posterior odds ratio are respectively given by:</p>
<p><span class="math display">\[
\begin{split}
\Lambda (X) &amp;
    \equiv \frac{\phi(X\vert Y=1)}{\phi(X\vert Y=0)}
    = e^{a X^2 + bX +c},\\
\rho (X) &amp;
    \equiv \frac{\text{Pr}(Y = 1\vert X)}{\text{Pr}(Y = 0\vert X)}
    = e^{aX^2 + bX+c+d},
\end{split}
\]</span>
where we have defined:</p>
<p>$$</p>
<p>a ,
b _1 - _0,
c -+(),
d () .</p>
<p>$$</p>
<p>Suppose that we fit an exponential function <span class="math inline">\(r(X)=e^{mX +q}\)</span> to <span class="math inline">\(\Lambda(X)\)</span> by
Likelihood Ratio cost minimization, and similarly <span class="math inline">\(r&#39;(X)=e^{m&#39;X+q&#39;}\)</span> to
<span class="math inline">\(\rho(X)\)</span> by cross-entropy minimization<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.
Do the results of these two procedure agree in some sense in the large sample limit?</p>
<p>We can easily find this out through a simulation. We first define two helpers
to compute cross-entropy and <span class="math inline">\(C_\text{LLR}\)</span>, respectively:</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>Second, we define a function to sample from the distribution described above:</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>where I have encoded the parameter values I will use for the example as argument defaults. In particular, I’m considering a heavily unbalanced case (<span class="math inline">\(\text{Pr}(Y = 1) = 0.1\%\)</span>) in which negative cases give rise to a sharply localized <span class="math inline">\(X\)</span> signal around <span class="math inline">\(X=0\)</span>, while the few positive cases give rise to a broader signal centered at <span class="math inline">\(X=1\)</span>.</p>
<p>We now generate a large dataset and use it to optimize the two loss functions,
which should provide a fairly close approximation to the population minimizers:</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>where the purpose of the last function is to return the estimated log-likelihood
ratio at a given <span class="math inline">\(X=x\)</span>. Since the objective of cross-entropy is actually the posterior odds ratio, we need to divide the cross-entropy estimate by the prior ratio <span class="math inline">\(\frac{\pi} {1-\pi}\)</span> in order to obtain the likelihood ratio, which we can
achieve with the following trick:</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>Finally, we also define a function that computes the true log-likelihood ratio:</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>So, what do our best estimates look like? The plot below shows the best fit
lines for the log-likelihood ratio from <span class="math inline">\(C_{\text{LLR}}\)</span> minimization (in solid red) and cross-entropy minimization (in solid blue). The true log-likelihood ratio parabola is the black line. Also shown are the <span class="math inline">\(\text{LLR}=0\)</span> line (in dashed red) and the <span class="math inline">\(\text{LLR}=\ln(\frac{1-\pi}{\pi})\)</span> (in
dashed blue), which are the appropriate “Bayes” thresholds for classifying a
data point as positive (<span class="math inline">\(Y=1\)</span>), assuming data comes from a balanced and unbalanced distribution, respectively.</p>
<div class="layout-chunk" data-layout="l-body">
<details>
<summary>
Show code
</summary>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://dplyr.tidyverse.org'>dplyr</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://ggplot2.tidyverse.org'>ggplot2</a></span><span class='op'>)</span> </span>
<span></span>
<span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggplot.html'>ggplot</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>+</span> </span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_function.html'>geom_function</a></span><span class='op'>(</span>fun <span class='op'>=</span> \<span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='fu'>llr</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>par_cllr</span><span class='op'>)</span>, color <span class='op'>=</span> <span class='st'>"red"</span><span class='op'>)</span> <span class='op'>+</span> </span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_function.html'>geom_function</a></span><span class='op'>(</span>fun <span class='op'>=</span> \<span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='fu'>llr</span><span class='op'>(</span><span class='va'>x</span>, <span class='va'>par_cross_entropy</span><span class='op'>)</span>, color <span class='op'>=</span> <span class='st'>"blue"</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_function.html'>geom_function</a></span><span class='op'>(</span>fun <span class='op'>=</span> \<span class='op'>(</span><span class='va'>x</span><span class='op'>)</span> <span class='fu'>llr_true</span><span class='op'>(</span><span class='va'>x</span><span class='op'>)</span>, color <span class='op'>=</span> <span class='st'>"black"</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_abline.html'>geom_hline</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>yintercept <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span>, linetype <span class='op'>=</span> <span class='st'>"dashed"</span>, color <span class='op'>=</span> <span class='st'>"red"</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_abline.html'>geom_hline</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>yintercept <span class='op'>=</span> <span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>pi</span> <span class='op'>/</span> <span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='va'>pi</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span>, </span>
<span>               linetype <span class='op'>=</span> <span class='st'>"dashed"</span>, color <span class='op'>=</span> <span class='st'>"blue"</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>    <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/lims.html'>ylim</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>10</span>,<span class='fl'>10</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/lims.html'>xlim</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>1</span>, <span class='fl'>2</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/labs.html'>xlab</a></span><span class='op'>(</span><span class='st'>"X"</span><span class='op'>)</span> <span class='op'>+</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/labs.html'>ylab</a></span><span class='op'>(</span><span class='st'>"Log-Likelihood Ratio"</span><span class='op'>)</span></span></code></pre>
</div>
</details>
<p><img src="cllr-loss-function_files/figure-html5/unnamed-chunk-6-1.png" width="624" /></p>
</div>
<p>The reason why the lines differ is that they are designed to solve a different predictive problem: as we’ve argued above, minimizing <span class="math inline">\(C_\text{LLR}\)</span> looks for the best <span class="math inline">\(Y\vert X\)</span> conditional probability estimate according to the balanced
measure <span class="math inline">\(\text{Pr}&#39;\)</span>, whereas cross-entropy minimization does the same for
the original measure <span class="math inline">\(\text{Pr}\)</span>. This is how data looks like under the two measures (the histograms are stacked - in the unbalanced case, positive examples are invisible on the linear scale of the plot):</p>
<div class="layout-chunk" data-layout="l-body">
<details>
<summary>
Show code
</summary>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>test_data</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/bind_rows.html'>bind_rows</a></span><span class='op'>(</span></span>
<span>  <span class='fu'>rxy</span><span class='op'>(</span>n <span class='op'>=</span> <span class='fl'>1e6</span>, pi <span class='op'>=</span> <span class='fl'>0.5</span><span class='op'>)</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>type <span class='op'>=</span> <span class='st'>"Balanced"</span>, llr_thresh <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span>,</span>
<span>  <span class='fu'>rxy</span><span class='op'>(</span>n <span class='op'>=</span> <span class='fl'>1e6</span><span class='op'>)</span> <span class='op'>|&gt;</span> <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>type <span class='op'>=</span> <span class='st'>"Unbalanced"</span>, llr_thresh <span class='op'>=</span> <span class='op'>-</span><span class='fu'><a href='https://rdrr.io/r/base/Log.html'>log</a></span><span class='op'>(</span><span class='va'>pi</span> <span class='op'>/</span> <span class='op'>(</span><span class='fl'>1</span><span class='op'>-</span><span class='va'>pi</span><span class='op'>)</span><span class='op'>)</span><span class='op'>)</span></span>
<span>  <span class='op'>)</span></span>
<span></span>
<span><span class='va'>test_data</span> <span class='op'>|&gt;</span> </span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggplot.html'>ggplot</a></span><span class='op'>(</span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='va'>x</span>, fill <span class='op'>=</span> <span class='va'>y</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span> </span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_histogram.html'>geom_histogram</a></span><span class='op'>(</span>bins <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/facet_grid.html'>facet_grid</a></span><span class='op'>(</span><span class='va'>type</span> <span class='op'>~</span> <span class='va'>.</span>, scales <span class='op'>=</span> <span class='st'>"free_y"</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/lims.html'>xlim</a></span><span class='op'>(</span><span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='op'>-</span><span class='fl'>2</span>, <span class='fl'>4</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</details>
<p><img src="cllr-loss-function_files/figure-html5/unnamed-chunk-7-1.png" width="624" /></p>
</div>
<p>This differences are reflected in the classification accuracies of the resulting classifiers defined by <span class="math inline">\(\hat Y(X)=I(\text{LLR}(X)&gt;\text{threshold})\)</span>, where the appropriate threshold is zero in the balanced case, and <span class="math inline">\(\ln(\frac{1-\pi}{\pi})\)</span> in the unbalanced case. According to intuition, we see that the <span class="math inline">\(C_\text{LLR}\)</span> optimizer beats the cross-entropy optimizer on the balanced sample, and performs
slightly worse on the unbalanced one (the differences are not statistical fluctuations).</p>
<div class="layout-chunk" data-layout="l-body">
<pre><code># A tibble: 2 × 4
  type       accuracy_cllr accuracy_cross_entropy accuracy_true_llr
  &lt;chr&gt;              &lt;dbl&gt;                  &lt;dbl&gt;             &lt;dbl&gt;
1 Balanced           0.816                  0.804             0.839
2 Unbalanced         0.999                  0.999             0.999</code></pre>
</div>
<h1 id="summary-and-conclusions">Summary and conclusions</h1>
<div class="sourceCode" id="cb2"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-BRUMMER2006230" class="csl-entry" role="listitem">
Brümmer, Niko, and Johan du Preez. 2006. <span>“Application-Independent Evaluation of Speaker Detection.”</span> <em>Computer Speech &amp; Language</em> 20 (2): 230–75. https://doi.org/<a href="https://doi.org/10.1016/j.csl.2005.08.001">https://doi.org/10.1016/j.csl.2005.08.001</a>.
</div>
<div id="ref-Cover2006" class="csl-entry" role="listitem">
Cover, Thomas M., and Joy A. Thomas. 2006. <em>Elements of Information Theory 2nd Edition (Wiley Series in Telecommunications and Signal Processing)</em>. Hardcover; Wiley-Interscience.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>This is how I understood things should <em>theoretically</em> work, from discussions with friends who are actually working on this field. I have no idea on how much day-to-day practice comes close to this mathematical ideal, and whether there exist other frameworks to the one I have just described.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The Likelihood Ratio Cost was introduced in <span class="citation" data-cites="BRUMMER2006230">(<a href="#ref-BRUMMER2006230" role="doc-biblioref">Brümmer and du Preez 2006</a>)</span>. The reference looks promising, but I find its notation and terminology so unfamiliar that I decided to do my own investigation and read it in a second moment.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><em>Nota bene:</em> the function <span class="math inline">\(f\)</span> is here assumed to be fixed, whereas the randomness in the quantity <span class="math inline">\(L _N ^w [f]\)</span> only comes from the paired observations <span class="math inline">\(\{(X_i,\,Y_i)\}_{i=1,\,2,\,\dots,N}\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>
Due to the chain-rule satisfied by the Kullback-Liebler divergence <span class="citation" data-cites="Cover2006">(<a href="#ref-Cover2006" role="doc-biblioref">Cover and Thomas 2006</a>)</span>,
this is the same as the (<span class="math inline">\(X\)</span>-averaged) Kullback-Liebler divergence
<span class="math inline">\(\mathbb E(D(f_*(X)\vert\vert f(X))\)</span><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The quantity <span class="math inline">\(w(\boldsymbol Y)\)</span> is not defined when all <span class="math inline">\(Y_i\)</span>’s are zero, as the right-hand
side of Eq. <a href="#eq:CLLR">(1)</a> itself. In this case, we make the convention <span class="math inline">\(w(\boldsymbol Y) = 0\)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Here we assume, just for notational simplicity, that <span class="math inline">\(X\)</span> is discrete.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Formally, given an i.i.d.
stochastic process <span class="math inline">\(Z_i = (X_i,\,Y_i)\)</span>, we can define a new stochastic process
<span class="math inline">\(Z_i ^\prime = (X_i^\prime,\,Y_i^\prime)\)</span> such that
<span class="math inline">\(Z_i ^\prime = Z_{2i - 1}\)</span> if <span class="math inline">\(Y_{2i-1}\neq Y_{2i}\)</span>, and <span class="math inline">\(Z_i ^\prime = \perp\)</span>
(not defined) otherwise. Discarding <span class="math inline">\(\perp\)</span> values, we obtain an i.i.d.
stochastic process whose individual observations are distributed according to
<span class="math inline">\(\text{Pr}^\prime\)</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>This is just logistic regression. A straight line may be a reasonable approximation if <span class="math inline">\(\sigma_0 ^2\approx \sigma_1 ^2\)</span>, which however I will assume below to be badly violated<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="references">References</h3>
<div id="references-listing"></div>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>

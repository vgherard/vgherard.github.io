---
title: "Akaike for the normal linear model: known vs. unknown variance"
description: |
  Does knowledge of noise variance have any effect on model selection for the mean? 
author:
  - name: Valerio Gherardi
    url: https://vgherard.github.io
date: 2024-03-13
output:
  distill::distill_article:
    self_contained: false
categories: 
  - Model Selection
  - Linear Models
  - Regression
  - Statistics
---

The Akaike Information Criterion (AIC) for the normal linear model 
$Y = X \beta + \varepsilon$, where $\varepsilon \sim \mathcal N (0,\sigma ^2)$
takes the form:

$$
\text{AIC}^{\text{(k)}} = \frac{(\mathbf Y-\mathbf X\hat \beta )^2}{\sigma ^2} + 2p
$$
if the noise variance $\sigma ^2$ is known, and:

$$
\text{AIC}^{\text{(u)}} = \ln(\hat \sigma ^2) + 2p
$$
if $\sigma^2$ is unknown. Here $\hat \beta$ is the maximum-likelihood estimate 
of $\beta$, and $\hat \sigma ^2 = \frac{1}{N-p}(\mathbf Y -\mathbf X \hat \beta)^2$ the corresponding estimate of $\sigma ^2$ if 
the latter is unknown. 

Asymptotically, whether the variance is known or not should make little 
difference on our model selection for the mean. In practice, $\text{AIC}^{\text{(u)}}$ differences can be expanded using 
$\ln (1+x)\approx 1 + x$:

$$
\begin{split}
\text{AIC}^{\text{(u)}}_1-\text{AIC}^{\text{(u)}}_2 &= \ln(\frac{\hat \sigma ^2_1}{\hat \sigma ^2_2}) + 2(p_1-p_2)\\
&\approx \frac{\hat \sigma _{1}^2-\hat \sigma _2 ^2}{\hat \sigma _2 ^2} + 2(p_1-p_2).
\end{split}
$$
This will be approximately equal to $\text{AIC}^{\text{(k)}}_1-\text{AIC}^{\text{(k)}}_2$ provided that $\hat \sigma _1 ^2 \approx\hat \sigma _2 ^2\approx \sigma ^2$ - that is, 
*provided that the models involved in the AIC comparison estimate reasonably well the true variance*.

